<!DOCTYPE html>

<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
<meta charset="utf-8"/>
<meta content="quarto-1.5.57" name="generator"/>
<meta content="width=device-width, initial-scale=1.0, user-scalable=yes" name="viewport"/>
<meta content="Peter Fuleky" name="author"/>
<title>Chapter 2: Conditional Probability and Independence – Study notes for Econometrics I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>
<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta content="../" name="quarto:offset"/>
<link href="../chapters/chap03.html" rel="next"/>
<link href="../chapters/chap01.html" rel="prev"/>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet"/>
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" id="quarto-text-highlighting-styles" rel="stylesheet"/>
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet"/>
<link data-mode="light" href="../site_libs/bootstrap/bootstrap.min.css" id="quarto-bootstrap" rel="stylesheet"/>
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<link href="../style.css" rel="stylesheet"/>
</head>
<body class="nav-sidebar floating">
<div id="quarto-search-results"></div>
<header class="headroom fixed-top" id="quarto-header">

</header>
<!-- content -->
<div class="quarto-container page-columns page-rows-contents page-layout-article" id="quarto-content">
<!-- sidebar -->

<div class="quarto-sidebar-collapse-item" data-bs-target=".quarto-sidebar-collapse-item" data-bs-toggle="collapse" id="quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
<div class="sidebar margin-sidebar" id="quarto-margin-sidebar">

</div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header class="quarto-title-block default" id="title-block-header">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 2: Conditional Probability and Independence</span></h1>
</div>
<div class="quarto-title-meta">
</div>
</header>
<section class="level2" id="conditional-probability">
<h2 class="anchored" data-anchor-id="conditional-probability">2.1 CONDITIONAL PROBABILITY</h2>
<p>In many statistical applications, we have events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and want to explain or predict <span class="math inline">\(A\)</span> from <span class="math inline">\(B\)</span>, i.e., we want to say how likely <span class="math inline">\(A\)</span> is, given that <span class="math inline">\(B\)</span> has occurred.</p>
<section class="level3" id="example-2.1.">
<h3 class="anchored" data-anchor-id="example-2.1.">Example 2.1.</h3>
<p>In university admissions, we might be interested in</p>
<p><span class="math inline">\(A =\)</span> {got g.p.a. 4.0 in college}</p>
<p><span class="math inline">\(B =\)</span> {got g.p.a. 4.0 in High School}.</p>
</section>
<section class="level3" id="example-2.2.">
<h3 class="anchored" data-anchor-id="example-2.2.">Example 2.2.</h3>
<p>Investment professionals might be interested in the case</p>
<p><span class="math inline">\(A =\)</span> {stocks up Today}</p>
<p><span class="math inline">\(B =\)</span> {stocks up Yesterday}.</p>
<p>We are interested not just in <strong>marginal probabilities</strong>, but also in <strong>conditional probabilities</strong>, that is, we want to incorporate some information into our predictions.</p>
</section>
<section class="level3" id="definition-2.1.">
<h3 class="anchored" data-anchor-id="definition-2.1.">Definition 2.1.</h3>
<p>The <strong>probability of an event</strong> <span class="math inline">\(A \in \mathcal{A}\)</span> given an event <span class="math inline">\(B \in \mathcal{A}\)</span>, denoted <span class="math inline">\(P(A|B)\)</span>, is given by</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)}\)</span> (2.1)</p>
<p>when <span class="math inline">\(P(B) &gt; 0\)</span>.</p>
<p>The exclusion of the case <span class="math inline">\(P(B) = 0\)</span> has important ramifications later on.</p>
<ul>
<li>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>mutually exclusive events</strong>, then <span class="math inline">\(P(A|B) = 0\)</span>.</li>
<li>If <span class="math inline">\(A \subseteq B\)</span>, then <span class="math inline">\(P(A|B) = \dfrac{P(A)}{P(B)} \geq P(A)\)</span> with strict inequality unless <span class="math inline">\(P(B) = 1\)</span>.</li>
<li>If <span class="math inline">\(B \subseteq A\)</span>, then <span class="math inline">\(P(A|B) = 1\)</span>.</li>
</ul>
<p>We will later have interest in the special case where <span class="math inline">\(P(A|B) = P(A)\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The conditional probability <span class="math inline">\(P(A|B)\)</span> represents the probability of event <span class="math inline">\(A\)</span> occurring given that we know event <span class="math inline">\(B\)</span> has already occurred. We are essentially restricting our sample space to the outcomes where <span class="math inline">\(B\)</span> occurs and then calculating the proportion of those outcomes in which <span class="math inline">\(A\)</span> also occurs. The formula reflects this by dividing the probability of both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring (<span class="math inline">\(P(A \cap B)\)</span>) by the probability of <span class="math inline">\(B\)</span> occurring (<span class="math inline">\(P(B)\)</span>).</p>
<p>Note that <span class="math inline">\(P(\cdot|B)\)</span> is a probability measure that maps <span class="math inline">\(\mathcal{A} \rightarrow \mathbb{R}_{+}\)</span>. In particular, we have:</p>
</section>
<section class="level3" id="theorem-2.1.">
<h3 class="anchored" data-anchor-id="theorem-2.1.">Theorem 2.1.</h3>
<p>Suppose that <span class="math inline">\(B \in \mathcal{A}\)</span>. Then</p>
<ol type="1">
<li>For any <span class="math inline">\(A \in \mathcal{A}, P(A|B) \geq 0\)</span>;</li>
<li><span class="math inline">\(P(B|B) = 1\)</span></li>
<li><span class="math inline">\(P \left( \bigcup_{i=1}^{\infty} A_i | B \right) = \sum_{i=1}^{\infty} P(A_i|B)\)</span> for any pairwise disjoint events <span class="math inline">\(\lbrace A_i \rbrace_{i=1}^{\infty}\)</span>.</li>
</ol>
<p><strong>Proof:</strong></p>
<p>This follows directly from the definitions and properties of <span class="math inline">\(P\)</span>.</p>
<ol type="1">
<li><p>Since <span class="math inline">\(P(A \cap B) \geq 0\)</span> and <span class="math inline">\(P(B) &gt; 0\)</span>, it follows that <span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} \geq 0\)</span>.</p></li>
<li><p><span class="math inline">\(P(B|B) = \dfrac{P(B \cap B)}{P(B)} = \dfrac{P(B)}{P(B)} = 1\)</span>.</p></li>
<li><p>For pairwise disjoint events <span class="math inline">\(\{A_i\}_{i=1}^{\infty}\)</span>, we have</p>
<p><span class="math inline">\(\begin{aligned}
P \left( \bigcup_{i=1}^{\infty} A_i | B \right) &amp;= \dfrac{P \left( \left( \bigcup_{i=1}^{\infty} A_i \right) \cap B \right)}{P(B)} \\
&amp;= \dfrac{P \left( \bigcup_{i=1}^{\infty} (A_i \cap B) \right)}{P(B)} \\
&amp;= \dfrac{\sum_{i=1}^{\infty} P(A_i \cap B)}{P(B)} \\
&amp;= \sum_{i=1}^{\infty} \dfrac{P(A_i \cap B)}{P(B)} \\
&amp;= \sum_{i=1}^{\infty} P(A_i|B)
\end{aligned}\)</span></p></li>
</ol>
</section>
<section class="level3" id="example-2.3.">
<h3 class="anchored" data-anchor-id="example-2.3.">Example 2.3.</h3>
<p>We have 100 stocks and we observe whether they went up or down on consecutive days, the information is given below</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;">Today</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">up</td>
<td style="text-align: left;">down</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Y’day</td>
<td style="text-align: left;">up</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">78</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">down</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">22</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">68</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">100</td>
</tr>
</tbody>
</table>
<p>The information given here is effectively: <span class="math inline">\(P(A \cap B)\)</span>, <span class="math inline">\(P(A \cap B^c)\)</span>, <span class="math inline">\(P(B \cap A^c)\)</span>, and <span class="math inline">\(P(B^c \cap A^c)\)</span>, where <span class="math inline">\(A =\)</span> {up Y’day} and <span class="math inline">\(B =\)</span> {up T’day}. It is an easy exercise to convert these “joint probabilities” to marginal and conditional probabilities using the <strong>Law of total probability</strong>. Specifically, the equation</p>
<p><span class="math inline">\(P(A) = P(A \cap B) + P(A \cap B^c)\)</span></p>
<p>determines the marginals, and then definition (2.1) gives the conditionals. Thus</p>
<p><span class="math inline">\(P(\text{Up Y'day}) = \dfrac{78}{100}\)</span></p>
<p><span class="math inline">\(P(\text{Down Y'day}) = \dfrac{22}{100}\)</span></p>
<p><span class="math inline">\(P(\text{Up Today} | \text{Up Y'day}) = \dfrac{53/100}{78/100} = \dfrac{53}{78}\)</span>.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><span class="math inline">\(P(A) = P(\text{Up Y'day}) = \dfrac{53 + 25}{100} = \dfrac{78}{100}\)</span></li>
<li><span class="math inline">\(P(A^c) = P(\text{Down Y'day}) = \dfrac{15 + 7}{100} = \dfrac{22}{100}\)</span></li>
<li><span class="math inline">\(P(B) = P(\text{Up Today}) = \dfrac{53 + 15}{100} = \dfrac{68}{100}\)</span></li>
<li><span class="math inline">\(P(B^c) = P(\text{Down Today}) = \dfrac{25 + 7}{100} = \dfrac{32}{100}\)</span></li>
<li><span class="math inline">\(P(A|B) = P(\text{Up Y'day} | \text{Up Today}) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{53/100}{68/100} = \dfrac{53}{68}\)</span></li>
<li><span class="math inline">\(P(A|B^c) = P(\text{Up Y'day} | \text{Down Today}) = \dfrac{P(A \cap B^c)}{P(B^c)} = \dfrac{25/100}{32/100} = \dfrac{25}{32}\)</span></li>
<li><span class="math inline">\(P(A^c|B) = P(\text{Down Y'day} | \text{Up Today}) = \dfrac{P(A^c \cap B)}{P(B)} = \dfrac{15/100}{68/100} = \dfrac{15}{68}\)</span></li>
<li><span class="math inline">\(P(A^c|B^c) = P(\text{Down Y'day} | \text{Down Today}) = \dfrac{P(A^c \cap B^c)}{P(B^c)} = \dfrac{7/100}{32/100} = \dfrac{7}{32}\)</span></li>
<li><span class="math inline">\(P(B|A) = P(\text{Up Today} | \text{Up Y'day}) = \dfrac{P(B \cap A)}{P(A)} = \dfrac{53/100}{78/100} = \dfrac{53}{78}\)</span></li>
<li><span class="math inline">\(P(B|A^c) = P(\text{Up Today} | \text{Down Y'day}) = \dfrac{P(B \cap A^c)}{P(A^c)} = \dfrac{15/100}{22/100} = \dfrac{15}{22}\)</span></li>
<li><span class="math inline">\(P(B^c|A) = P(\text{Down Today} | \text{Up Y'day}) = \dfrac{P(B^c \cap A)}{P(A)} = \dfrac{25/100}{78/100} = \dfrac{25}{78}\)</span></li>
<li><span class="math inline">\(P(B^c|A^c) = P(\text{Down Today} | \text{Down Y'day}) = \dfrac{P(B^c \cap A^c)}{P(A^c)} = \dfrac{7/100}{22/100} = \dfrac{7}{22}\)</span></li>
</ul>
</section>
</section>
<section class="level2" id="bayes-theorem">
<h2 class="anchored" data-anchor-id="bayes-theorem">2.2 BAYES THEOREM</h2>
<p>We next give the famous <strong>Bayes Rule</strong> (or Formula, Lemma or Theorem depending on the source), which is an important result in probability and statistics. Often we have prior information about a marginal probability and about a conditional probability, but we are interested in the reverse direction conditional probability, i.e., in making an <strong>inference</strong>. This can be obtained from this rule.</p>
<section class="level3" id="theorem-2.2.-bayes-rule.">
<h3 class="anchored" data-anchor-id="theorem-2.2.-bayes-rule.">Theorem 2.2. (Bayes Rule).</h3>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be two events with <span class="math inline">\(P(A) \neq 0\)</span>. Then</p>
<p><span class="math inline">\(P(B|A) = \dfrac{P(A|B) \times P(B)}{P(A)} = \dfrac{P(A|B) \cdot P(B)}{P(A|B) \cdot P(B) + P(A|B^c) \cdot P(B^c)}\)</span>. (2.2)</p>
<p><strong>Proof:</strong></p>
<p>This follows from the definition of conditional probability and the law of total probability:</p>
<p><span class="math inline">\(P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)\)</span></p>
<p><span class="math inline">\(P(A) = P(A \cap B) + P(A \cap B^c) = P(A|B) \cdot P(B) + P(A|B^c) \cdot P(B^c)\)</span>.</p>
<p>Dividing the first equation by <span class="math inline">\(P(A)\)</span> and substituting the second equation into the denominator, we get Bayes’ Theorem.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>Bayes’ Theorem provides a way to update our beliefs about an event (<span class="math inline">\(B\)</span>) in light of new evidence (<span class="math inline">\(A\)</span>). It relates the conditional probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span> (the posterior probability) to the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> (the likelihood), the prior probability of <span class="math inline">\(B\)</span>, and the probability of <span class="math inline">\(A\)</span>.</p>
<p>The probability <span class="math inline">\(P(B)\)</span> is frequently called the <strong>prior probability</strong> and <span class="math inline">\(P(A|B)\)</span> is called the <strong>likelihood</strong>, while <span class="math inline">\(P(B|A)\)</span> is called the <strong>posterior</strong>. We next give some examples.</p>
</section>
<section class="level3" id="example-2.4.">
<h3 class="anchored" data-anchor-id="example-2.4.">Example 2.4.</h3>
<p>Suppose we want to know what is the probability a person is telling the truth given the results of a Polygraph test. Let a positive reading on the Polygraph be denoted by <span class="math inline">\((+)\)</span>, and a negative reading be denoted by <span class="math inline">\((-)\)</span>; <span class="math inline">\(T\)</span> denotes the person is telling truth and <span class="math inline">\(L\)</span> denotes the person is lying. We have information on <span class="math inline">\(P(\pm|L)\)</span> and <span class="math inline">\(P(\pm|T)\)</span> from lab work (we are using a shorthand but obvious notation here). Suppose we get <span class="math inline">\(+\)</span> readout</p>
<p><span class="math inline">\(P(T|+) = \dfrac{P(+|T)P(T)}{P(+|T)P(T) + P(+|L)P(L)}\)</span>.</p>
<p>If we believe that <span class="math inline">\(P(T) = 0.99\)</span>, say, and know that <span class="math inline">\(P(+|L) = 0.88\)</span>, <span class="math inline">\(P(+|T) = 0.14\)</span>, then</p>
<p><span class="math inline">\(P(T|+) = 0.94\)</span>.</p>
<p><strong>Solution:</strong></p>
<p>Given <span class="math inline">\(P(T) = 0.99\)</span>, <span class="math inline">\(P(L) = 1 - P(T) = 0.01\)</span>, <span class="math inline">\(P(+|L) = 0.88\)</span>, and <span class="math inline">\(P(+|T) = 0.14\)</span>, we can use Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(T|+) &amp;= \dfrac{P(+|T)P(T)}{P(+|T)P(T) + P(+|L)P(L)} \\
&amp;= \dfrac{(0.14)(0.99)}{(0.14)(0.99) + (0.88)(0.01)} \\
&amp;= \dfrac{0.1386}{0.1386 + 0.0088} \\
&amp;= \dfrac{0.1386}{0.1474} \\
&amp;\approx 0.9403
\end{aligned}\)</span>.</p>
<p>This is perhaps a bit surprising, see <strong>Prosecutor’s Fallacy</strong>.</p>
</section>
<section class="level3" id="example-2.5.">
<h3 class="anchored" data-anchor-id="example-2.5.">Example 2.5.</h3>
<p>We next consider an example from economic theory, called the <strong>sequential trading model</strong>. A stock price can take two possible values</p>
<p><span class="math inline">\(V = \begin{cases}
V_H &amp; \text{with prob } 1 - \delta \\
V_L &amp; \text{with prob } \delta
\end{cases}\)</span></p>
<p>where <span class="math inline">\(V_L &lt; V_H\)</span> and <span class="math inline">\(\delta \in [0, 1]\)</span>. This is the prior distribution on value. The investor is chosen randomly from two possible types</p>
<p><span class="math inline">\(T = \begin{cases}
I &amp; \text{with prob } \mu \\
U &amp; \text{with prob } 1 - \mu
\end{cases}\)</span>.</p>
<p>The timeline is: first, a value is chosen, and then a type of investor is chosen, and that investor carries out his strategy. The strategies of the investors are as follows. The informed traders <span class="math inline">\((I)\)</span> will buy if the value is high <span class="math inline">\(V_H\)</span>, and sell if the value is low <span class="math inline">\(V_L\)</span>, provided the quoted prices lie in the interval <span class="math inline">\([V_L, V_H]\)</span>. The uninformed traders <span class="math inline">\((U)\)</span> buy or sell with probability <span class="math inline">\(1/2\)</span>. Suppose that a buy order is received (but it is not known from whom), what does that tell us about the value of the stock? Let <span class="math inline">\(A = \lbrace V = V_L \rbrace\)</span> and <span class="math inline">\(B = \lbrace \text{buy order received} \rbrace\)</span>. We can calculate <span class="math inline">\(P(B|A)\)</span> directly from the knowledge of the traders strategies and the distribution of trader types. That is</p>
<p><span class="math inline">\(P(B|A) = \dfrac{1}{2}(1 - \mu)\)</span></p>
<p>because if the value is low the informed trader will not buy and the uninformed trader will buy one half of the time. Likewise</p>
<p><span class="math inline">\(P(B|A^c) = \dfrac{1}{2}(1 - \mu) + \mu\)</span></p>
<p>because when the value is high the informed trader will always buy. We want to know <span class="math inline">\(P(A|B)\)</span> as this tells us the updated value distribution. By Bayes rule, we can calculate the updated distribution (<strong>posterior</strong>) of <span class="math inline">\(V\)</span></p>
<p><span class="math inline">\(\begin{aligned}
P(A|B) &amp;= \dfrac{P(B|A) P(A)}{P(B)} \\
&amp;= \dfrac{P(\text{buy}|V = V_L) P(V = V_L)}{P(\text{buy}|V = V_L)P(V = V_L) + P(\text{buy}|V = V_H)P(V = V_H)} \\
&amp;= \dfrac{\frac{1}{2}(1 - \mu) \times \delta}{\left(\frac{1}{2}(1 - \mu) + \mu \right) \times (1 - \delta) + \frac{1}{2}(1 - \mu) \times \delta} \\
&amp;= \dfrac{(1 - \mu) \times \delta}{(\frac{1}{2}(1 + \mu(1 - 2\delta)))} \\
&amp;= \dfrac{1 - \mu}{1 + \mu(1 - 2\delta)} \times \delta \leq \delta
\end{aligned}\)</span></p>
<p><span class="math inline">\(P(V = V_H | \text{buy}) = P(A^c|B) = 1 - P(A|B) = \dfrac{(\mu + 1)(1 - \delta)}{(1 + \mu(1 - 2\delta))} \geq 1 - \delta\)</span>.</p>
<p>The information that a buy order has been received is useful and increases our valuation of the asset. On the other hand, if a sell order were received, this would lower our valuation of the asset.</p>
</section>
<section class="level3" id="example-2.6.">
<h3 class="anchored" data-anchor-id="example-2.6.">Example 2.6.</h3>
<p>Why most published research findings are false, Ioannidis (2005).</p>
</section>
</section>
<section class="level2" id="independence">
<h2 class="anchored" data-anchor-id="independence">2.3 INDEPENDENCE</h2>
<p>We next define the notion of <strong>independence</strong>, which is a central property in much of statistics. This concerns a special case of conditional probability that makes many calculations simpler.</p>
<section class="level3" id="definition-2.2.">
<h3 class="anchored" data-anchor-id="definition-2.2.">Definition 2.2.</h3>
<p><strong>Independence</strong>. Suppose <span class="math inline">\(P(A), P(B) &gt; 0\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong> if:</p>
<ol type="1">
<li><span class="math inline">\(P(A \cap B) = P(A) \cdot P(B)\)</span></li>
<li><span class="math inline">\(P(A|B) = P(A)\)</span></li>
<li><span class="math inline">\(P(B|A) = P(B)\)</span></li>
</ol>
<p>These are equivalent definitions. Definition (1) is symmetric in <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>; the value of property (1) is that given knowledge of <span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span>, we can directly determine <span class="math inline">\(P(A \cap B)\)</span>, whereas without independence all we can say is the bound (1.2). Definitions (2) and (3) are perhaps easier to interpret. In (2) we are saying that knowledge of <span class="math inline">\(B\)</span> does not change our assessment of the likelihood of <span class="math inline">\(A\)</span>, and essentially <span class="math inline">\(B\)</span> is useless for this purpose. We can in principle allow <span class="math inline">\(P(A)\)</span> and/or <span class="math inline">\(P(B)\)</span> to be zero in all three definitions provided we assign <span class="math inline">\(0/0 = 0\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>Two events are independent if the occurrence of one does not affect the probability of the other occurring. In other words, knowing that event <span class="math inline">\(B\)</span> has occurred does not give us any information about whether or not event <span class="math inline">\(A\)</span> has occurred, and vice versa.</p>
<ul>
<li>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are mutually exclusive events, i.e., <span class="math inline">\(P(A \cap B) = 0\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> cannot be independent unless either <span class="math inline">\(P(A) = 0\)</span> or <span class="math inline">\(P(B) = 0\)</span>.</li>
<li>If <span class="math inline">\(A \subseteq B\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> cannot be independent (unless <span class="math inline">\(P(A) = 0\)</span>).</li>
<li><strong>Independence</strong> is a <strong>symmetric relationship</strong>, so that <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span>, if and only if <span class="math inline">\(B\)</span> is independent of <span class="math inline">\(A\)</span>.</li>
<li>Furthermore, if <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span>, then: <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B^c\)</span>, <span class="math inline">\(A^c\)</span> is independent of <span class="math inline">\(B\)</span>, and <span class="math inline">\(A^c\)</span> is independent of <span class="math inline">\(B^c\)</span>. If you know <span class="math inline">\(B\)</span>, then you know <span class="math inline">\(B^c\)</span>.</li>
<li>However, it is <strong>not a transitive relationship</strong>, i.e. <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span> and <span class="math inline">\(B\)</span> is independent of <span class="math inline">\(C\)</span> does not imply that <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(C\)</span>.</li>
</ul>
</section>
<section class="level3" id="example-2.7.">
<h3 class="anchored" data-anchor-id="example-2.7.">Example 2.7.</h3>
<p>A counterexample: in the six-sided die example <span class="math inline">\(S = \lbrace 1, 2, 3, 4, 5, 6 \rbrace\)</span>, take <span class="math inline">\(A = \lbrace 2, 4, 6 \rbrace\)</span>, <span class="math inline">\(B = \lbrace 1, 2, 3, 4 \rbrace\)</span>, and <span class="math inline">\(C = \lbrace 1, 3, 5 \rbrace\)</span>.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><span class="math inline">\(P(A) = \dfrac{3}{6} = \dfrac{1}{2}\)</span></li>
<li><span class="math inline">\(P(B) = \dfrac{4}{6} = \dfrac{2}{3}\)</span></li>
<li><span class="math inline">\(P(C) = \dfrac{3}{6} = \dfrac{1}{2}\)</span></li>
<li><span class="math inline">\(P(A \cap B) = \dfrac{2}{6} = \dfrac{1}{3}\)</span></li>
<li><span class="math inline">\(P(A \cap C) = 0\)</span></li>
<li><span class="math inline">\(P(B \cap C) = \dfrac{2}{6} = \dfrac{1}{3}\)</span></li>
<li><span class="math inline">\(P(A)P(B) = \left( \dfrac{1}{2} \right) \left( \dfrac{2}{3} \right) = \dfrac{1}{3} = P(A \cap B)\)</span></li>
<li><span class="math inline">\(P(A)P(C) = \left( \dfrac{1}{2} \right) \left( \dfrac{1}{2} \right) = \dfrac{1}{4} \neq P(A \cap C)\)</span></li>
<li><span class="math inline">\(P(B)P(C) = \left( \dfrac{2}{3} \right) \left( \dfrac{1}{2} \right) = \dfrac{1}{3} = P(B \cap C)\)</span></li>
</ul>
<p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent. <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are independent. <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span> are not independent. This is an example where independence is not transitive.</p>
<p><strong>Independence</strong> is an important property that is often assumed in applications. For example:</p>
<ol type="a">
<li><p>Stock returns are independent from day to day;</p></li>
<li><p>Different household spending decisions are independent of each other;</p></li>
<li><p>Legal cases such as Sally Clark/Roy Meadow. Expert Meadow testified that the odds against two cot deaths occurring in the same family was 73,000,000:1, a figure which he obtained by squaring the observed ratio of live-births to cot deaths in affluent non-smoking families (approximately 8,500:1), which would be valid under independence of these two events. He testified under oath that: “one sudden infant death in a family is a tragedy, two is suspicious and three is murder unless proven otherwise” (Meadow’s law). See Dawid (2002) expert witness statement in the retrial.</p></li>
</ol>
<p>Although independence is a central case, in practice dependence is common in many settings. One can measure the amount of dependence and its direction (positive or negative) between two events in several ways:</p>
<p><span class="math inline">\(\alpha(A, B) = P(A \cap B) - P(A) \cdot P(B)\)</span></p>
<p><span class="math inline">\(\beta(A, B) = P(A|B) - P(A) = \dfrac{P(A \cap B)}{P(B)} - P(A)\)</span></p>
<p><span class="math inline">\(\gamma(A, B) = \dfrac{P(A \cap B)}{P(A)P(B)} - 1\)</span></p>
<p>where <span class="math inline">\(\alpha, \beta, \gamma\)</span> can be positive or negative indicating the direction of the mutual dependence. For example, if <span class="math inline">\(\beta &gt; 0\)</span> this means that event <span class="math inline">\(A\)</span> is more likely to occur when <span class="math inline">\(B\)</span> has occurred than when we don’t know whether <span class="math inline">\(B\)</span> has occurred or not. We may show that <span class="math inline">\(\alpha \in [-1, 1/4], \beta \in [-1, 1]\)</span>, and <span class="math inline">\(\gamma \in \mathbb{R}\)</span>. These measures allow us to rank cases according to the degree of dependence. Suppose that <span class="math inline">\(A \subseteq B\)</span>, then clearly, knowing <span class="math inline">\(B\)</span> gives us some information about whether <span class="math inline">\(A\)</span> has occurred whenever <span class="math inline">\(B\)</span> is a strict subset of <span class="math inline">\(S\)</span>. In this case</p>
<p><span class="math inline">\(\alpha(A, B) = P(A)(1 - P(B))\)</span></p>
<p><span class="math inline">\(\beta(A, B) = \dfrac{P(A)}{P(B)} - 1\)</span></p>
<p><span class="math inline">\(\gamma(A, B) = \dfrac{1}{P(B)} - 1\)</span>.</p>
</section>
<section class="level3" id="example-2.8.">
<h3 class="anchored" data-anchor-id="example-2.8.">Example 2.8.</h3>
<p>In the stock example, we have very mild negative dependence with:</p>
<p><span class="math inline">\(\alpha(A, B) = 0.53 - 0.78 \times 0.68 = -0.0004\)</span></p>
<p><span class="math inline">\(\beta(A, B) = -0.000588\)</span></p>
<p><span class="math inline">\(\gamma(A, B) = -0.000754\)</span>.</p>
<p><strong>Solution:</strong></p>
<p>From Example 2.3, we have <span class="math inline">\(P(A \cap B) = 0.53\)</span>, <span class="math inline">\(P(A) = 0.78\)</span>, and <span class="math inline">\(P(B) = 0.68\)</span>. Using the formulas above:</p>
<p><span class="math inline">\(\alpha(A, B) = P(A \cap B) - P(A)P(B) = 0.53 - (0.78)(0.68) = 0.53 - 0.5304 = -0.0004\)</span></p>
<p><span class="math inline">\(\beta(A, B) = \dfrac{P(A \cap B)}{P(B)} - P(A) = \dfrac{0.53}{0.68} - 0.78 \approx 0.7794 - 0.78 = -0.000588\)</span></p>
<p><span class="math inline">\(\gamma(A, B) = \dfrac{P(A \cap B)}{P(A)P(B)} - 1 = \dfrac{0.53}{(0.78)(0.68)} - 1 \approx 0.9992 - 1 = -0.000754\)</span></p>
</section>
<section class="level3" id="example-2.9.">
<h3 class="anchored" data-anchor-id="example-2.9.">Example 2.9.</h3>
<p>An example of conditional probability and independence. Suppose you deal two cards without replacement.</p>
<p><span class="math inline">\(A = \left \{ \begin{matrix} \text{first card} \\ \text{is Ace} \end{matrix} \right \}\)</span>, <span class="math inline">\(B = \left \{ \begin{matrix} \text{second card} \\ \text{is King} \end{matrix} \right \}\)</span>, <span class="math inline">\(C = \left \{ \begin{matrix} \text{first card} \\ \text{is King} \end{matrix} \right \}\)</span>.</p>
<p>We have</p>
<p><span class="math inline">\(P(A) = 4/52, P(B|A) = 4/51\)</span></p>
<p><span class="math inline">\(P(B) = P(B|C) \cdot P(C) + P(B|C^c)P(C^c)\)</span>.</p>
<p>Furthermore, <span class="math inline">\(P(C) = 4/52\)</span>, <span class="math inline">\(P(C^c) = 48/52\)</span>, <span class="math inline">\(P(B|C) = 3/51\)</span>, <span class="math inline">\(P(B|C^c) = 4/51\)</span>. This implies that</p>
<p><span class="math inline">\(P(B) = \dfrac{3}{51} \cdot \dfrac{4}{52} + \dfrac{4}{51} \cdot \dfrac{48}{52} = \dfrac{12 + 192}{51 \cdot 52} = \dfrac{204}{51 \cdot 52} = \dfrac{4}{52} &lt; \dfrac{4}{51}\)</span>.</p>
<p>So <span class="math inline">\(P(B) &lt; P(B|A)\)</span>, i.e., <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not independent events. In this case <span class="math inline">\(\beta(A, B) = 1/51 &gt; 0\)</span> meaning there is positive dependence.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><span class="math inline">\(P(A) = \dfrac{4}{52}\)</span> (There are 4 Aces in a 52-card deck)</li>
<li><span class="math inline">\(P(B|A) = \dfrac{4}{51}\)</span> (Given the first card is an Ace, there are 4 Kings left among the remaining 51 cards)</li>
<li><span class="math inline">\(P(C) = \dfrac{4}{52}\)</span> (There are 4 Kings in a 52-card deck)</li>
<li><span class="math inline">\(P(C^c) = \dfrac{48}{52}\)</span> (There are 48 non-Kings in a 52-card deck)</li>
<li><span class="math inline">\(P(B|C) = \dfrac{3}{51}\)</span> (Given the first card is a King, there are 3 Kings left among the remaining 51 cards)</li>
<li><span class="math inline">\(P(B|C^c) = \dfrac{4}{51}\)</span> (Given the first card is not a King, there are 4 Kings left among the remaining 51 cards)</li>
<li><span class="math inline">\(P(B) = P(B|C)P(C) + P(B|C^c)P(C^c) = \left( \dfrac{3}{51} \right) \left( \dfrac{4}{52} \right) + \left( \dfrac{4}{51} \right) \left( \dfrac{48}{52} \right) = \dfrac{12 + 192}{51 \cdot 52} = \dfrac{204}{2652} = \dfrac{4}{52}\)</span></li>
<li><span class="math inline">\(P(A \cap B) = P(B|A)P(A) = \left( \dfrac{4}{51} \right) \left( \dfrac{4}{52} \right) = \dfrac{16}{2652}\)</span></li>
<li><span class="math inline">\(P(A)P(B) = \left( \dfrac{4}{52} \right) \left( \dfrac{4}{52} \right) = \dfrac{16}{2704}\)</span></li>
</ul>
<p>Since <span class="math inline">\(P(A \cap B) \neq P(A)P(B)\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not independent.</p>
<p><span class="math inline">\(\beta(A, B) = P(B|A) - P(B) = \dfrac{4}{51} - \dfrac{4}{52} = \dfrac{208 - 204}{51 \cdot 52} = \dfrac{4}{51 \cdot 52} = \dfrac{1}{13 \cdot 51} = \dfrac{1}{663} &gt; 0\)</span></p>
<p>We next consider the more general case with more than two events.</p>
</section>
<section class="level3" id="definition-2.3.">
<h3 class="anchored" data-anchor-id="definition-2.3.">Definition 2.3.</h3>
<p>A <strong>general definition of independence</strong>. Events <span class="math inline">\(A_1, \ldots, A_n\)</span> are said to be <strong>mutually independent</strong> if</p>
<p><span class="math inline">\(P \left( \bigcap_{j=1}^k A_{i_j} \right) = \prod_{j=1}^k P(A_{i_j})\)</span>, for all <span class="math inline">\(A_{i_1}, \ldots, A_{i_k}, k = 2, \ldots, n\)</span>.</p>
<p>For example, independence of events <span class="math inline">\(A, B, C\)</span> requires the following conditions to hold:</p>
<ol type="1">
<li><span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></li>
<li><span class="math inline">\(P(A \cap C) = P(A)P(C)\)</span></li>
<li><span class="math inline">\(P(B \cap C) = P(B)P(C)\)</span></li>
<li><span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span>.</li>
</ol>
</section>
<section class="level3" id="example-2.10.">
<h3 class="anchored" data-anchor-id="example-2.10.">Example 2.10.</h3>
<p>The <strong>infinite monkey theorem</strong> says that if one had an infinite number of monkeys randomly tapping on a keyboard, with probability one, at least one of them will produce the complete works of Shakespeare. If one has a finite set of characters on the typewriter <span class="math inline">\(K\)</span> and a finite length document <span class="math inline">\(n\)</span>, then the probability that any one monkey would type this document exactly is <span class="math inline">\(K^{-n}\)</span>. If there are 47 keys on the standard typewriter, and 884,421 words, so perhaps 5 million characters, in which case the probability is so low that a given monkey will produce the documents. Let <span class="math inline">\(A_i = \{\text{Monkey } i \text{ nails it} \}\)</span>. Then</p>
<p><span class="math inline">\(P(A_i) = K^{-n}\)</span>.</p>
<p>However, the probability that no monkeys would produce it is (assuming that the monkeys are mutually independent agents and don’t interfere with other monkeys)</p>
<p><span class="math inline">\(\lim_{M \rightarrow \infty} P \left( \bigcap_{i=1}^M A_i^c \right) = \lim_{M \rightarrow \infty} (1 - K^{-n})^M = 0\)</span>.</p>
<p>This can be strengthened to say that with probability one an infinite number of monkeys would produce the complete works of Shakespeare. Consider the sets <span class="math inline">\(B_1 = \{1, 2, \ldots, M \}\)</span>, <span class="math inline">\(B_2 = \{M+1, M+2, \ldots, 2M \}\)</span>, etc. There was an Arts council grant that was commissioned to investigate the infinite monkey theorem.</p>
<p>We give two further independence concepts.</p>
</section>
<section class="level3" id="definition-2.4.">
<h3 class="anchored" data-anchor-id="definition-2.4.">Definition 2.4.</h3>
<p><strong>Pairwise independence</strong>. Events <span class="math inline">\(A_1, \ldots, A_n\)</span> are said to be <strong>pairwise independent</strong> if for all <span class="math inline">\(A_i, A_j\)</span></p>
<p><span class="math inline">\(P(A_i \cap A_j) = P(A_i) \cdot P(A_j)\)</span>.</p>
<p>We can have pairwise independence but not independence, i.e., pairwise independence is the weaker property.</p>
</section>
<section class="level3" id="example-2.11.">
<h3 class="anchored" data-anchor-id="example-2.11.">Example 2.11.</h3>
<p>Suppose that <span class="math inline">\(S = \{1, 2, 3, 4 \}\)</span>, <span class="math inline">\(A = \{1, 2 \}\)</span>, <span class="math inline">\(B = \{1, 3 \}\)</span>, and <span class="math inline">\(C = \{1, 4 \}\)</span>. Then <span class="math inline">\(P(A \cap B \cap C) = 1/4\)</span> but <span class="math inline">\(P(A) = P(B) = P(C) = 1/2\)</span> and <span class="math inline">\(P(A \cap B) = P(A \cap C) = P(B \cap C) = 1/4\)</span>.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><span class="math inline">\(P(A \cap B \cap C) = \dfrac{1}{4}\)</span> (Only the outcome 1 is in all three sets)</li>
<li><span class="math inline">\(P(A) = \dfrac{2}{4} = \dfrac{1}{2}\)</span></li>
<li><span class="math inline">\(P(B) = \dfrac{2}{4} = \dfrac{1}{2}\)</span></li>
<li><span class="math inline">\(P(C) = \dfrac{2}{4} = \dfrac{1}{2}\)</span></li>
<li><span class="math inline">\(P(A \cap B) = \dfrac{1}{4}\)</span> (Only the outcome 1 is in both A and B)</li>
<li><span class="math inline">\(P(A \cap C) = \dfrac{1}{4}\)</span> (Only the outcome 1 is in both A and C)</li>
<li><span class="math inline">\(P(B \cap C) = \dfrac{1}{4}\)</span> (Only the outcome 1 is in both B and C)</li>
<li><span class="math inline">\(P(A)P(B)P(C) = \left( \dfrac{1}{2} \right) \left( \dfrac{1}{2} \right) \left( \dfrac{1}{2} \right) = \dfrac{1}{8} \neq P(A \cap B \cap C)\)</span></li>
</ul>
<p>Although the events are pairwise independent (e.g., <span class="math inline">\(P(A \cap B) = \dfrac{1}{4} = P(A)P(B)\)</span>), they are not mutually independent because <span class="math inline">\(P(A \cap B \cap C) \neq P(A)P(B)P(C)\)</span>.</p>
<p>There is a further concept of interest in many applications.</p>
</section>
<section class="level3" id="definition-2.5.">
<h3 class="anchored" data-anchor-id="definition-2.5.">Definition 2.5.</h3>
<p><strong>Conditional Independence</strong>. Suppose that <span class="math inline">\(P(A), P(B), P(C) &gt; 0\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent events given <span class="math inline">\(C\)</span> if either:</p>
<ol type="1">
<li><span class="math inline">\(P(A \cap B | C) = P(A|C)P(B|C)\)</span>;</li>
<li><span class="math inline">\(P(C)P(A \cap B \cap C) = P(A \cap C) \cdot P(B \cap C)\)</span>.</li>
</ol>
<p>Note that independence of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> does not imply conditional independence of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> given <span class="math inline">\(C\)</span>, and vice versa, conditional independence of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> given <span class="math inline">\(C\)</span> does not imply independence of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>Conditional independence means that two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if we restrict our attention to the outcomes where event <span class="math inline">\(C\)</span> has occurred. In other words, if we know that <span class="math inline">\(C\)</span> has occurred, then knowing whether <span class="math inline">\(A\)</span> occurred does not give us any additional information about whether <span class="math inline">\(B\)</span> occurred, and vice versa.</p>
</section>
<section class="level3" id="example-2.12.">
<h3 class="anchored" data-anchor-id="example-2.12.">Example 2.12.</h3>
<p>You toss two dice</p>
<p><span class="math inline">\(A = \left \{ \begin{matrix} \text{Your first die} \\ \text{is 6} \end{matrix} \right \}\)</span>, <span class="math inline">\(B = \left \{ \begin{matrix} \text{Your second die} \\ \text{is 6} \end{matrix} \right \}\)</span>, <span class="math inline">\(C = \left \{ \begin{matrix} \text{Both dice are} \\ \text{the same} \end{matrix} \right \}\)</span>.</p>
<p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> here are independent. However, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are conditionally dependent given <span class="math inline">\(C\)</span>, since if you know <span class="math inline">\(C\)</span> then your first die will tell you exactly what the other one is.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><span class="math inline">\(P(A) = \dfrac{1}{6}\)</span></li>
<li><span class="math inline">\(P(B) = \dfrac{1}{6}\)</span></li>
<li><span class="math inline">\(P(A \cap B) = \dfrac{1}{36}\)</span></li>
<li><span class="math inline">\(P(A)P(B) = \left( \dfrac{1}{6} \right) \left( \dfrac{1}{6} \right) = \dfrac{1}{36} = P(A \cap B)\)</span>, so <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent.</li>
<li><span class="math inline">\(P(C) = \dfrac{6}{36} = \dfrac{1}{6}\)</span> (There are 6 outcomes where both dice are the same: (1,1), (2,2), …, (6,6))</li>
<li><span class="math inline">\(P(A|C) = \dfrac{1}{6}\)</span> (If both dice are the same, there’s a 1/6 chance the first die is a 6)</li>
<li><span class="math inline">\(P(B|C) = \dfrac{1}{6}\)</span> (If both dice are the same, there’s a 1/6 chance the second die is a 6)</li>
<li><span class="math inline">\(P(A \cap B | C) = \dfrac{1}{6}\)</span> (If both dice are the same, there’s a 1/6 chance they are both 6)</li>
<li><span class="math inline">\(P(A|C)P(B|C) = \left( \dfrac{1}{6} \right) \left( \dfrac{1}{6} \right) = \dfrac{1}{36} \neq P(A \cap B | C)\)</span></li>
</ul>
<p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not conditionally independent given <span class="math inline">\(C\)</span>.</p>
<p>There are many examples where conditional independence holds but not independence. Likewise, the direction of dependence or association can change depending on whether you are in the conditional distribution or unconditional. This is called <strong>Simpson’s Paradox</strong>: the reversal of the direction of an association when data from several groups are combined (aggregated) to form a single group. That is, we may have <span class="math inline">\(Pr(A|B) &gt; Pr(A|B^c)\)</span> but both <span class="math inline">\(Pr(A|B, C) &lt; Pr(A|B^c, C)\)</span> and <span class="math inline">\(Pr(A|B, C^c) &lt; Pr(A|B^c, C^c)\)</span> for events <span class="math inline">\(A, B, C\)</span>.</p>
</section>
<section class="level3" id="example-2.13.">
<h3 class="anchored" data-anchor-id="example-2.13.">Example 2.13.</h3>
<p>A common application of conditional independence is in time series. We have a sequence of outcomes on the stock market observed over time, either up or down. Each outcome is random at time <span class="math inline">\(t\)</span>, and there is a probability <span class="math inline">\(p_t\)</span> of an Up and <span class="math inline">\(1 - p_t\)</span> of a Down and this probability may depend on past outcomes. We assume that only what happens yesterday is relevant for today, i.e., the future is independent of the past given the present</p>
<p><span class="math inline">\(P(\text{Outcome}_t | \text{Outcome}_{t-1} \cap \ldots \cap \text{Outcome}_{-\infty}) = P(\text{Outcome}_t | \text{Outcome}_{t-1})\)</span>.</p>
<p>This is called a <strong>Markov Chain</strong>. A special case of this is when <span class="math inline">\(p_t\)</span> is time invariant as in our next example.</p>
</section>
<section class="level3" id="example-2.14.">
<h3 class="anchored" data-anchor-id="example-2.14.">Example 2.14.</h3>
<p><strong>Gambler’s ruin</strong>. Each period there is a probability <span class="math inline">\(p\)</span> of an up and probability <span class="math inline">\(1-p\)</span> of a down, and this does not depend on past outcomes. Suppose that you have $1 and take $1 positions in the stock market indefinitely [when the market is up, you gain $1, and when it is down you lose $1], or until you become bankrupt. What is the probability you become bankrupt? You can write out a table showing all the possible paths you can take to the destination $0. An important thing to note in this problem is the symmetry. Let <span class="math inline">\(P_{j,k}\)</span> be the probability of going from $j to $k. Clearly, <span class="math inline">\(P_{j+l, k+l}\)</span> for any <span class="math inline">\(l\)</span>, i.e., just adding $l to your total doesn’t change anything real. Now note that</p>
<p><span class="math inline">\(P_{1,0} = 1 - p + p P_{2,0}\)</span>.</p>
<p>Furthermore, <span class="math inline">\(P_{2,1} = P_{1,0}\)</span> and so <span class="math inline">\(P_{2,0} = P_{2,1} P_{1,0} = P_{1,0}^2\)</span>. Therefore, we have a quadratic equation</p>
<p><span class="math inline">\(P_{1,0} = 1 - p + p P_{1,0}^2\)</span>,</p>
<p>which has solutions</p>
<p><span class="math inline">\(P_{1,0} = 1 \text{ ; } P_{1,0} = \dfrac{1-p}{p}\)</span>.</p>
<p>The first solution is relevant when <span class="math inline">\(p \leq 1/2\)</span>, while the second is relevant otherwise. This says that for example even if you have a fifty fifty chance of success, you will become bankrupt with probability one. This shows the advantage of the principle “quit while you are ahead”.</p>
<p><strong>Solution:</strong></p>
<p>Let <span class="math inline">\(x = P_{1,0}\)</span> be the probability of ruin starting with $1.</p>
<p>From the given equation, <span class="math inline">\(P_{1,0} = 1 - p + pP_{2,0}\)</span>. Since <span class="math inline">\(P_{2,0}\)</span> is the probability of ruin starting with $2, and the problem is symmetric, we can express <span class="math inline">\(P_{2,0}\)</span> in terms of <span class="math inline">\(P_{1,0}\)</span>. Specifically, to reach ruin from $2, you need to lose twice in a row, each with probability <span class="math inline">\(P_{1,0}\)</span>. So, <span class="math inline">\(P_{2,0} = P_{1,0} \cdot P_{1,0} = P_{1,0}^2\)</span>.</p>
<p>Substituting into the equation, we get:</p>
<p><span class="math inline">\(x = 1 - p + px^2\)</span></p>
<p>Rearranging, we get a quadratic equation:</p>
<p><span class="math inline">\(px^2 - x + (1 - p) = 0\)</span></p>
<p>Using the quadratic formula to solve for <span class="math inline">\(x\)</span>:</p>
<p><span class="math inline">\(x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a}\)</span></p>
<p>where <span class="math inline">\(a = p\)</span>, <span class="math inline">\(b = -1\)</span>, and <span class="math inline">\(c = 1 - p\)</span>. Plugging in these values:</p>
<p><span class="math inline">\(x = \dfrac{1 \pm \sqrt{(-1)^2 - 4(p)(1-p)}}{2p} = \dfrac{1 \pm \sqrt{1 - 4p + 4p^2}}{2p} = \dfrac{1 \pm \sqrt{(1 - 2p)^2}}{2p} = \dfrac{1 \pm (1 - 2p)}{2p}\)</span>.</p>
<p>This gives us two possible solutions:</p>
<p><span class="math inline">\(x = \dfrac{1 + (1 - 2p)}{2p} = \dfrac{2 - 2p}{2p} = \dfrac{1 - p}{p}\)</span></p>
<p><span class="math inline">\(x = \dfrac{1 - (1 - 2p)}{2p} = \dfrac{2p}{2p} = 1\)</span></p>
<p>Therefore, the two solutions are <span class="math inline">\(P_{1,0} = 1\)</span> and <span class="math inline">\(P_{1,0} = \dfrac{1-p}{p}\)</span>.</p>
<p>Final Answer: The probability of becoming bankrupt starting with $1 is <span class="math inline">\(P_{1,0} = 1\)</span> if <span class="math inline">\(p \leq 1/2\)</span> and <span class="math inline">\(P_{1,0} = \dfrac{1-p}{p}\)</span> if <span class="math inline">\(p &gt; 1/2\)</span>.</p>
</section>
</section>
<section class="level2" id="exercises">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<section class="level3" id="sec-ch02exercise1">
<h3 class="anchored" data-anchor-id="sec-ch02exercise1">Exercise 1</h3>
<p><a href="#sec-ch02solution1">Solution 1</a></p>
<p>In a certain city, it rains 40% of the time. A company specializing in weather prediction forecasts rain 70% of the time when it actually rains, and they forecast rain 20% of the time when it doesn’t rain. Given that the company has forecasted rain, what is the probability that it will actually rain?</p>
</section>
<section class="level3" id="sec-ch02exercise2">
<h3 class="anchored" data-anchor-id="sec-ch02exercise2">Exercise 2</h3>
<p><a href="#sec-ch02solution2">Solution 2</a></p>
<p>Suppose we have two coins. One is fair (with probability of heads = 0.5), and the other is biased (with probability of heads = 0.75). We randomly choose one coin and flip it twice. If both flips result in heads, what is the probability that we chose the fair coin?</p>
</section>
<section class="level3" id="sec-ch02exercise3">
<h3 class="anchored" data-anchor-id="sec-ch02exercise3">Exercise 3</h3>
<p><a href="#sec-ch02solution3">Solution 3</a></p>
<p>A factory has three machines, A, B, and C, producing bolts. Machine A produces 25% of the total bolts, Machine B produces 35%, and Machine C produces 40%. Of their respective outputs, 5%, 4%, and 2% of the bolts are defective. If a bolt is randomly selected and found to be defective, what is the probability it was produced by Machine B?</p>
</section>
<section class="level3" id="sec-ch02exercise4">
<h3 class="anchored" data-anchor-id="sec-ch02exercise4">Exercise 4</h3>
<p><a href="#sec-ch02solution4">Solution 4</a></p>
<p>Two events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, are such that <span class="math inline">\(P(A) = 0.6\)</span>, <span class="math inline">\(P(B) = 0.4\)</span>, and <span class="math inline">\(P(A \cap B) = 0.2\)</span>. Calculate <span class="math inline">\(P(A|B)\)</span> and <span class="math inline">\(P(B|A)\)</span>. Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> <strong>independent events</strong>? Explain your reasoning.</p>
</section>
<section class="level3" id="sec-ch02exercise5">
<h3 class="anchored" data-anchor-id="sec-ch02exercise5">Exercise 5</h3>
<p><a href="#sec-ch02solution5">Solution 5</a></p>
<p>A box contains 5 red balls and 3 green balls. Two balls are drawn without replacement. What is the probability that the second ball is green given that the first ball was red?</p>
</section>
<section class="level3" id="sec-ch02exercise6">
<h3 class="anchored" data-anchor-id="sec-ch02exercise6">Exercise 6</h3>
<p><a href="#sec-ch02solution6">Solution 6</a></p>
<p>Consider two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> such that <span class="math inline">\(P(A) = 1/3\)</span>, <span class="math inline">\(P(B) = 1/2\)</span>, and <span class="math inline">\(P(A \cup B) = 3/4\)</span>. Find <span class="math inline">\(P(A|B)\)</span>.</p>
</section>
<section class="level3" id="sec-ch02exercise7">
<h3 class="anchored" data-anchor-id="sec-ch02exercise7">Exercise 7</h3>
<p><a href="#sec-ch02solution7">Solution 7</a></p>
<p>A survey indicates that 80% of college students own a laptop, 60% own a smartphone, and 50% own both. What is the probability that a randomly selected college student who owns a smartphone also owns a laptop?</p>
</section>
<section class="level3" id="sec-ch02exercise8">
<h3 class="anchored" data-anchor-id="sec-ch02exercise8">Exercise 8</h3>
<p><a href="#sec-ch02solution8">Solution 8</a></p>
<p>In a game, you roll a fair six-sided die. Let <span class="math inline">\(A\)</span> be the event that you roll an even number, and <span class="math inline">\(B\)</span> be the event that you roll a number greater than 3. Calculate <span class="math inline">\(P(A|B)\)</span> and <span class="math inline">\(P(B|A)\)</span>. Are events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> <strong>independent</strong>?</p>
</section>
<section class="level3" id="sec-ch02exercise9">
<h3 class="anchored" data-anchor-id="sec-ch02exercise9">Exercise 9</h3>
<p><a href="#sec-ch02solution9">Solution 9</a></p>
<p>A diagnostic test for a certain disease is 95% accurate on those who have the disease (i.e., true positive rate) and 90% accurate on those who do not have the disease (i.e., true negative rate). If 2% of the population has the disease, what is the probability that a person has the disease given that they tested positive?</p>
</section>
<section class="level3" id="sec-ch02exercise10">
<h3 class="anchored" data-anchor-id="sec-ch02exercise10">Exercise 10</h3>
<p><a href="#sec-ch02solution10">Solution 10</a></p>
<p>A company produces light bulbs in two factories, A and B. Factory A produces 60% of the bulbs, and Factory B produces 40%. The probability that a bulb produced by Factory A is defective is 0.04, while for Factory B it is 0.02. If a randomly selected bulb is found to be defective, what is the probability it was produced by Factory A?</p>
</section>
<section class="level3" id="sec-ch02exercise11">
<h3 class="anchored" data-anchor-id="sec-ch02exercise11">Exercise 11</h3>
<p><a href="#sec-ch02solution11">Solution 11</a></p>
<p>Suppose <span class="math inline">\(P(A) = 0.4\)</span>, <span class="math inline">\(P(B) = 0.5\)</span>, and <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong>. Calculate <span class="math inline">\(P(A \cap B)\)</span>, <span class="math inline">\(P(A \cup B)\)</span>, and <span class="math inline">\(P(A|B)\)</span>.</p>
</section>
<section class="level3" id="sec-ch02exercise12">
<h3 class="anchored" data-anchor-id="sec-ch02exercise12">Exercise 12</h3>
<p><a href="#sec-ch02solution12">Solution 12</a></p>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be events with <span class="math inline">\(P(A) = 0.7\)</span>, <span class="math inline">\(P(B) = 0.3\)</span>, and <span class="math inline">\(P(A \cap B) = 0.2\)</span>. Calculate the <strong>measures of dependence</strong> <span class="math inline">\(\alpha(A, B)\)</span>, <span class="math inline">\(\beta(A, B)\)</span>, and <span class="math inline">\(\gamma(A, B)\)</span>. Interpret the results.</p>
</section>
<section class="level3" id="sec-ch02exercise13">
<h3 class="anchored" data-anchor-id="sec-ch02exercise13">Exercise 13</h3>
<p><a href="#sec-ch02solution13">Solution 13</a></p>
<p>Events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are such that <span class="math inline">\(P(A) = 0.5\)</span>, <span class="math inline">\(P(B) = 0.3\)</span>, and <span class="math inline">\(P(A \cup B) = 0.6\)</span>. Determine whether <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong>.</p>
</section>
<section class="level3" id="sec-ch02exercise14">
<h3 class="anchored" data-anchor-id="sec-ch02exercise14">Exercise 14</h3>
<p><a href="#sec-ch02solution14">Solution 14</a></p>
<p>A card is drawn randomly from a standard deck of 52 cards. Let <span class="math inline">\(A\)</span> be the event that the card is a heart, and <span class="math inline">\(B\)</span> be the event that the card is a face card (Jack, Queen, or King). Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> <strong>independent events</strong>? Justify your answer.</p>
</section>
<section class="level3" id="sec-ch02exercise15">
<h3 class="anchored" data-anchor-id="sec-ch02exercise15">Exercise 15</h3>
<p><a href="#sec-ch02solution15">Solution 15</a></p>
<p>Suppose 5% of men and 0.25% of women are color-blind. A person is chosen at random and is found to be color-blind. Assuming an equal number of men and women, what is the probability that the person is a man?</p>
</section>
<section class="level3" id="sec-ch02exercise16">
<h3 class="anchored" data-anchor-id="sec-ch02exercise16">Exercise 16</h3>
<p><a href="#sec-ch02solution16">Solution 16</a></p>
<p>Consider three events <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> such that <span class="math inline">\(P(A) = P(B) = P(C) = 1/4\)</span>, <span class="math inline">\(P(A \cap B) = P(A \cap C) = P(B \cap C) = 1/16\)</span>, and <span class="math inline">\(P(A \cap B \cap C) = 1/64\)</span>. Are <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> <strong>mutually independent</strong>?</p>
</section>
<section class="level3" id="sec-ch02exercise17">
<h3 class="anchored" data-anchor-id="sec-ch02exercise17">Exercise 17</h3>
<p><a href="#sec-ch02solution17">Solution 17</a></p>
<p>In a group of students, 60% are studying Mathematics, 50% are studying Physics, and 30% are studying both. If a student is chosen at random and is found to be studying Mathematics, what is the probability that they are also studying Physics?</p>
</section>
<section class="level3" id="sec-ch02exercise18">
<h3 class="anchored" data-anchor-id="sec-ch02exercise18">Exercise 18</h3>
<p><a href="#sec-ch02solution18">Solution 18</a></p>
<p>A basketball player makes a free throw with a probability of 0.8. If the player makes a free throw, the probability of making the next one is 0.9. If the player misses, the probability of making the next one is 0.7. Given that the player made the first free throw, what is the probability that the player makes the second free throw? What concept does this illustrate?</p>
</section>
<section class="level3" id="sec-ch02exercise19">
<h3 class="anchored" data-anchor-id="sec-ch02exercise19">Exercise 19</h3>
<p><a href="#sec-ch02solution19">Solution 19</a></p>
<p>A box contains 4 red balls and 6 blue balls. Two balls are drawn sequentially without replacement. What is the probability that both balls are blue?</p>
</section>
<section class="level3" id="sec-ch02exercise20">
<h3 class="anchored" data-anchor-id="sec-ch02exercise20">Exercise 20</h3>
<p><a href="#sec-ch02solution20">Solution 20</a></p>
<p>A screening test for a rare disease has a sensitivity of 99% (true positive rate) and a specificity of 98% (true negative rate). The disease prevalence in the population is 1 in 10,000. If a person tests positive, what is the probability that they actually have the disease?</p>
</section>
</section>
<section class="level2" id="solutions">
<h2 class="anchored" data-anchor-id="solutions">Solutions</h2>
<section class="level3" id="sec-ch02solution1">
<h3 class="anchored" data-anchor-id="sec-ch02solution1">Solution 1</h3>
<p><a href="#sec-ch02exercise1">Exercise 1</a></p>
<p>Let <span class="math inline">\(R\)</span> be the event that it actually rains, and let <span class="math inline">\(F\)</span> be the event that the company forecasts rain. We are given the following probabilities:</p>
<ul>
<li><span class="math inline">\(P(R) = 0.4\)</span> (It rains 40% of the time)</li>
<li><span class="math inline">\(P(R^c) = 1 - P(R) = 1 - 0.4 = 0.6\)</span> (It does not rain 60% of the time)</li>
<li><span class="math inline">\(P(F|R) = 0.7\)</span> (The company forecasts rain 70% of the time when it actually rains)</li>
<li><span class="math inline">\(P(F|R^c) = 0.2\)</span> (The company forecasts rain 20% of the time when it doesn’t rain)</li>
</ul>
<p>We want to find <span class="math inline">\(P(R|F)\)</span>, the probability that it actually rains given that the company has forecasted rain. We can use <strong>Bayes’ Theorem</strong> (Theorem 2.2) to solve this:</p>
<p><span class="math inline">\(P(R|F) = \dfrac{P(F|R)P(R)}{P(F)}\)</span>.</p>
<p>First, we need to find <span class="math inline">\(P(F)\)</span>, the probability that the company forecasts rain. We can use the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(P(F) = P(F|R)P(R) + P(F|R^c)P(R^c) = (0.7)(0.4) + (0.2)(0.6) = 0.28 + 0.12 = 0.4\)</span>.</p>
<p>Now we can plug the values into Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(R|F) &amp;= \dfrac{P(F|R)P(R)}{P(F)} \\
&amp;= \dfrac{(0.7)(0.4)}{0.4} \\
&amp;= \dfrac{0.28}{0.4} \\
&amp;= 0.7
\end{aligned}\)</span></p>
<p>So, given that the company has forecasted rain, the probability that it will actually rain is 0.7.</p>
<p>In this solution, we used the definition of <strong>conditional probability</strong> to set up the problem. We applied <strong>Bayes’ Theorem</strong> to calculate the conditional probability of interest. We also used the <strong>Law of Total Probability</strong> to find the denominator in Bayes’ Theorem.</p>
</section>
<section class="level3" id="sec-ch02solution2">
<h3 class="anchored" data-anchor-id="sec-ch02solution2">Solution 2</h3>
<p><a href="#sec-ch02exercise2">Exercise 2</a></p>
<p>Let <span class="math inline">\(F\)</span> be the event that we choose the fair coin, and <span class="math inline">\(B\)</span> be the event that we choose the biased coin. Let <span class="math inline">\(HH\)</span> be the event that we get two heads in a row. We are given:</p>
<ul>
<li><span class="math inline">\(P(F) = P(B) = 0.5\)</span> (We randomly choose one coin)</li>
<li><span class="math inline">\(P(H|F) = 0.5\)</span> (Fair coin has a 0.5 probability of heads)</li>
<li><span class="math inline">\(P(H|B) = 0.75\)</span> (Biased coin has a 0.75 probability of heads)</li>
</ul>
<p>We want to find <span class="math inline">\(P(F|HH)\)</span>, the probability that we chose the fair coin given that we got two heads.</p>
<p>Since the coin flips are <strong>independent</strong> given the type of coin, we have <span class="math inline">\(P(HH|F) = P(H|F) \cdot P(H|F) = 0.5 \cdot 0.5 = 0.25\)</span>, and <span class="math inline">\(P(HH|B) = P(H|B) \cdot P(H|B) = 0.75 \cdot 0.75 = 0.5625\)</span>.</p>
<p>We can use <strong>Bayes’ Theorem</strong> here:</p>
<p><span class="math inline">\(P(F|HH) = \dfrac{P(HH|F)P(F)}{P(HH)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(HH)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(HH) &amp;= P(HH|F)P(F) + P(HH|B)P(B) \\
&amp;= (0.25)(0.5) + (0.5625)(0.5) \\
&amp;= 0.125 + 0.28125 \\
&amp;= 0.40625
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(F|HH) &amp;= \dfrac{P(HH|F)P(F)}{P(HH)} \\
&amp;= \dfrac{(0.25)(0.5)}{0.40625} \\
&amp;= \dfrac{0.125}{0.40625} \\
&amp;\approx 0.3077
\end{aligned}\)</span>.</p>
<p>So, the probability that we chose the fair coin given that we got two heads is approximately 0.3077.</p>
<p>This solution uses the concept of <strong>independence</strong> to calculate the probability of two heads given the type of coin. It applies <strong>Bayes’ Theorem</strong> to find the desired conditional probability, and it uses the <strong>Law of Total Probability</strong> to find the denominator for Bayes’ Theorem.</p>
</section>
<section class="level3" id="sec-ch02solution3">
<h3 class="anchored" data-anchor-id="sec-ch02solution3">Solution 3</h3>
<p><a href="#sec-ch02exercise3">Exercise 3</a></p>
<p>Let <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> be the events that a bolt is produced by Machine A, Machine B, and Machine C, respectively. Let <span class="math inline">\(D\)</span> be the event that a bolt is defective. We are given:</p>
<ul>
<li><span class="math inline">\(P(A) = 0.25\)</span></li>
<li><span class="math inline">\(P(B) = 0.35\)</span></li>
<li><span class="math inline">\(P(C) = 0.40\)</span></li>
<li><span class="math inline">\(P(D|A) = 0.05\)</span></li>
<li><span class="math inline">\(P(D|B) = 0.04\)</span></li>
<li><span class="math inline">\(P(D|C) = 0.02\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(B|D)\)</span>, the probability that a defective bolt was produced by Machine B. We can use <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(B|D) = \dfrac{P(D|B)P(B)}{P(D)}\)</span>.</p>
<p>First, we need to find <span class="math inline">\(P(D)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(D) &amp;= P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C) \\
&amp;= (0.05)(0.25) + (0.04)(0.35) + (0.02)(0.40) \\
&amp;= 0.0125 + 0.014 + 0.008 \\
&amp;= 0.0345
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(B|D) &amp;= \dfrac{P(D|B)P(B)}{P(D)} \\
&amp;= \dfrac{(0.04)(0.35)}{0.0345} \\
&amp;= \dfrac{0.014}{0.0345} \\
&amp;\approx 0.4058
\end{aligned}\)</span>.</p>
<p>So, the probability that a defective bolt was produced by Machine B is approximately 0.4058.</p>
<p>This solution uses the definition of <strong>conditional probability</strong> to interpret the given information. It applies <strong>Bayes’ Theorem</strong> to find the desired conditional probability, and it uses the <strong>Law of Total Probability</strong> to calculate the denominator for Bayes’ Theorem.</p>
</section>
<section class="level3" id="sec-ch02solution4">
<h3 class="anchored" data-anchor-id="sec-ch02solution4">Solution 4</h3>
<p><a href="#sec-ch02exercise4">Exercise 4</a></p>
<p>We are given <span class="math inline">\(P(A) = 0.6\)</span>, <span class="math inline">\(P(B) = 0.4\)</span>, and <span class="math inline">\(P(A \cap B) = 0.2\)</span>.</p>
<p>We can calculate <span class="math inline">\(P(A|B)\)</span> using the definition of <strong>conditional probability</strong> (Definition 2.1):</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{0.2}{0.4} = 0.5\)</span>.</p>
<p>Similarly, we can calculate <span class="math inline">\(P(B|A)\)</span>:</p>
<p><span class="math inline">\(P(B|A) = \dfrac{P(A \cap B)}{P(A)} = \dfrac{0.2}{0.6} = \dfrac{1}{3}\)</span>.</p>
<p>To determine if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong>, we can check if <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span> (Definition 2.2).</p>
<p><span class="math inline">\(P(A)P(B) = (0.6)(0.4) = 0.24\)</span>.</p>
<p>Since <span class="math inline">\(P(A \cap B) = 0.2 \neq 0.24 = P(A)P(B)\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>not independent events</strong>.</p>
<p>This solution directly applies the definition of <strong>conditional probability</strong> and the definition of <strong>independence</strong> to solve the problem.</p>
</section>
<section class="level3" id="sec-ch02solution5">
<h3 class="anchored" data-anchor-id="sec-ch02solution5">Solution 5</h3>
<p><a href="#sec-ch02exercise5">Exercise 5</a></p>
<p>Let <span class="math inline">\(R_1\)</span> be the event that the first ball drawn is red, and <span class="math inline">\(G_2\)</span> be the event that the second ball drawn is green. We want to find <span class="math inline">\(P(G_2|R_1)\)</span>.</p>
<p>Initially, there are 5 red balls and 3 green balls, making a total of 8 balls.</p>
<p>Since the first ball drawn is red and not replaced, we are left with 4 red balls and 3 green balls, making a total of 7 balls.</p>
<p>Using the definition of <strong>conditional probability</strong>, we have:</p>
<p><span class="math inline">\(P(G_2|R_1) = \dfrac{P(G_2 \cap R_1)}{P(R_1)}\)</span>.</p>
<p>However, we can also directly calculate <span class="math inline">\(P(G_2|R_1)\)</span> by considering the state of the box after the first red ball is drawn.</p>
<p><span class="math inline">\(P(G_2|R_1) = \dfrac{\text{Number of green balls remaining}}{\text{Total number of balls remaining}} = \dfrac{3}{7}\)</span>.</p>
<p>So the probability that the second ball is green given that the first ball was red is <span class="math inline">\(\dfrac{3}{7}\)</span>.</p>
<p>In this solution we used the definition of <strong>conditional probability</strong>. We also used the fact that when sampling <strong>without replacement</strong>, the probabilities change in subsequent draws.</p>
</section>
<section class="level3" id="sec-ch02solution6">
<h3 class="anchored" data-anchor-id="sec-ch02solution6">Solution 6</h3>
<p><a href="#sec-ch02exercise6">Exercise 6</a></p>
<p>We are given <span class="math inline">\(P(A) = 1/3\)</span>, <span class="math inline">\(P(B) = 1/2\)</span>, and <span class="math inline">\(P(A \cup B) = 3/4\)</span>. We want to find <span class="math inline">\(P(A|B)\)</span>.</p>
<p>From the formula for the probability of the union of two events, we have:</p>
<p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>.</p>
<p>We can rearrange this to find <span class="math inline">\(P(A \cap B)\)</span>:</p>
<p><span class="math inline">\(\begin{aligned}
P(A \cap B) &amp;= P(A) + P(B) - P(A \cup B) \\
&amp;= \dfrac{1}{3} + \dfrac{1}{2} - \dfrac{3}{4} \\
&amp;= \dfrac{4}{12} + \dfrac{6}{12} - \dfrac{9}{12} \\
&amp;= \dfrac{1}{12}
\end{aligned}\)</span>.</p>
<p>Now we can use the definition of <strong>conditional probability</strong> to find <span class="math inline">\(P(A|B)\)</span>:</p>
<p><span class="math inline">\(\begin{aligned}
P(A|B) &amp;= \dfrac{P(A \cap B)}{P(B)} \\
&amp;= \dfrac{1/12}{1/2} \\
&amp;= \dfrac{1}{12} \cdot \dfrac{2}{1} \\
&amp;= \dfrac{1}{6}
\end{aligned}\)</span>.</p>
<p>This solution uses the formula for the probability of the <strong>union</strong> of two events to find the intersection, and then applies the definition of <strong>conditional probability</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution7">
<h3 class="anchored" data-anchor-id="sec-ch02solution7">Solution 7</h3>
<p><a href="#sec-ch02exercise7">Exercise 7</a></p>
<p>Let <span class="math inline">\(L\)</span> be the event that a student owns a laptop, and <span class="math inline">\(S\)</span> be the event that a student owns a smartphone. We are given:</p>
<ul>
<li><span class="math inline">\(P(L) = 0.8\)</span></li>
<li><span class="math inline">\(P(S) = 0.6\)</span></li>
<li><span class="math inline">\(P(L \cap S) = 0.5\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(L|S)\)</span>, the probability that a student owns a laptop given that they own a smartphone. Using the definition of <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(L|S) &amp;= \dfrac{P(L \cap S)}{P(S)} \\
&amp;= \dfrac{0.5}{0.6} \\
&amp;= \dfrac{5}{6}
\end{aligned}\)</span>.</p>
<p>So, the probability that a randomly selected college student who owns a smartphone also owns a laptop is <span class="math inline">\(\dfrac{5}{6}\)</span>.</p>
<p>This solution is a direct application of the definition of <strong>conditional probability</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution8">
<h3 class="anchored" data-anchor-id="sec-ch02solution8">Solution 8</h3>
<p><a href="#sec-ch02exercise8">Exercise 8</a></p>
<p>Let <span class="math inline">\(A\)</span> be the event of rolling an even number, and <span class="math inline">\(B\)</span> be the event of rolling a number greater than 3. The possible outcomes are <span class="math inline">\(\{1, 2, 3, 4, 5, 6\}\)</span>.</p>
<ul>
<li><span class="math inline">\(A = \{2, 4, 6\}\)</span>, so <span class="math inline">\(P(A) = \dfrac{3}{6} = \dfrac{1}{2}\)</span>.</li>
<li><span class="math inline">\(B = \{4, 5, 6\}\)</span>, so <span class="math inline">\(P(B) = \dfrac{3}{6} = \dfrac{1}{2}\)</span>.</li>
<li><span class="math inline">\(A \cap B = \{4, 6\}\)</span>, so <span class="math inline">\(P(A \cap B) = \dfrac{2}{6} = \dfrac{1}{3}\)</span>.</li>
</ul>
<p>Now we can calculate the conditional probabilities:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{1/3}{1/2} = \dfrac{2}{3}\)</span>.</p>
<p><span class="math inline">\(P(B|A) = \dfrac{P(A \cap B)}{P(A)} = \dfrac{1/3}{1/2} = \dfrac{2}{3}\)</span>.</p>
<p>To check for <strong>independence</strong>, we compare <span class="math inline">\(P(A \cap B)\)</span> with <span class="math inline">\(P(A)P(B)\)</span>:</p>
<p><span class="math inline">\(P(A)P(B) = \left( \dfrac{1}{2} \right) \left( \dfrac{1}{2} \right) = \dfrac{1}{4}\)</span>.</p>
<p>Since <span class="math inline">\(P(A \cap B) = \dfrac{1}{3} \neq \dfrac{1}{4} = P(A)P(B)\)</span>, events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>not independent</strong>.</p>
<p>This solution applies the definitions of <strong>conditional probability</strong> and <strong>independence</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution9">
<h3 class="anchored" data-anchor-id="sec-ch02solution9">Solution 9</h3>
<p><a href="#sec-ch02exercise9">Exercise 9</a></p>
<p>Let <span class="math inline">\(D\)</span> be the event that a person has the disease, and <span class="math inline">\(T\)</span> be the event that a person tests positive. We are given:</p>
<ul>
<li><span class="math inline">\(P(D) = 0.02\)</span> (2% of the population has the disease)</li>
<li><span class="math inline">\(P(D^c) = 1 - P(D) = 0.98\)</span> (98% of the population does not have the disease)</li>
<li><span class="math inline">\(P(T|D) = 0.95\)</span> (True positive rate)</li>
<li><span class="math inline">\(P(T^c|D^c) = 0.90\)</span> (True negative rate)</li>
<li><span class="math inline">\(P(T|D^c) = 1 - P(T^c|D^c) = 1 - 0.90 = 0.10\)</span> (False positive rate)</li>
</ul>
<p>We want to find <span class="math inline">\(P(D|T)\)</span>. We can use <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(D|T) = \dfrac{P(T|D)P(D)}{P(T)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(T)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(T) &amp;= P(T|D)P(D) + P(T|D^c)P(D^c) \\
&amp;= (0.95)(0.02) + (0.10)(0.98) \\
&amp;= 0.019 + 0.098 \\
&amp;= 0.117
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(D|T) &amp;= \dfrac{P(T|D)P(D)}{P(T)} \\
&amp;= \dfrac{(0.95)(0.02)}{0.117} \\
&amp;= \dfrac{0.019}{0.117} \\
&amp;\approx 0.1624
\end{aligned}\)</span>.</p>
<p>So, the probability that a person has the disease given that they tested positive is approximately 0.1624.</p>
<p>This solution applies <strong>Bayes’ Theorem</strong> and the <strong>Law of Total Probability</strong> to find the desired conditional probability.</p>
</section>
<section class="level3" id="sec-ch02solution10">
<h3 class="anchored" data-anchor-id="sec-ch02solution10">Solution 10</h3>
<p><a href="#sec-ch02exercise10">Exercise 10</a></p>
<p>Let <span class="math inline">\(A\)</span> be the event that a bulb is produced by Factory A, <span class="math inline">\(B\)</span> be the event that a bulb is produced by Factory B, and <span class="math inline">\(D\)</span> be the event that a bulb is defective. We are given:</p>
<ul>
<li><span class="math inline">\(P(A) = 0.6\)</span></li>
<li><span class="math inline">\(P(B) = 0.4\)</span></li>
<li><span class="math inline">\(P(D|A) = 0.04\)</span></li>
<li><span class="math inline">\(P(D|B) = 0.02\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(A|D)\)</span>. We can use <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(A|D) = \dfrac{P(D|A)P(A)}{P(D)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(D)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(D) &amp;= P(D|A)P(A) + P(D|B)P(B) \\
&amp;= (0.04)(0.6) + (0.02)(0.4) \\
&amp;= 0.024 + 0.008 \\
&amp;= 0.032
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(A|D) &amp;= \dfrac{P(D|A)P(A)}{P(D)} \\
&amp;= \dfrac{(0.04)(0.6)}{0.032} \\
&amp;= \dfrac{0.024}{0.032} \\
&amp;= 0.75
\end{aligned}\)</span>.</p>
<p>So, the probability that a defective bulb was produced by Factory A is 0.75.</p>
<p>This solution applies <strong>Bayes’ Theorem</strong> and the <strong>Law of Total Probability</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution11">
<h3 class="anchored" data-anchor-id="sec-ch02solution11">Solution 11</h3>
<p><a href="#sec-ch02exercise11">Exercise 11</a></p>
<p>We are given <span class="math inline">\(P(A) = 0.4\)</span>, <span class="math inline">\(P(B) = 0.5\)</span>, and <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong>.</p>
<p>Since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, we have <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span> (Definition 2.2):</p>
<p><span class="math inline">\(P(A \cap B) = (0.4)(0.5) = 0.2\)</span>.</p>
<p>We can find <span class="math inline">\(P(A \cup B)\)</span> using the formula for the probability of the union of two events:</p>
<p><span class="math inline">\(\begin{aligned}
P(A \cup B) &amp;= P(A) + P(B) - P(A \cap B) \\
&amp;= 0.4 + 0.5 - 0.2 \\
&amp;= 0.7
\end{aligned}\)</span>.</p>
<p>Since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, we also have <span class="math inline">\(P(A|B) = P(A)\)</span>:</p>
<p><span class="math inline">\(P(A|B) = P(A) = 0.4\)</span>.</p>
<p>This solution uses the definition of <strong>independence</strong> and the formula for the probability of the <strong>union</strong> of two events.</p>
</section>
<section class="level3" id="sec-ch02solution12">
<h3 class="anchored" data-anchor-id="sec-ch02solution12">Solution 12</h3>
<p><a href="#sec-ch02exercise12">Exercise 12</a></p>
<p>We are given <span class="math inline">\(P(A) = 0.7\)</span>, <span class="math inline">\(P(B) = 0.3\)</span>, and <span class="math inline">\(P(A \cap B) = 0.2\)</span>. We want to calculate the <strong>measures of dependence</strong> <span class="math inline">\(\alpha(A, B)\)</span>, <span class="math inline">\(\beta(A, B)\)</span>, and <span class="math inline">\(\gamma(A, B)\)</span>.</p>
<p><span class="math inline">\(\begin{aligned}
\alpha(A, B) &amp;= P(A \cap B) - P(A)P(B) \\
&amp;= 0.2 - (0.7)(0.3) \\
&amp;= 0.2 - 0.21 \\
&amp;= -0.01
\end{aligned}\)</span>.</p>
<p><span class="math inline">\(\begin{aligned}
\beta(A, B) &amp;= \dfrac{P(A \cap B)}{P(B)} - P(A) \\
&amp;= \dfrac{0.2}{0.3} - 0.7 \\
&amp;= \dfrac{2}{3} - \dfrac{7}{10} \\
&amp;= \dfrac{20}{30} - \dfrac{21}{30} \\
&amp;= -\dfrac{1}{30} \approx -0.0333
\end{aligned}\)</span>.</p>
<p><span class="math inline">\(\begin{aligned}
\gamma(A, B) &amp;= \dfrac{P(A \cap B)}{P(A)P(B)} - 1 \\
&amp;= \dfrac{0.2}{(0.7)(0.3)} - 1 \\
&amp;= \dfrac{0.2}{0.21} - 1 \\
&amp;= \dfrac{20}{21} - 1 \\
&amp;= -\dfrac{1}{21} \approx -0.0476
\end{aligned}\)</span>.</p>
<p>The negative values of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\gamma\)</span> indicate a <strong>mild negative dependence</strong> between events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. This means that the occurrence of one event slightly decreases the likelihood of the other event occurring.</p>
<p>This solution directly applies the formulas for the <strong>measures of dependence</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution13">
<h3 class="anchored" data-anchor-id="sec-ch02solution13">Solution 13</h3>
<p><a href="#sec-ch02exercise13">Exercise 13</a></p>
<p>We are given <span class="math inline">\(P(A) = 0.5\)</span>, <span class="math inline">\(P(B) = 0.3\)</span>, and <span class="math inline">\(P(A \cup B) = 0.6\)</span>. To determine if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong>, we need to check if <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span>.</p>
<p>First, we can find <span class="math inline">\(P(A \cap B)\)</span> using the formula for the probability of the union of two events:</p>
<p><span class="math inline">\(\begin{aligned}
P(A \cup B) &amp;= P(A) + P(B) - P(A \cap B) \\
0.6 &amp;= 0.5 + 0.3 - P(A \cap B) \\
P(A \cap B) &amp;= 0.5 + 0.3 - 0.6 \\
P(A \cap B) &amp;= 0.2
\end{aligned}\)</span>.</p>
<p>Now, we calculate <span class="math inline">\(P(A)P(B)\)</span>:</p>
<p><span class="math inline">\(P(A)P(B) = (0.5)(0.3) = 0.15\)</span>.</p>
<p>Since <span class="math inline">\(P(A \cap B) = 0.2 \neq 0.15 = P(A)P(B)\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>not independent</strong>.</p>
<p>This solution uses the formula for the probability of the <strong>union</strong> of two events and the definition of <strong>independence</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution14">
<h3 class="anchored" data-anchor-id="sec-ch02solution14">Solution 14</h3>
<p><a href="#sec-ch02exercise14">Exercise 14</a></p>
<p>Let <span class="math inline">\(A\)</span> be the event that the card is a heart, and <span class="math inline">\(B\)</span> be the event that the card is a face card (Jack, Queen, or King). There are 52 cards in a standard deck.</p>
<ul>
<li>There are 13 hearts, so <span class="math inline">\(P(A) = \dfrac{13}{52} = \dfrac{1}{4}\)</span>.</li>
<li>There are 12 face cards (3 in each of the 4 suits), so <span class="math inline">\(P(B) = \dfrac{12}{52} = \dfrac{3}{13}\)</span>.</li>
<li>There are 3 face cards that are also hearts (Jack, Queen, and King of hearts), so <span class="math inline">\(P(A \cap B) = \dfrac{3}{52}\)</span>.</li>
</ul>
<p>To check for <strong>independence</strong>, we compare <span class="math inline">\(P(A \cap B)\)</span> with <span class="math inline">\(P(A)P(B)\)</span>:</p>
<p><span class="math inline">\(P(A)P(B) = \left( \dfrac{1}{4} \right) \left( \dfrac{3}{13} \right) = \dfrac{3}{52}\)</span>.</p>
<p>Since <span class="math inline">\(P(A \cap B) = \dfrac{3}{52} = P(A)P(B)\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong>.</p>
<p>This solution applies the definition of <strong>independence</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution15">
<h3 class="anchored" data-anchor-id="sec-ch02solution15">Solution 15</h3>
<p><a href="#sec-ch02exercise15">Exercise 15</a></p>
<p>Let <span class="math inline">\(M\)</span> be the event that the person is a man, <span class="math inline">\(W\)</span> be the event that the person is a woman, and <span class="math inline">\(C\)</span> be the event that the person is color-blind. We are given:</p>
<ul>
<li><span class="math inline">\(P(C|M) = 0.05\)</span></li>
<li><span class="math inline">\(P(C|W) = 0.0025\)</span></li>
<li><span class="math inline">\(P(M) = P(W) = 0.5\)</span> (Assuming an equal number of men and women)</li>
</ul>
<p>We want to find <span class="math inline">\(P(M|C)\)</span>. We can use <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(M|C) = \dfrac{P(C|M)P(M)}{P(C)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(C)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(C) &amp;= P(C|M)P(M) + P(C|W)P(W) \\
&amp;= (0.05)(0.5) + (0.0025)(0.5) \\
&amp;= 0.025 + 0.00125 \\
&amp;= 0.02625
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(M|C) &amp;= \dfrac{P(C|M)P(M)}{P(C)} \\
&amp;= \dfrac{(0.05)(0.5)}{0.02625} \\
&amp;= \dfrac{0.025}{0.02625} \\
&amp;\approx 0.9524
\end{aligned}\)</span>.</p>
<p>So, the probability that the color-blind person is a man is approximately 0.9524.</p>
<p>This solution applies <strong>Bayes’ Theorem</strong> and the <strong>Law of Total Probability</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution16">
<h3 class="anchored" data-anchor-id="sec-ch02solution16">Solution 16</h3>
<p><a href="#sec-ch02exercise16">Exercise 16</a></p>
<p>We are given <span class="math inline">\(P(A) = P(B) = P(C) = 1/4\)</span>, <span class="math inline">\(P(A \cap B) = P(A \cap C) = P(B \cap C) = 1/16\)</span>, and <span class="math inline">\(P(A \cap B \cap C) = 1/64\)</span>.</p>
<p>To determine if <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are <strong>mutually independent</strong>, we need to check two conditions (Definition 2.3):</p>
<ol type="1">
<li><strong>Pairwise independence</strong>: <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span>, <span class="math inline">\(P(A \cap C) = P(A)P(C)\)</span>, and <span class="math inline">\(P(B \cap C) = P(B)P(C)\)</span>.</li>
<li><strong>Mutual independence</strong>: <span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span>.</li>
</ol>
<p>Let’s check the first condition:</p>
<ul>
<li><span class="math inline">\(P(A)P(B) = (1/4)(1/4) = 1/16 = P(A \cap B)\)</span></li>
<li><span class="math inline">\(P(A)P(C) = (1/4)(1/4) = 1/16 = P(A \cap C)\)</span></li>
<li><span class="math inline">\(P(B)P(C) = (1/4)(1/4) = 1/16 = P(B \cap C)\)</span></li>
</ul>
<p>So, the events are pairwise independent.</p>
<p>Now let’s check the second condition:</p>
<p><span class="math inline">\(P(A)P(B)P(C) = (1/4)(1/4)(1/4) = 1/64 = P(A \cap B \cap C)\)</span>.</p>
<p>Since both conditions are satisfied, <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are <strong>mutually independent</strong>.</p>
<p>This solution uses the definition of <strong>mutual independence</strong>, which includes <strong>pairwise independence</strong> as a component.</p>
</section>
<section class="level3" id="sec-ch02solution17">
<h3 class="anchored" data-anchor-id="sec-ch02solution17">Solution 17</h3>
<p><a href="#sec-ch02exercise17">Exercise 17</a></p>
<p>Let <span class="math inline">\(M\)</span> be the event that a student is studying Mathematics, and <span class="math inline">\(P\)</span> be the event that a student is studying Physics. We are given:</p>
<ul>
<li><span class="math inline">\(P(M) = 0.6\)</span></li>
<li><span class="math inline">\(P(P) = 0.5\)</span></li>
<li><span class="math inline">\(P(M \cap P) = 0.3\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(P|M)\)</span>, the probability that a student is studying Physics given that they are studying Mathematics. Using the definition of <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(P|M) &amp;= \dfrac{P(M \cap P)}{P(M)} \\
&amp;= \dfrac{0.3}{0.6} \\
&amp;= 0.5
\end{aligned}\)</span>.</p>
<p>So, the probability that a student is studying Physics given that they are studying Mathematics is 0.5.</p>
<p>This solution is a direct application of the definition of <strong>conditional probability</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution18">
<h3 class="anchored" data-anchor-id="sec-ch02solution18">Solution 18</h3>
<p><a href="#sec-ch02exercise18">Exercise 18</a></p>
<p>Let <span class="math inline">\(M_1\)</span> be the event that the player makes the first free throw, <span class="math inline">\(M_2\)</span> be the event that the player makes the second free throw, and <span class="math inline">\(M_1^c\)</span> be the event that the player misses the first free throw. We are given:</p>
<ul>
<li><span class="math inline">\(P(M_1) = 0.8\)</span> (Probability of making a free throw)</li>
<li><span class="math inline">\(P(M_1^c) = 1 - P(M_1) = 0.2\)</span></li>
<li><span class="math inline">\(P(M_2|M_1) = 0.9\)</span> (Probability of making the second given the first is made)</li>
<li><span class="math inline">\(P(M_2|M_1^c) = 0.7\)</span> (Probability of making the second given the first is missed)</li>
</ul>
<p>We want to find <span class="math inline">\(P(M_2|M_1)\)</span>. We are already given this value:</p>
<p><span class="math inline">\(P(M_2|M_1) = 0.9\)</span>.</p>
<p>This illustrates the concept of <strong>conditional probability</strong> where the outcome of one event affects the probability of another event. If we were asked to find the probability of making the second free throw <span class="math inline">\(P(M_2)\)</span> regardless of the outcome of the first, we would use the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(M_2) &amp;= P(M_2|M_1)P(M_1) + P(M_2|M_1^c)P(M_1^c) \\
&amp;= (0.9)(0.8) + (0.7)(0.2) \\
&amp;= 0.72 + 0.14 \\
&amp;= 0.86
\end{aligned}\)</span>.</p>
<p>The concept illustrated in this problem is how <strong>conditional probabilities</strong> can change depending on prior events. When <span class="math inline">\(P(M_2|M_1) \neq P(M_2|M_1^c)\)</span> as in this case, we say that the events <span class="math inline">\(M_2\)</span> and <span class="math inline">\(M_1\)</span> are <strong>not independent</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution19">
<h3 class="anchored" data-anchor-id="sec-ch02solution19">Solution 19</h3>
<p><a href="#sec-ch02exercise19">Exercise 19</a></p>
<p>Let <span class="math inline">\(B_1\)</span> be the event that the first ball drawn is blue, and <span class="math inline">\(B_2\)</span> be the event that the second ball drawn is blue. We want to find <span class="math inline">\(P(B_1 \cap B_2)\)</span>, the probability that both balls are blue.</p>
<p>Initially, there are 4 red balls and 6 blue balls, making a total of 10 balls.</p>
<p>We can use the formula for <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(P(B_1 \cap B_2) = P(B_2|B_1)P(B_1)\)</span>.</p>
<p>The probability of drawing a blue ball first is:</p>
<p><span class="math inline">\(P(B_1) = \dfrac{6}{10} = \dfrac{3}{5}\)</span>.</p>
<p>Given that the first ball drawn was blue, there are now 4 red balls and 5 blue balls remaining, making a total of 9 balls. So, the probability of drawing a second blue ball given that the first one was blue is:</p>
<p><span class="math inline">\(P(B_2|B_1) = \dfrac{5}{9}\)</span>.</p>
<p>Therefore, the probability that both balls are blue is:</p>
<p><span class="math inline">\(\begin{aligned}
P(B_1 \cap B_2) &amp;= P(B_2|B_1)P(B_1) \\
&amp;= \left( \dfrac{5}{9} \right) \left( \dfrac{3}{5} \right) \\
&amp;= \dfrac{15}{45} \\
&amp;= \dfrac{1}{3}
\end{aligned}\)</span>.</p>
<p>This solution applies the definition of <strong>conditional probability</strong> and considers the change in probabilities when sampling <strong>without replacement</strong>.</p>
</section>
<section class="level3" id="sec-ch02solution20">
<h3 class="anchored" data-anchor-id="sec-ch02solution20">Solution 20</h3>
<p><a href="#sec-ch02exercise20">Exercise 20</a></p>
<p>Let <span class="math inline">\(D\)</span> be the event that a person has the disease, and <span class="math inline">\(T\)</span> be the event that a person tests positive. We are given:</p>
<ul>
<li><span class="math inline">\(P(D) = 1/10000 = 0.0001\)</span> (Disease prevalence)</li>
<li><span class="math inline">\(P(D^c) = 1 - P(D) = 0.9999\)</span></li>
<li><span class="math inline">\(P(T|D) = 0.99\)</span> (Sensitivity or true positive rate)</li>
<li><span class="math inline">\(P(T^c|D^c) = 0.98\)</span> (Specificity or true negative rate)</li>
<li><span class="math inline">\(P(T|D^c) = 1 - P(T^c|D^c) = 1 - 0.98 = 0.02\)</span> (False positive rate)</li>
</ul>
<p>We want to find <span class="math inline">\(P(D|T)\)</span>, the probability that a person has the disease given that they tested positive. We can use <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(D|T) = \dfrac{P(T|D)P(D)}{P(T)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(T)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(T) &amp;= P(T|D)P(D) + P(T|D^c)P(D^c) \\
&amp;= (0.99)(0.0001) + (0.02)(0.9999) \\
&amp;= 0.000099 + 0.019998 \\
&amp;= 0.020097
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(D|T) &amp;= \dfrac{P(T|D)P(D)}{P(T)} \\
&amp;= \dfrac{(0.99)(0.0001)}{0.020097} \\
&amp;= \dfrac{0.000099}{0.020097} \\
&amp;\approx 0.004926
\end{aligned}\)</span>.</p>
<p>So, if a person tests positive, the probability that they actually have the disease is approximately 0.004926, or about 0.49%.</p>
<p>This solution applies <strong>Bayes’ Theorem</strong> and the <strong>Law of Total Probability</strong> to find the desired conditional probability. It highlights the importance of considering the <strong>base rate</strong> or <strong>prevalence</strong> of a disease when interpreting test results.</p>
</section>
</section>
<section class="level2" id="r-scripts">
<h2 class="anchored" data-anchor-id="r-scripts">R Scripts</h2>
<section class="level3" id="r-script-1-simulating-conditional-probability">
<h3 class="anchored" data-anchor-id="r-script-1-simulating-conditional-probability">R Script 1: Simulating Conditional Probability</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a aria-hidden="true" href="#cb1-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1-2"><a aria-hidden="true" href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a aria-hidden="true" href="#cb3-1" tabindex="-1"></a><span class="co"># Set the number of simulations</span></span>
<span id="cb3-2"><a aria-hidden="true" href="#cb3-2" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb3-3"><a aria-hidden="true" href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a aria-hidden="true" href="#cb3-4" tabindex="-1"></a><span class="co"># Simulate the rolling of two dice</span></span>
<span id="cb3-5"><a aria-hidden="true" href="#cb3-5" tabindex="-1"></a>die1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-6"><a aria-hidden="true" href="#cb3-6" tabindex="-1"></a>die2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-7"><a aria-hidden="true" href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a aria-hidden="true" href="#cb3-8" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb3-9"><a aria-hidden="true" href="#cb3-9" tabindex="-1"></a>dice_rolls <span class="ot">&lt;-</span> <span class="fu">tibble</span>(die1, die2)</span>
<span id="cb3-10"><a aria-hidden="true" href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a aria-hidden="true" href="#cb3-11" tabindex="-1"></a><span class="co"># Calculate the probability of rolling a sum of 7 given that the first die is a 3</span></span>
<span id="cb3-12"><a aria-hidden="true" href="#cb3-12" tabindex="-1"></a>conditional_prob <span class="ot">&lt;-</span> dice_rolls <span class="sc">%&gt;%</span></span>
<span id="cb3-13"><a aria-hidden="true" href="#cb3-13" tabindex="-1"></a>  <span class="fu">filter</span>(die1 <span class="sc">==</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span> <span class="co"># Restrict sample space to cases where die1 is 3</span></span>
<span id="cb3-14"><a aria-hidden="true" href="#cb3-14" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb3-15"><a aria-hidden="true" href="#cb3-15" tabindex="-1"></a>    <span class="at">prob_sum_7 =</span> <span class="fu">mean</span>(die1 <span class="sc">+</span> die2 <span class="sc">==</span> <span class="dv">7</span>) <span class="co"># Calculate the proportion of cases where the sum is 7</span></span>
<span id="cb3-16"><a aria-hidden="true" href="#cb3-16" tabindex="-1"></a>  )</span>
<span id="cb3-17"><a aria-hidden="true" href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a aria-hidden="true" href="#cb3-18" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb3-19"><a aria-hidden="true" href="#cb3-19" tabindex="-1"></a><span class="fu">print</span>(conditional_prob)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  prob_sum_7
       &lt;dbl&gt;
1      0.170</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Simulate Dice Rolls:</strong>
<ul>
<li>We simulate rolling two six-sided dice 10,000 times using the <code>sample()</code> function.</li>
<li>The results are stored in a <code>tibble</code> called <code>dice_rolls</code>.</li>
</ul></li>
<li><strong>Calculate Conditional Probability:</strong>
<ul>
<li>We use <code>filter(die1 == 3)</code> to restrict our sample space to only those outcomes where the first die rolled a 3. This is equivalent to considering the event <span class="math inline">\(B\)</span> in the formula <span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)}\)</span>.</li>
<li>Then, we use <code>summarise()</code> to calculate the proportion of these outcomes where the sum of the two dice is 7. This is equivalent to finding <span class="math inline">\(P(A|B)\)</span>, where <span class="math inline">\(A\)</span> is the event that the sum is 7 and <span class="math inline">\(B\)</span> is the event that the first die is 3.</li>
<li>The result is stored in the <code>conditional_prob</code> variable.</li>
</ul></li>
<li><strong>Print the Result:</strong>
<ul>
<li>Finally, we print the calculated conditional probability.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script directly illustrates the concept of <strong>conditional probability</strong> as defined in <strong>Definition 2.1</strong> of the text. We are essentially calculating <span class="math inline">\(P(A|B)\)</span> where:</p>
<ul>
<li><span class="math inline">\(A\)</span> = {The sum of the two dice is 7}</li>
<li><span class="math inline">\(B\)</span> = {The first die rolled a 3}</li>
</ul>
<p>We are restricting the sample space to the event <span class="math inline">\(B\)</span> and then calculating the probability of event <span class="math inline">\(A\)</span> within that restricted space.</p>
</section>
<section class="level3" id="r-script-2-illustrating-bayes-theorem">
<h3 class="anchored" data-anchor-id="r-script-2-illustrating-bayes-theorem">R Script 2: Illustrating Bayes’ Theorem</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a aria-hidden="true" href="#cb5-1" tabindex="-1"></a><span class="co"># Set the parameters</span></span>
<span id="cb5-2"><a aria-hidden="true" href="#cb5-2" tabindex="-1"></a>prior_prob_disease <span class="ot">&lt;-</span> <span class="fl">0.01</span> <span class="co"># Prior probability of having the disease</span></span>
<span id="cb5-3"><a aria-hidden="true" href="#cb5-3" tabindex="-1"></a>true_positive_rate <span class="ot">&lt;-</span> <span class="fl">0.95</span> <span class="co"># Sensitivity of the test</span></span>
<span id="cb5-4"><a aria-hidden="true" href="#cb5-4" tabindex="-1"></a>false_positive_rate <span class="ot">&lt;-</span> <span class="fl">0.10</span> <span class="co"># 1 - Specificity of the test</span></span>
<span id="cb5-5"><a aria-hidden="true" href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a aria-hidden="true" href="#cb5-6" tabindex="-1"></a><span class="co"># Calculate the probability of testing positive using the Law of Total Probability</span></span>
<span id="cb5-7"><a aria-hidden="true" href="#cb5-7" tabindex="-1"></a>prob_positive <span class="ot">&lt;-</span> true_positive_rate <span class="sc">*</span> prior_prob_disease <span class="sc">+</span> </span>
<span id="cb5-8"><a aria-hidden="true" href="#cb5-8" tabindex="-1"></a>                 false_positive_rate <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> prior_prob_disease)</span>
<span id="cb5-9"><a aria-hidden="true" href="#cb5-9" tabindex="-1"></a></span>
<span id="cb5-10"><a aria-hidden="true" href="#cb5-10" tabindex="-1"></a><span class="co"># Calculate the posterior probability using Bayes' Theorem</span></span>
<span id="cb5-11"><a aria-hidden="true" href="#cb5-11" tabindex="-1"></a>posterior_prob_disease <span class="ot">&lt;-</span> (true_positive_rate <span class="sc">*</span> prior_prob_disease) <span class="sc">/</span> prob_positive</span>
<span id="cb5-12"><a aria-hidden="true" href="#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a aria-hidden="true" href="#cb5-13" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb5-14"><a aria-hidden="true" href="#cb5-14" tabindex="-1"></a><span class="fu">print</span>(posterior_prob_disease)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0875576</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Set Parameters:</strong>
<ul>
<li>We define the <strong>prior probability</strong> of having the disease (<code>prior_prob_disease</code>), the <strong>true positive rate</strong> (sensitivity) of the test (<code>true_positive_rate</code>), and the <strong>false positive rate</strong> (<code>false_positive_rate</code>).</li>
</ul></li>
<li><strong>Calculate Probability of Testing Positive:</strong>
<ul>
<li>We use the <strong>Law of Total Probability</strong> to calculate the overall probability of testing positive (<code>prob_positive</code>). This involves considering both the probability of testing positive given that you have the disease and the probability of testing positive given that you don’t have the disease, weighted by the prior probabilities.</li>
</ul></li>
<li><strong>Calculate Posterior Probability:</strong>
<ul>
<li>We apply <strong>Bayes’ Theorem</strong> to calculate the <strong>posterior probability</strong> of having the disease given a positive test result (<code>posterior_prob_disease</code>). This is done by dividing the probability of testing positive and having the disease by the overall probability of testing positive.</li>
</ul></li>
<li><strong>Print the Result:</strong>
<ul>
<li>We print the calculated posterior probability.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script directly demonstrates <strong>Bayes’ Theorem</strong> (<strong>Theorem 2.2</strong> in the text). We are calculating <span class="math inline">\(P(D|T)\)</span> where:</p>
<ul>
<li><span class="math inline">\(D\)</span> = {Having the disease}</li>
<li><span class="math inline">\(T\)</span> = {Testing positive}</li>
</ul>
<p>The script shows how the prior probability <span class="math inline">\(P(D)\)</span> is updated to the posterior probability <span class="math inline">\(P(D|T)\)</span> after observing the evidence (a positive test result).</p>
</section>
<section class="level3" id="r-script-3-simulating-independent-events">
<h3 class="anchored" data-anchor-id="r-script-3-simulating-independent-events">R Script 3: Simulating Independent Events</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a aria-hidden="true" href="#cb7-1" tabindex="-1"></a><span class="co"># Set the number of simulations</span></span>
<span id="cb7-2"><a aria-hidden="true" href="#cb7-2" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb7-3"><a aria-hidden="true" href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a aria-hidden="true" href="#cb7-4" tabindex="-1"></a><span class="co"># Simulate two independent coin flips</span></span>
<span id="cb7-5"><a aria-hidden="true" href="#cb7-5" tabindex="-1"></a>coin1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"Heads"</span>, <span class="st">"Tails"</span>), n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-6"><a aria-hidden="true" href="#cb7-6" tabindex="-1"></a>coin2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"Heads"</span>, <span class="st">"Tails"</span>), n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-7"><a aria-hidden="true" href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a aria-hidden="true" href="#cb7-8" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb7-9"><a aria-hidden="true" href="#cb7-9" tabindex="-1"></a>coin_flips <span class="ot">&lt;-</span> <span class="fu">tibble</span>(coin1, coin2)</span>
<span id="cb7-10"><a aria-hidden="true" href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a aria-hidden="true" href="#cb7-11" tabindex="-1"></a><span class="co"># Calculate the probability of getting heads on coin2 given heads on coin1</span></span>
<span id="cb7-12"><a aria-hidden="true" href="#cb7-12" tabindex="-1"></a>conditional_prob <span class="ot">&lt;-</span> coin_flips <span class="sc">%&gt;%</span></span>
<span id="cb7-13"><a aria-hidden="true" href="#cb7-13" tabindex="-1"></a>  <span class="fu">filter</span>(coin1 <span class="sc">==</span> <span class="st">"Heads"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-14"><a aria-hidden="true" href="#cb7-14" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob_coin2_heads =</span> <span class="fu">mean</span>(coin2 <span class="sc">==</span> <span class="st">"Heads"</span>))</span>
<span id="cb7-15"><a aria-hidden="true" href="#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a aria-hidden="true" href="#cb7-16" tabindex="-1"></a><span class="co"># Calculate the marginal probability of getting heads on coin2</span></span>
<span id="cb7-17"><a aria-hidden="true" href="#cb7-17" tabindex="-1"></a>marginal_prob <span class="ot">&lt;-</span> coin_flips <span class="sc">%&gt;%</span></span>
<span id="cb7-18"><a aria-hidden="true" href="#cb7-18" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob_coin2_heads =</span> <span class="fu">mean</span>(coin2 <span class="sc">==</span> <span class="st">"Heads"</span>))</span>
<span id="cb7-19"><a aria-hidden="true" href="#cb7-19" tabindex="-1"></a></span>
<span id="cb7-20"><a aria-hidden="true" href="#cb7-20" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb7-21"><a aria-hidden="true" href="#cb7-21" tabindex="-1"></a><span class="fu">print</span>(conditional_prob)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  prob_coin2_heads
             &lt;dbl&gt;
1            0.491</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a aria-hidden="true" href="#cb9-1" tabindex="-1"></a><span class="fu">print</span>(marginal_prob)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  prob_coin2_heads
             &lt;dbl&gt;
1            0.488</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Simulate Independent Coin Flips:</strong>
<ul>
<li>We simulate two independent coin flips 10,000 times using the <code>sample()</code> function. The results are stored in a <code>tibble</code> called <code>coin_flips</code>.</li>
</ul></li>
<li><strong>Calculate Conditional Probability:</strong>
<ul>
<li>We calculate the probability of getting heads on <code>coin2</code> given that <code>coin1</code> was heads using <code>filter()</code> and <code>summarise()</code>. This is similar to Example 1, but here we expect the conditional probability to be roughly equal to the marginal probability because the events are independent.</li>
</ul></li>
<li><strong>Calculate Marginal Probability:</strong>
<ul>
<li>We calculate the overall (marginal) probability of getting heads on <code>coin2</code> without any conditioning.</li>
</ul></li>
<li><strong>Print the Results:</strong>
<ul>
<li>We print both the conditional and marginal probabilities.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script illustrates the concept of <strong>independence</strong> (<strong>Definition 2.2</strong>). For independent events, <span class="math inline">\(P(A|B) = P(A)\)</span>. In this case:</p>
<ul>
<li><span class="math inline">\(A\)</span> = {Getting heads on coin2}</li>
<li><span class="math inline">\(B\)</span> = {Getting heads on coin1}</li>
</ul>
<p>We expect the conditional probability <span class="math inline">\(P(A|B)\)</span> to be approximately equal to the marginal probability <span class="math inline">\(P(A)\)</span> because the outcome of the first coin flip does not affect the outcome of the second flip.</p>
</section>
<section class="level3" id="r-script-4-demonstrating-the-law-of-total-probability">
<h3 class="anchored" data-anchor-id="r-script-4-demonstrating-the-law-of-total-probability">R Script 4: Demonstrating the Law of Total Probability</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a aria-hidden="true" href="#cb11-1" tabindex="-1"></a><span class="co"># Set the parameters for two factories</span></span>
<span id="cb11-2"><a aria-hidden="true" href="#cb11-2" tabindex="-1"></a>prob_factory_A <span class="ot">&lt;-</span> <span class="fl">0.6</span></span>
<span id="cb11-3"><a aria-hidden="true" href="#cb11-3" tabindex="-1"></a>prob_factory_B <span class="ot">&lt;-</span> <span class="fl">0.4</span></span>
<span id="cb11-4"><a aria-hidden="true" href="#cb11-4" tabindex="-1"></a>prob_defective_given_A <span class="ot">&lt;-</span> <span class="fl">0.04</span></span>
<span id="cb11-5"><a aria-hidden="true" href="#cb11-5" tabindex="-1"></a>prob_defective_given_B <span class="ot">&lt;-</span> <span class="fl">0.02</span></span>
<span id="cb11-6"><a aria-hidden="true" href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a aria-hidden="true" href="#cb11-7" tabindex="-1"></a><span class="co"># Calculate the total probability of a defective bulb using the Law of Total Probability</span></span>
<span id="cb11-8"><a aria-hidden="true" href="#cb11-8" tabindex="-1"></a>prob_defective <span class="ot">&lt;-</span> prob_defective_given_A <span class="sc">*</span> prob_factory_A <span class="sc">+</span> </span>
<span id="cb11-9"><a aria-hidden="true" href="#cb11-9" tabindex="-1"></a>                  prob_defective_given_B <span class="sc">*</span> prob_factory_B</span>
<span id="cb11-10"><a aria-hidden="true" href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a aria-hidden="true" href="#cb11-11" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb11-12"><a aria-hidden="true" href="#cb11-12" tabindex="-1"></a><span class="fu">print</span>(prob_defective)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.032</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Set Parameters:</strong>
<ul>
<li>We define the probability that a bulb comes from Factory A (<code>prob_factory_A</code>), the probability that a bulb comes from Factory B (<code>prob_factory_B</code>), the probability that a bulb is defective given it’s from Factory A (<code>prob_defective_given_A</code>), and the probability that a bulb is defective given it’s from Factory B (<code>prob_defective_given_B</code>).</li>
</ul></li>
<li><strong>Calculate Total Probability of a Defective Bulb:</strong>
<ul>
<li>We apply the <strong>Law of Total Probability</strong> to calculate the overall probability of a bulb being defective (<code>prob_defective</code>). This is done by summing the probabilities of a bulb being defective and coming from each factory, weighted by the probability of a bulb coming from that factory.</li>
</ul></li>
<li><strong>Print the Result:</strong>
<ul>
<li>We print the calculated probability of a bulb being defective.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script demonstrates the <strong>Law of Total Probability</strong>, which is used extensively in the text, especially when calculating the denominator of Bayes’ Theorem. We are calculating <span class="math inline">\(P(D)\)</span> where:</p>
<ul>
<li><span class="math inline">\(D\)</span> = {Bulb is defective}</li>
<li><span class="math inline">\(A\)</span> = {Bulb comes from Factory A}</li>
<li><span class="math inline">\(B\)</span> = {Bulb comes from Factory B}</li>
</ul>
<p>The script shows how to calculate <span class="math inline">\(P(D)\)</span> by considering the different ways a bulb can be defective (either from Factory A or Factory B) and weighting those probabilities by the probabilities of a bulb coming from each factory.</p>
</section>
<section class="level3" id="r-script-5-visualizing-conditional-probability-with-a-scatter-plot">
<h3 class="anchored" data-anchor-id="r-script-5-visualizing-conditional-probability-with-a-scatter-plot">R Script 5: Visualizing Conditional Probability with a Scatter Plot</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a aria-hidden="true" href="#cb13-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb13-2"><a aria-hidden="true" href="#cb13-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb13-3"><a aria-hidden="true" href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a aria-hidden="true" href="#cb13-4" tabindex="-1"></a><span class="co"># Set the number of simulations</span></span>
<span id="cb13-5"><a aria-hidden="true" href="#cb13-5" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb13-6"><a aria-hidden="true" href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a aria-hidden="true" href="#cb13-7" tabindex="-1"></a><span class="co"># Simulate the rolling of two dice</span></span>
<span id="cb13-8"><a aria-hidden="true" href="#cb13-8" tabindex="-1"></a>die1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-9"><a aria-hidden="true" href="#cb13-9" tabindex="-1"></a>die2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-10"><a aria-hidden="true" href="#cb13-10" tabindex="-1"></a></span>
<span id="cb13-11"><a aria-hidden="true" href="#cb13-11" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb13-12"><a aria-hidden="true" href="#cb13-12" tabindex="-1"></a>dice_rolls <span class="ot">&lt;-</span> <span class="fu">tibble</span>(die1, die2)</span>
<span id="cb13-13"><a aria-hidden="true" href="#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a aria-hidden="true" href="#cb13-14" tabindex="-1"></a><span class="co"># Create a scatter plot of the results</span></span>
<span id="cb13-15"><a aria-hidden="true" href="#cb13-15" tabindex="-1"></a><span class="fu">ggplot</span>(dice_rolls, <span class="fu">aes</span>(<span class="at">x =</span> die1, <span class="at">y =</span> die2)) <span class="sc">+</span></span>
<span id="cb13-16"><a aria-hidden="true" href="#cb13-16" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">height =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="co"># Use jitter to see overlapping points</span></span>
<span id="cb13-17"><a aria-hidden="true" href="#cb13-17" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">7</span>, <span class="at">slope =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span> <span class="co"># Add a line where die1 + die2 = 7</span></span>
<span id="cb13-18"><a aria-hidden="true" href="#cb13-18" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>, <span class="dv">7</span>) <span class="sc">+</span> <span class="co"># Adjust x-axis limits</span></span>
<span id="cb13-19"><a aria-hidden="true" href="#cb13-19" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">7</span>) <span class="sc">+</span> <span class="co"># Adjust y-axis limits</span></span>
<span id="cb13-20"><a aria-hidden="true" href="#cb13-20" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-21"><a aria-hidden="true" href="#cb13-21" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Scatter Plot of Two Dice Rolls"</span>,</span>
<span id="cb13-22"><a aria-hidden="true" href="#cb13-22" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Red line represents die1 + die2 = 7"</span>,</span>
<span id="cb13-23"><a aria-hidden="true" href="#cb13-23" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Die 1"</span>,</span>
<span id="cb13-24"><a aria-hidden="true" href="#cb13-24" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Die 2"</span></span>
<span id="cb13-25"><a aria-hidden="true" href="#cb13-25" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-26"><a aria-hidden="true" href="#cb13-26" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap02_files/figure-html/unnamed-chunk-5-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Library:</strong>
<ul>
<li>We load the <code>ggplot2</code> library for creating the scatter plot.</li>
</ul></li>
<li><strong>Simulate Dice Rolls:</strong>
<ul>
<li>We simulate rolling two six-sided dice 1,000 times using the <code>sample()</code> function.</li>
<li>The results are stored in a <code>tibble</code> called <code>dice_rolls</code>.</li>
</ul></li>
<li><strong>Create Scatter Plot:</strong>
<ul>
<li>We use <code>ggplot()</code> to create a scatter plot with <code>die1</code> on the x-axis and <code>die2</code> on the y-axis.</li>
<li><code>geom_jitter()</code> is used to slightly shift the points so that we can see overlapping points more clearly.</li>
<li><code>geom_abline()</code> adds a red line representing the equation <code>die1 + die2 = 7</code>.</li>
<li><code>xlim()</code> and <code>ylim()</code> adjust the axis limits for better visualization.</li>
<li><code>labs()</code> adds a title and axis labels.</li>
<li><code>theme_minimal()</code> applies a clean theme to the plot.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script provides a visual representation of <strong>conditional probability</strong> in the context of rolling two dice. The red line represents the event where the sum of the two dice is 7. By visually restricting our attention to the points where <code>die1</code> is 3 (or any other specific value), we can see how the probability of the sum being 7 changes. This visual representation helps build intuition for how conditioning on an event alters the sample space and the probabilities of other events.</p>
<p>These R scripts provide practical examples of how to simulate and calculate probabilities, illustrating key concepts from the text such as conditional probability, Bayes’ Theorem, independence, and the Law of Total Probability. They also demonstrate how to use visualization to gain a better understanding of these concepts.</p>
<p>Okay, here are 5 more multi-line R script examples using tidyverse syntax (where possible) to illustrate the concepts from the provided text, along with detailed explanations.</p>
</section>
<section class="level3" id="r-script-6-simulating-the-gamblers-ruin-problem">
<h3 class="anchored" data-anchor-id="r-script-6-simulating-the-gamblers-ruin-problem">R Script 6: Simulating the Gambler’s Ruin Problem</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a aria-hidden="true" href="#cb14-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb14-2"><a aria-hidden="true" href="#cb14-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb14-3"><a aria-hidden="true" href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a aria-hidden="true" href="#cb14-4" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb14-5"><a aria-hidden="true" href="#cb14-5" tabindex="-1"></a>initial_capital <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb14-6"><a aria-hidden="true" href="#cb14-6" tabindex="-1"></a>prob_win <span class="ot">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Probability of winning a single round</span></span>
<span id="cb14-7"><a aria-hidden="true" href="#cb14-7" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb14-8"><a aria-hidden="true" href="#cb14-8" tabindex="-1"></a></span>
<span id="cb14-9"><a aria-hidden="true" href="#cb14-9" tabindex="-1"></a><span class="co"># Function to simulate one gambler's ruin game</span></span>
<span id="cb14-10"><a aria-hidden="true" href="#cb14-10" tabindex="-1"></a>simulate_gamblers_ruin <span class="ot">&lt;-</span> <span class="cf">function</span>(initial_capital, prob_win) {</span>
<span id="cb14-11"><a aria-hidden="true" href="#cb14-11" tabindex="-1"></a>  capital <span class="ot">&lt;-</span> initial_capital</span>
<span id="cb14-12"><a aria-hidden="true" href="#cb14-12" tabindex="-1"></a>  <span class="cf">while</span> (capital <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> capital <span class="sc">&lt;</span> <span class="dv">10</span>) {  <span class="co"># Continue until ruin or reaching the target</span></span>
<span id="cb14-13"><a aria-hidden="true" href="#cb14-13" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> prob_win) {</span>
<span id="cb14-14"><a aria-hidden="true" href="#cb14-14" tabindex="-1"></a>      capital <span class="ot">&lt;-</span> capital <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb14-15"><a aria-hidden="true" href="#cb14-15" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb14-16"><a aria-hidden="true" href="#cb14-16" tabindex="-1"></a>      capital <span class="ot">&lt;-</span> capital <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb14-17"><a aria-hidden="true" href="#cb14-17" tabindex="-1"></a>    }</span>
<span id="cb14-18"><a aria-hidden="true" href="#cb14-18" tabindex="-1"></a>  }</span>
<span id="cb14-19"><a aria-hidden="true" href="#cb14-19" tabindex="-1"></a>  <span class="fu">return</span>(capital)</span>
<span id="cb14-20"><a aria-hidden="true" href="#cb14-20" tabindex="-1"></a>}</span>
<span id="cb14-21"><a aria-hidden="true" href="#cb14-21" tabindex="-1"></a></span>
<span id="cb14-22"><a aria-hidden="true" href="#cb14-22" tabindex="-1"></a><span class="co"># Run simulations</span></span>
<span id="cb14-23"><a aria-hidden="true" href="#cb14-23" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_simulations, <span class="fu">simulate_gamblers_ruin</span>(initial_capital, prob_win))</span>
<span id="cb14-24"><a aria-hidden="true" href="#cb14-24" tabindex="-1"></a></span>
<span id="cb14-25"><a aria-hidden="true" href="#cb14-25" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb14-26"><a aria-hidden="true" href="#cb14-26" tabindex="-1"></a>results_tibble <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">final_capital =</span> results)</span>
<span id="cb14-27"><a aria-hidden="true" href="#cb14-27" tabindex="-1"></a></span>
<span id="cb14-28"><a aria-hidden="true" href="#cb14-28" tabindex="-1"></a><span class="co"># Calculate the probability of ruin</span></span>
<span id="cb14-29"><a aria-hidden="true" href="#cb14-29" tabindex="-1"></a>prob_ruin <span class="ot">&lt;-</span> <span class="fu">mean</span>(results_tibble<span class="sc">$</span>final_capital <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb14-30"><a aria-hidden="true" href="#cb14-30" tabindex="-1"></a></span>
<span id="cb14-31"><a aria-hidden="true" href="#cb14-31" tabindex="-1"></a><span class="co"># Print the probability of ruin</span></span>
<span id="cb14-32"><a aria-hidden="true" href="#cb14-32" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Probability of ruin:"</span>, prob_ruin))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Probability of ruin: 0.506"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a aria-hidden="true" href="#cb16-1" tabindex="-1"></a><span class="co"># Plot a histogram of final capital</span></span>
<span id="cb16-2"><a aria-hidden="true" href="#cb16-2" tabindex="-1"></a><span class="fu">ggplot</span>(results_tibble, <span class="fu">aes</span>(<span class="at">x =</span> final_capital)) <span class="sc">+</span></span>
<span id="cb16-3"><a aria-hidden="true" href="#cb16-3" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">1</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb16-4"><a aria-hidden="true" href="#cb16-4" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb16-5"><a aria-hidden="true" href="#cb16-5" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Gambler's Ruin Simulation Results"</span>,</span>
<span id="cb16-6"><a aria-hidden="true" href="#cb16-6" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Final Capital"</span>,</span>
<span id="cb16-7"><a aria-hidden="true" href="#cb16-7" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Frequency"</span></span>
<span id="cb16-8"><a aria-hidden="true" href="#cb16-8" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb16-9"><a aria-hidden="true" href="#cb16-9" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap02_files/figure-html/unnamed-chunk-6-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Library:</strong>
<ul>
<li>We load the <code>tidyverse</code> library for data manipulation and visualization.</li>
</ul></li>
<li><strong>Set Parameters:</strong>
<ul>
<li><code>initial_capital</code>: The gambler’s starting capital.</li>
<li><code>prob_win</code>: The probability of winning a single round (set to 0.5 for a fair game).</li>
<li><code>n_simulations</code>: The number of times we want to simulate the game.</li>
</ul></li>
<li><strong>Simulate Gambler’s Ruin Function:</strong>
<ul>
<li><code>simulate_gamblers_ruin()</code>: This function simulates a single game of gambler’s ruin.</li>
<li>It takes the initial capital and probability of winning as input.</li>
<li>It uses a <code>while</code> loop to continue the game until the gambler’s capital reaches 0 (ruin) or 10 (an arbitrary target in this case).</li>
<li><code>runif(1)</code> generates a random number between 0 and 1. If it’s less than <code>prob_win</code>, the gambler wins and their capital increases by 1; otherwise, they lose and their capital decreases by 1.</li>
<li>The function returns the gambler’s final capital.</li>
</ul></li>
<li><strong>Run Simulations:</strong>
<ul>
<li><code>replicate()</code> is used to run the <code>simulate_gamblers_ruin()</code> function <code>n_simulations</code> times, effectively simulating the game many times.</li>
<li>The results (final capital in each simulation) are stored in the <code>results</code> variable.</li>
</ul></li>
<li><strong>Create Tibble:</strong>
<ul>
<li>The simulation results are stored in a <code>tibble</code> called <code>results_tibble</code>.</li>
</ul></li>
<li><strong>Calculate Probability of Ruin:</strong>
<ul>
<li><code>mean(results_tibble$final_capital == 0)</code> calculates the proportion of simulations where the final capital is 0, which represents the probability of ruin.</li>
</ul></li>
<li><strong>Print Result:</strong>
<ul>
<li>The calculated probability of ruin is printed.</li>
</ul></li>
<li><strong>Plot Histogram:</strong>
<ul>
<li><code>ggplot()</code> is used to create a histogram of the <code>final_capital</code> from the simulations. This provides a visual representation of the distribution of outcomes.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script directly simulates the <strong>Gambler’s Ruin</strong> problem described in <strong>Example 2.14</strong> of the text. It demonstrates how to use simulation to estimate the probability of ruin and provides a visual representation of the possible outcomes. The histogram helps visualize that even in a fair game, the gambler has a high probability of going bankrupt when starting with limited capital.</p>
</section>
<section class="level3" id="r-script-7-demonstrating-conditional-independence">
<h3 class="anchored" data-anchor-id="r-script-7-demonstrating-conditional-independence">R Script 7: Demonstrating Conditional Independence</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a aria-hidden="true" href="#cb17-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb17-2"><a aria-hidden="true" href="#cb17-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb17-3"><a aria-hidden="true" href="#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a aria-hidden="true" href="#cb17-4" tabindex="-1"></a><span class="co"># Set parameters for the simulation</span></span>
<span id="cb17-5"><a aria-hidden="true" href="#cb17-5" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb17-6"><a aria-hidden="true" href="#cb17-6" tabindex="-1"></a></span>
<span id="cb17-7"><a aria-hidden="true" href="#cb17-7" tabindex="-1"></a><span class="co"># Simulate two independent dice rolls and whether they are the same</span></span>
<span id="cb17-8"><a aria-hidden="true" href="#cb17-8" tabindex="-1"></a>die1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb17-9"><a aria-hidden="true" href="#cb17-9" tabindex="-1"></a>die2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb17-10"><a aria-hidden="true" href="#cb17-10" tabindex="-1"></a>both_same <span class="ot">&lt;-</span> (die1 <span class="sc">==</span> die2)</span>
<span id="cb17-11"><a aria-hidden="true" href="#cb17-11" tabindex="-1"></a></span>
<span id="cb17-12"><a aria-hidden="true" href="#cb17-12" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb17-13"><a aria-hidden="true" href="#cb17-13" tabindex="-1"></a>dice_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(die1, die2, both_same)</span>
<span id="cb17-14"><a aria-hidden="true" href="#cb17-14" tabindex="-1"></a></span>
<span id="cb17-15"><a aria-hidden="true" href="#cb17-15" tabindex="-1"></a><span class="co"># Calculate P(die1 = 6 | both_same) and P(die2 = 6 | both_same)</span></span>
<span id="cb17-16"><a aria-hidden="true" href="#cb17-16" tabindex="-1"></a>prob_die1_given_same <span class="ot">&lt;-</span> dice_data <span class="sc">%&gt;%</span></span>
<span id="cb17-17"><a aria-hidden="true" href="#cb17-17" tabindex="-1"></a>  <span class="fu">filter</span>(both_same) <span class="sc">%&gt;%</span></span>
<span id="cb17-18"><a aria-hidden="true" href="#cb17-18" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob =</span> <span class="fu">mean</span>(die1 <span class="sc">==</span> <span class="dv">6</span>))</span>
<span id="cb17-19"><a aria-hidden="true" href="#cb17-19" tabindex="-1"></a></span>
<span id="cb17-20"><a aria-hidden="true" href="#cb17-20" tabindex="-1"></a>prob_die2_given_same <span class="ot">&lt;-</span> dice_data <span class="sc">%&gt;%</span></span>
<span id="cb17-21"><a aria-hidden="true" href="#cb17-21" tabindex="-1"></a>  <span class="fu">filter</span>(both_same) <span class="sc">%&gt;%</span></span>
<span id="cb17-22"><a aria-hidden="true" href="#cb17-22" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob =</span> <span class="fu">mean</span>(die2 <span class="sc">==</span> <span class="dv">6</span>))</span>
<span id="cb17-23"><a aria-hidden="true" href="#cb17-23" tabindex="-1"></a></span>
<span id="cb17-24"><a aria-hidden="true" href="#cb17-24" tabindex="-1"></a><span class="co"># Calculate P(die1 = 6 and die2 = 6 | both_same)</span></span>
<span id="cb17-25"><a aria-hidden="true" href="#cb17-25" tabindex="-1"></a>prob_both_6_given_same <span class="ot">&lt;-</span> dice_data <span class="sc">%&gt;%</span></span>
<span id="cb17-26"><a aria-hidden="true" href="#cb17-26" tabindex="-1"></a>  <span class="fu">filter</span>(both_same) <span class="sc">%&gt;%</span></span>
<span id="cb17-27"><a aria-hidden="true" href="#cb17-27" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob =</span> <span class="fu">mean</span>(die1 <span class="sc">==</span> <span class="dv">6</span> <span class="sc">&amp;</span> die2 <span class="sc">==</span> <span class="dv">6</span>))</span>
<span id="cb17-28"><a aria-hidden="true" href="#cb17-28" tabindex="-1"></a></span>
<span id="cb17-29"><a aria-hidden="true" href="#cb17-29" tabindex="-1"></a><span class="co"># Print the probabilities</span></span>
<span id="cb17-30"><a aria-hidden="true" href="#cb17-30" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"P(die1 = 6 | both_same):"</span>, prob_die1_given_same<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "P(die1 = 6 | both_same): 0.158083832335329"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a aria-hidden="true" href="#cb19-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"P(die2 = 6 | both_same):"</span>, prob_die2_given_same<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "P(die2 = 6 | both_same): 0.158083832335329"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a aria-hidden="true" href="#cb21-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"P(die1 = 6 and die2 = 6 | both_same):"</span>, prob_both_6_given_same<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "P(die1 = 6 and die2 = 6 | both_same): 0.158083832335329"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a aria-hidden="true" href="#cb23-1" tabindex="-1"></a><span class="co"># Check for conditional independence</span></span>
<span id="cb23-2"><a aria-hidden="true" href="#cb23-2" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"P(die1 = 6 | both_same) * P(die2 = 6 | both_same):"</span>, </span>
<span id="cb23-3"><a aria-hidden="true" href="#cb23-3" tabindex="-1"></a>            prob_die1_given_same<span class="sc">$</span>prob <span class="sc">*</span> prob_die2_given_same<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "P(die1 = 6 | both_same) * P(die2 = 6 | both_same): 0.0249904980458245"</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Library:</strong>
<ul>
<li>We load the <code>tidyverse</code> library for data manipulation.</li>
</ul></li>
<li><strong>Set Parameters:</strong>
<ul>
<li><code>n_simulations</code>: The number of times we want to simulate the dice rolls.</li>
</ul></li>
<li><strong>Simulate Dice Rolls:</strong>
<ul>
<li>We simulate two independent dice rolls (<code>die1</code> and <code>die2</code>) using <code>sample()</code>.</li>
<li><code>both_same</code> is a logical vector indicating whether the two dice rolls are the same.</li>
</ul></li>
<li><strong>Create Tibble:</strong>
<ul>
<li>The simulation results are stored in a <code>tibble</code> called <code>dice_data</code>.</li>
</ul></li>
<li><strong>Calculate Conditional Probabilities:</strong>
<ul>
<li>We calculate <code>P(die1 = 6 | both_same)</code>, <code>P(die2 = 6 | both_same)</code>, and <code>P(die1 = 6 and die2 = 6 | both_same)</code> using <code>filter()</code> and <code>summarise()</code>. We filter the data to include only cases where <code>both_same</code> is <code>TRUE</code> and then calculate the relevant proportions.</li>
</ul></li>
<li><strong>Print Probabilities:</strong>
<ul>
<li>The calculated probabilities are printed.</li>
</ul></li>
<li><strong>Check for Conditional Independence:</strong>
<ul>
<li>We check if the condition for conditional independence holds: <span class="math inline">\(P(A \cap B | C) = P(A|C)P(B|C)\)</span>. In this case, we check if <code>P(die1 = 6 and die2 = 6 | both_same)</code> is approximately equal to <code>P(die1 = 6 | both_same) * P(die2 = 6 | both_same)</code>.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script illustrates the concept of <strong>conditional independence</strong> as discussed in <strong>Definition 2.5</strong> and <strong>Example 2.12</strong> of the text. We are checking if the events {<code>die1</code> = 6} and {<code>die2</code> = 6} are conditionally independent given the event {<code>both_same</code>}. The results will show that they are <em>not</em> conditionally independent, even though they are independent without conditioning. This demonstrates that independence does not imply conditional independence.</p>
</section>
<section class="level3" id="r-script-8-exploring-measures-of-dependence">
<h3 class="anchored" data-anchor-id="r-script-8-exploring-measures-of-dependence">R Script 8: Exploring Measures of Dependence</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a aria-hidden="true" href="#cb25-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb25-2"><a aria-hidden="true" href="#cb25-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb25-3"><a aria-hidden="true" href="#cb25-3" tabindex="-1"></a></span>
<span id="cb25-4"><a aria-hidden="true" href="#cb25-4" tabindex="-1"></a><span class="co"># Set parameters for the simulation</span></span>
<span id="cb25-5"><a aria-hidden="true" href="#cb25-5" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb25-6"><a aria-hidden="true" href="#cb25-6" tabindex="-1"></a></span>
<span id="cb25-7"><a aria-hidden="true" href="#cb25-7" tabindex="-1"></a><span class="co"># Simulate two dice rolls</span></span>
<span id="cb25-8"><a aria-hidden="true" href="#cb25-8" tabindex="-1"></a>die1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-9"><a aria-hidden="true" href="#cb25-9" tabindex="-1"></a>die2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n_simulations, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-10"><a aria-hidden="true" href="#cb25-10" tabindex="-1"></a></span>
<span id="cb25-11"><a aria-hidden="true" href="#cb25-11" tabindex="-1"></a><span class="co"># Create a tibble to store the results</span></span>
<span id="cb25-12"><a aria-hidden="true" href="#cb25-12" tabindex="-1"></a>dice_rolls <span class="ot">&lt;-</span> <span class="fu">tibble</span>(die1, die2)</span>
<span id="cb25-13"><a aria-hidden="true" href="#cb25-13" tabindex="-1"></a></span>
<span id="cb25-14"><a aria-hidden="true" href="#cb25-14" tabindex="-1"></a><span class="co"># Define events A and B</span></span>
<span id="cb25-15"><a aria-hidden="true" href="#cb25-15" tabindex="-1"></a>dice_rolls <span class="ot">&lt;-</span> dice_rolls <span class="sc">%&gt;%</span></span>
<span id="cb25-16"><a aria-hidden="true" href="#cb25-16" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb25-17"><a aria-hidden="true" href="#cb25-17" tabindex="-1"></a>    <span class="at">A =</span> (die1 <span class="sc">%%</span> <span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>),  <span class="co"># Event A: die1 is even</span></span>
<span id="cb25-18"><a aria-hidden="true" href="#cb25-18" tabindex="-1"></a>    <span class="at">B =</span> (die2 <span class="sc">&gt;</span> <span class="dv">3</span>)       <span class="co"># Event B: die2 is greater than 3</span></span>
<span id="cb25-19"><a aria-hidden="true" href="#cb25-19" tabindex="-1"></a>  )</span>
<span id="cb25-20"><a aria-hidden="true" href="#cb25-20" tabindex="-1"></a></span>
<span id="cb25-21"><a aria-hidden="true" href="#cb25-21" tabindex="-1"></a><span class="co"># Calculate P(A), P(B), and P(A ∩ B)</span></span>
<span id="cb25-22"><a aria-hidden="true" href="#cb25-22" tabindex="-1"></a>prob_A <span class="ot">&lt;-</span> <span class="fu">mean</span>(dice_rolls<span class="sc">$</span>A)</span>
<span id="cb25-23"><a aria-hidden="true" href="#cb25-23" tabindex="-1"></a>prob_B <span class="ot">&lt;-</span> <span class="fu">mean</span>(dice_rolls<span class="sc">$</span>B)</span>
<span id="cb25-24"><a aria-hidden="true" href="#cb25-24" tabindex="-1"></a>prob_A_and_B <span class="ot">&lt;-</span> <span class="fu">mean</span>(dice_rolls<span class="sc">$</span>A <span class="sc">&amp;</span> dice_rolls<span class="sc">$</span>B)</span>
<span id="cb25-25"><a aria-hidden="true" href="#cb25-25" tabindex="-1"></a></span>
<span id="cb25-26"><a aria-hidden="true" href="#cb25-26" tabindex="-1"></a><span class="co"># Calculate the measures of dependence</span></span>
<span id="cb25-27"><a aria-hidden="true" href="#cb25-27" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> prob_A_and_B <span class="sc">-</span> prob_A <span class="sc">*</span> prob_B</span>
<span id="cb25-28"><a aria-hidden="true" href="#cb25-28" tabindex="-1"></a>beta <span class="ot">&lt;-</span> (prob_A_and_B <span class="sc">/</span> prob_B) <span class="sc">-</span> prob_A</span>
<span id="cb25-29"><a aria-hidden="true" href="#cb25-29" tabindex="-1"></a>gamma <span class="ot">&lt;-</span> (prob_A_and_B <span class="sc">/</span> (prob_A <span class="sc">*</span> prob_B)) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb25-30"><a aria-hidden="true" href="#cb25-30" tabindex="-1"></a></span>
<span id="cb25-31"><a aria-hidden="true" href="#cb25-31" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb25-32"><a aria-hidden="true" href="#cb25-32" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"alpha(A, B):"</span>, alpha))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "alpha(A, B): 0.00404974000000002"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a aria-hidden="true" href="#cb27-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"beta(A, B):"</span>, beta))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "beta(A, B): 0.00809786042791438"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a aria-hidden="true" href="#cb29-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"gamma(A, B):"</span>, gamma))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "gamma(A, B): 0.016111938774203"</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Library:</strong>
<ul>
<li>We load the <code>tidyverse</code> library for data manipulation.</li>
</ul></li>
<li><strong>Set Parameters:</strong>
<ul>
<li><code>n_simulations</code>: The number of times we want to simulate the dice rolls.</li>
</ul></li>
<li><strong>Simulate Dice Rolls:</strong>
<ul>
<li>We simulate two independent dice rolls (<code>die1</code> and <code>die2</code>) using <code>sample()</code>.</li>
</ul></li>
<li><strong>Create Tibble:</strong>
<ul>
<li>The simulation results are stored in a <code>tibble</code> called <code>dice_rolls</code>.</li>
</ul></li>
<li><strong>Define Events:</strong>
<ul>
<li>We define two events:
<ul>
<li><code>A</code>: <code>die1</code> is even.</li>
<li><code>B</code>: <code>die2</code> is greater than 3.</li>
</ul></li>
<li>These events are created as new logical columns in the <code>dice_rolls</code> tibble using <code>mutate()</code>.</li>
</ul></li>
<li><strong>Calculate Probabilities:</strong>
<ul>
<li>We calculate <span class="math inline">\(P(A)\)</span>, <span class="math inline">\(P(B)\)</span>, and <span class="math inline">\(P(A \cap B)\)</span> using <code>mean()</code>.</li>
</ul></li>
<li><strong>Calculate Measures of Dependence:</strong>
<ul>
<li>We calculate the measures of dependence <span class="math inline">\(\alpha(A, B)\)</span>, <span class="math inline">\(\beta(A, B)\)</span>, and <span class="math inline">\(\gamma(A, B)\)</span> using the formulas from the text.</li>
</ul></li>
<li><strong>Print Results:</strong>
<ul>
<li>The calculated measures of dependence are printed.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script demonstrates the calculation of the <strong>measures of dependence</strong> <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\gamma\)</span> as defined in the text. By simulating dice rolls and defining events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we can empirically estimate these measures and observe the direction and magnitude of dependence between the events. In this case since the two dice rolls are independent, we expect these measures to be close to zero.</p>
</section>
<section class="level3" id="r-script-9-illustrating-simpsons-paradox">
<h3 class="anchored" data-anchor-id="r-script-9-illustrating-simpsons-paradox">R Script 9: Illustrating Simpson’s Paradox</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a aria-hidden="true" href="#cb31-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb31-2"><a aria-hidden="true" href="#cb31-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb31-3"><a aria-hidden="true" href="#cb31-3" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'gridExtra'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    combine</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a aria-hidden="true" href="#cb34-1" tabindex="-1"></a><span class="co"># Create a synthetic dataset exhibiting Simpson's Paradox</span></span>
<span id="cb34-2"><a aria-hidden="true" href="#cb34-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb34-3"><a aria-hidden="true" href="#cb34-3" tabindex="-1"></a>group <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>), <span class="at">each =</span> <span class="dv">50</span>)</span>
<span id="cb34-4"><a aria-hidden="true" href="#cb34-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">1</span>))</span>
<span id="cb34-5"><a aria-hidden="true" href="#cb34-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">1</span>))</span>
<span id="cb34-6"><a aria-hidden="true" href="#cb34-6" tabindex="-1"></a><span class="co"># group_x &lt;- c(rnorm(50, mean = 3, sd = 1), rnorm(50, mean = 5, sd = 1))</span></span>
<span id="cb34-7"><a aria-hidden="true" href="#cb34-7" tabindex="-1"></a></span>
<span id="cb34-8"><a aria-hidden="true" href="#cb34-8" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(group, x, y)<span class="co">#, group_x)</span></span>
<span id="cb34-9"><a aria-hidden="true" href="#cb34-9" tabindex="-1"></a></span>
<span id="cb34-10"><a aria-hidden="true" href="#cb34-10" tabindex="-1"></a><span class="co"># Create scatter plots for each group</span></span>
<span id="cb34-11"><a aria-hidden="true" href="#cb34-11" tabindex="-1"></a>plot_A <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data <span class="sc">%&gt;%</span> <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"A"</span>), <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb34-12"><a aria-hidden="true" href="#cb34-12" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb34-13"><a aria-hidden="true" href="#cb34-13" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb34-14"><a aria-hidden="true" href="#cb34-14" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Group A"</span>) <span class="sc">+</span></span>
<span id="cb34-15"><a aria-hidden="true" href="#cb34-15" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb34-16"><a aria-hidden="true" href="#cb34-16" tabindex="-1"></a></span>
<span id="cb34-17"><a aria-hidden="true" href="#cb34-17" tabindex="-1"></a>plot_B <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data <span class="sc">%&gt;%</span> <span class="fu">filter</span>(group <span class="sc">==</span> <span class="st">"B"</span>), <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb34-18"><a aria-hidden="true" href="#cb34-18" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb34-19"><a aria-hidden="true" href="#cb34-19" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb34-20"><a aria-hidden="true" href="#cb34-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Group B"</span>) <span class="sc">+</span></span>
<span id="cb34-21"><a aria-hidden="true" href="#cb34-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb34-22"><a aria-hidden="true" href="#cb34-22" tabindex="-1"></a></span>
<span id="cb34-23"><a aria-hidden="true" href="#cb34-23" tabindex="-1"></a><span class="co"># Create a scatter plot for the combined data</span></span>
<span id="cb34-24"><a aria-hidden="true" href="#cb34-24" tabindex="-1"></a>plot_combined <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">color =</span> group)) <span class="sc">+</span></span>
<span id="cb34-25"><a aria-hidden="true" href="#cb34-25" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb34-26"><a aria-hidden="true" href="#cb34-26" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb34-27"><a aria-hidden="true" href="#cb34-27" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Combined"</span>) <span class="sc">+</span></span>
<span id="cb34-28"><a aria-hidden="true" href="#cb34-28" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb34-29"><a aria-hidden="true" href="#cb34-29" tabindex="-1"></a></span>
<span id="cb34-30"><a aria-hidden="true" href="#cb34-30" tabindex="-1"></a><span class="co"># Arrange the plots using grid.arrange()</span></span>
<span id="cb34-31"><a aria-hidden="true" href="#cb34-31" tabindex="-1"></a><span class="fu">grid.arrange</span>(plot_A, plot_B, plot_combined, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap02_files/figure-html/unnamed-chunk-9-1.png" width="672"/></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a aria-hidden="true" href="#cb37-1" tabindex="-1"></a><span class="co"># Calculate correlations</span></span>
<span id="cb37-2"><a aria-hidden="true" href="#cb37-2" tabindex="-1"></a>cor_A <span class="ot">&lt;-</span> <span class="fu">cor</span>(data<span class="sc">$</span>x[data<span class="sc">$</span>group <span class="sc">==</span> <span class="st">"A"</span>], data<span class="sc">$</span>y[data<span class="sc">$</span>group <span class="sc">==</span> <span class="st">"A"</span>])</span>
<span id="cb37-3"><a aria-hidden="true" href="#cb37-3" tabindex="-1"></a>cor_B <span class="ot">&lt;-</span> <span class="fu">cor</span>(data<span class="sc">$</span>x[data<span class="sc">$</span>group <span class="sc">==</span> <span class="st">"B"</span>], data<span class="sc">$</span>y[data<span class="sc">$</span>group <span class="sc">==</span> <span class="st">"B"</span>])</span>
<span id="cb37-4"><a aria-hidden="true" href="#cb37-4" tabindex="-1"></a>cor_combined <span class="ot">&lt;-</span> <span class="fu">cor</span>(data<span class="sc">$</span>x, data<span class="sc">$</span>y)</span>
<span id="cb37-5"><a aria-hidden="true" href="#cb37-5" tabindex="-1"></a></span>
<span id="cb37-6"><a aria-hidden="true" href="#cb37-6" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Correlation in Group A:"</span>, cor_A))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Correlation in Group A: 0.0291061197239367"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a aria-hidden="true" href="#cb39-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Correlation in Group B:"</span>, cor_B))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Correlation in Group B: -0.156263706483561"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a aria-hidden="true" href="#cb41-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Correlation in Combined Data:"</span>, cor_combined))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Correlation in Combined Data: 0.451044593477293"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a aria-hidden="true" href="#cb43-1" tabindex="-1"></a><span class="co"># # Create a plot that shows confounding variable</span></span>
<span id="cb43-2"><a aria-hidden="true" href="#cb43-2" tabindex="-1"></a><span class="co"># plot_confounding &lt;- ggplot(data, aes(x = group_x, y = y, color = group)) +</span></span>
<span id="cb43-3"><a aria-hidden="true" href="#cb43-3" tabindex="-1"></a><span class="co">#   geom_point() +</span></span>
<span id="cb43-4"><a aria-hidden="true" href="#cb43-4" tabindex="-1"></a><span class="co">#   geom_smooth(method = "lm", se = FALSE, color = "black") +</span></span>
<span id="cb43-5"><a aria-hidden="true" href="#cb43-5" tabindex="-1"></a><span class="co">#   labs(title = "Confounding Variable: group_x",</span></span>
<span id="cb43-6"><a aria-hidden="true" href="#cb43-6" tabindex="-1"></a><span class="co">#        x = "group_x") +</span></span>
<span id="cb43-7"><a aria-hidden="true" href="#cb43-7" tabindex="-1"></a><span class="co">#   theme_minimal()</span></span>
<span id="cb43-8"><a aria-hidden="true" href="#cb43-8" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb43-9"><a aria-hidden="true" href="#cb43-9" tabindex="-1"></a><span class="co"># print(plot_confounding)</span></span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Libraries:</strong>
<ul>
<li>We load the <code>tidyverse</code> library for data manipulation and <code>ggplot2</code> for plotting. We also load <code>gridExtra</code> to arrange the plots into a single figure.</li>
</ul></li>
<li><strong>Create Synthetic Dataset:</strong>
<ul>
<li>We create a synthetic dataset <code>data</code> that exhibits <strong>Simpson’s Paradox</strong>.</li>
<li>The dataset has two groups, “A” and “B”, each with 50 data points.</li>
<li><code>x</code> and <code>y</code> are variables that have a positive correlation within each group but a negative correlation overall. <!-- *   `group_x` is a third variable that will help to visualize the confounding effect. --></li>
</ul></li>
<li><strong>Create Scatter Plots:</strong>
<ul>
<li>We create three scatter plots using <code>ggplot()</code>:
<ul>
<li><code>plot_A</code>: Shows the relationship between <code>x</code> and <code>y</code> for Group A.</li>
<li><code>plot_B</code>: Shows the relationship between <code>x</code> and <code>y</code> for Group B.</li>
<li><code>plot_combined</code>: Shows the relationship between <code>x</code> and <code>y</code> for the combined data.</li>
</ul></li>
<li><code>geom_smooth(method = "lm", se = FALSE)</code> adds a linear regression line to each plot.</li>
</ul></li>
<li><strong>Arrange Plots:</strong>
<ul>
<li>We use <code>grid.arrange()</code> from <code>gridExtra</code> package to display the three plots side-by-side.</li>
</ul></li>
<li><strong>Calculate Correlations:</strong>
<ul>
<li>We calculate the correlation between <code>x</code> and <code>y</code> for each group and for the combined data using <code>cor()</code>. <!-- 6. **Create a Plot with Confounding Variable:** --> <!--     *  We create another scatter plot `plot_confounding` that shows the relationship between `group_x` and `y`. --></li>
</ul></li>
<li><strong>Print Correlations:</strong>
<ul>
<li>We print the calculated correlations. <!-- 8. **Print Confounding Variable Plot:** --> <!--     *  We print the `plot_confounding`. --></li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script provides a visual and numerical illustration of <strong>Simpson’s Paradox</strong>, which is mentioned in the text. The scatter plots and correlation coefficients demonstrate how the direction of association between two variables (<code>x</code> and <code>y</code>) can be reversed when the data is aggregated across groups. In this example, there is a positive correlation within each group, but a negative correlation in the combined data. <!-- The confounding variable `group_x` can be used to explain why this is happening. --></p>
</section>
<section class="level3" id="r-script-10-simulating-conditional-probability-with-replacement-vs.-without-replacement">
<h3 class="anchored" data-anchor-id="r-script-10-simulating-conditional-probability-with-replacement-vs.-without-replacement">R Script 10: Simulating Conditional Probability with Replacement vs. Without Replacement</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a aria-hidden="true" href="#cb44-1" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb44-2"><a aria-hidden="true" href="#cb44-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb44-3"><a aria-hidden="true" href="#cb44-3" tabindex="-1"></a></span>
<span id="cb44-4"><a aria-hidden="true" href="#cb44-4" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb44-5"><a aria-hidden="true" href="#cb44-5" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb44-6"><a aria-hidden="true" href="#cb44-6" tabindex="-1"></a>deck_size <span class="ot">&lt;-</span> <span class="dv">52</span></span>
<span id="cb44-7"><a aria-hidden="true" href="#cb44-7" tabindex="-1"></a>num_aces <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb44-8"><a aria-hidden="true" href="#cb44-8" tabindex="-1"></a>num_kings <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb44-9"><a aria-hidden="true" href="#cb44-9" tabindex="-1"></a></span>
<span id="cb44-10"><a aria-hidden="true" href="#cb44-10" tabindex="-1"></a><span class="co"># Function to simulate drawing two cards with replacement</span></span>
<span id="cb44-11"><a aria-hidden="true" href="#cb44-11" tabindex="-1"></a>simulate_with_replacement <span class="ot">&lt;-</span> <span class="cf">function</span>(n_simulations, deck_size, num_aces, num_kings) {</span>
<span id="cb44-12"><a aria-hidden="true" href="#cb44-12" tabindex="-1"></a>  results <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_simulations, {</span>
<span id="cb44-13"><a aria-hidden="true" href="#cb44-13" tabindex="-1"></a>    card1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Ace"</span>, num_aces), <span class="fu">rep</span>(<span class="st">"King"</span>, num_kings), </span>
<span id="cb44-14"><a aria-hidden="true" href="#cb44-14" tabindex="-1"></a>                      <span class="fu">rep</span>(<span class="st">"Other"</span>, deck_size <span class="sc">-</span> num_aces <span class="sc">-</span> num_kings)), <span class="dv">1</span>)</span>
<span id="cb44-15"><a aria-hidden="true" href="#cb44-15" tabindex="-1"></a>    card2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Ace"</span>, num_aces), <span class="fu">rep</span>(<span class="st">"King"</span>, num_kings), </span>
<span id="cb44-16"><a aria-hidden="true" href="#cb44-16" tabindex="-1"></a>                      <span class="fu">rep</span>(<span class="st">"Other"</span>, deck_size <span class="sc">-</span> num_aces <span class="sc">-</span> num_kings)), <span class="dv">1</span>)</span>
<span id="cb44-17"><a aria-hidden="true" href="#cb44-17" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">c</span>(card1, card2))</span>
<span id="cb44-18"><a aria-hidden="true" href="#cb44-18" tabindex="-1"></a>  })</span>
<span id="cb44-19"><a aria-hidden="true" href="#cb44-19" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">t</span>(results))</span>
<span id="cb44-20"><a aria-hidden="true" href="#cb44-20" tabindex="-1"></a>}</span>
<span id="cb44-21"><a aria-hidden="true" href="#cb44-21" tabindex="-1"></a></span>
<span id="cb44-22"><a aria-hidden="true" href="#cb44-22" tabindex="-1"></a><span class="co"># Function to simulate drawing two cards without replacement</span></span>
<span id="cb44-23"><a aria-hidden="true" href="#cb44-23" tabindex="-1"></a>simulate_without_replacement <span class="ot">&lt;-</span> <span class="cf">function</span>(n_simulations, deck_size, num_aces, num_kings) {</span>
<span id="cb44-24"><a aria-hidden="true" href="#cb44-24" tabindex="-1"></a>  results <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_simulations, {</span>
<span id="cb44-25"><a aria-hidden="true" href="#cb44-25" tabindex="-1"></a>    deck <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Ace"</span>, num_aces), <span class="fu">rep</span>(<span class="st">"King"</span>, num_kings), </span>
<span id="cb44-26"><a aria-hidden="true" href="#cb44-26" tabindex="-1"></a>              <span class="fu">rep</span>(<span class="st">"Other"</span>, deck_size <span class="sc">-</span> num_aces <span class="sc">-</span> num_kings))</span>
<span id="cb44-27"><a aria-hidden="true" href="#cb44-27" tabindex="-1"></a>    draw <span class="ot">&lt;-</span> <span class="fu">sample</span>(deck, <span class="dv">2</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb44-28"><a aria-hidden="true" href="#cb44-28" tabindex="-1"></a>    <span class="fu">return</span>(draw)</span>
<span id="cb44-29"><a aria-hidden="true" href="#cb44-29" tabindex="-1"></a>  })</span>
<span id="cb44-30"><a aria-hidden="true" href="#cb44-30" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">t</span>(results))</span>
<span id="cb44-31"><a aria-hidden="true" href="#cb44-31" tabindex="-1"></a>}</span>
<span id="cb44-32"><a aria-hidden="true" href="#cb44-32" tabindex="-1"></a></span>
<span id="cb44-33"><a aria-hidden="true" href="#cb44-33" tabindex="-1"></a><span class="co"># Run simulations</span></span>
<span id="cb44-34"><a aria-hidden="true" href="#cb44-34" tabindex="-1"></a>with_replacement_results <span class="ot">&lt;-</span> <span class="fu">simulate_with_replacement</span>(n_simulations, deck_size, num_aces, num_kings)</span>
<span id="cb44-35"><a aria-hidden="true" href="#cb44-35" tabindex="-1"></a>without_replacement_results <span class="ot">&lt;-</span> <span class="fu">simulate_without_replacement</span>(n_simulations, deck_size, num_aces, num_kings)</span>
<span id="cb44-36"><a aria-hidden="true" href="#cb44-36" tabindex="-1"></a></span>
<span id="cb44-37"><a aria-hidden="true" href="#cb44-37" tabindex="-1"></a><span class="co"># Create tibbles</span></span>
<span id="cb44-38"><a aria-hidden="true" href="#cb44-38" tabindex="-1"></a>with_replacement_tibble <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(with_replacement_results) <span class="sc">%&gt;%</span></span>
<span id="cb44-39"><a aria-hidden="true" href="#cb44-39" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">card1 =</span> V1, <span class="at">card2 =</span> V2)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if
`.name_repair` is omitted as of tibble 2.0.0.
ℹ Using compatibility `.name_repair`.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a aria-hidden="true" href="#cb46-1" tabindex="-1"></a>without_replacement_tibble <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(without_replacement_results) <span class="sc">%&gt;%</span></span>
<span id="cb46-2"><a aria-hidden="true" href="#cb46-2" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">card1 =</span> V1, <span class="at">card2 =</span> V2)</span>
<span id="cb46-3"><a aria-hidden="true" href="#cb46-3" tabindex="-1"></a></span>
<span id="cb46-4"><a aria-hidden="true" href="#cb46-4" tabindex="-1"></a><span class="co"># Calculate probabilities for with replacement</span></span>
<span id="cb46-5"><a aria-hidden="true" href="#cb46-5" tabindex="-1"></a>prob_king_given_ace_with <span class="ot">&lt;-</span> with_replacement_tibble <span class="sc">%&gt;%</span></span>
<span id="cb46-6"><a aria-hidden="true" href="#cb46-6" tabindex="-1"></a>  <span class="fu">filter</span>(card1 <span class="sc">==</span> <span class="st">"Ace"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb46-7"><a aria-hidden="true" href="#cb46-7" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob =</span> <span class="fu">mean</span>(card2 <span class="sc">==</span> <span class="st">"King"</span>))</span>
<span id="cb46-8"><a aria-hidden="true" href="#cb46-8" tabindex="-1"></a></span>
<span id="cb46-9"><a aria-hidden="true" href="#cb46-9" tabindex="-1"></a><span class="co"># Calculate probabilities for without replacement</span></span>
<span id="cb46-10"><a aria-hidden="true" href="#cb46-10" tabindex="-1"></a>prob_king_given_ace_without <span class="ot">&lt;-</span> without_replacement_tibble <span class="sc">%&gt;%</span></span>
<span id="cb46-11"><a aria-hidden="true" href="#cb46-11" tabindex="-1"></a>  <span class="fu">filter</span>(card1 <span class="sc">==</span> <span class="st">"Ace"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb46-12"><a aria-hidden="true" href="#cb46-12" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob =</span> <span class="fu">mean</span>(card2 <span class="sc">==</span> <span class="st">"King"</span>))</span>
<span id="cb46-13"><a aria-hidden="true" href="#cb46-13" tabindex="-1"></a></span>
<span id="cb46-14"><a aria-hidden="true" href="#cb46-14" tabindex="-1"></a><span class="co"># Print the results (intuitively Without Replacement &gt; With Replacement)</span></span>
<span id="cb46-15"><a aria-hidden="true" href="#cb46-15" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"With Replacement: P(King | Ace):"</span>, prob_king_given_ace_with<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "With Replacement: P(King | Ace): 0.0748730964467005"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a aria-hidden="true" href="#cb48-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Without Replacement: P(King | Ace):"</span>, prob_king_given_ace_without<span class="sc">$</span>prob))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Without Replacement: P(King | Ace): 0.0689655172413793"</code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<ol type="1">
<li><strong>Load Library:</strong>
<ul>
<li>We load the <code>tidyverse</code> library for data manipulation.</li>
</ul></li>
<li><strong>Set Parameters:</strong>
<ul>
<li><code>n_simulations</code>: The number of simulation runs.</li>
<li><code>deck_size</code>: The total number of cards in the deck.</li>
<li><code>num_aces</code>: The number of Aces in the deck.</li>
<li><code>num_kings</code>: The number of Kings in the deck.</li>
</ul></li>
<li><strong>Simulation Functions:</strong>
<ul>
<li><code>simulate_with_replacement()</code>: Simulates drawing two cards <em>with</em> replacement.</li>
<li><code>simulate_without_replacement()</code>: Simulates drawing two cards <em>without</em> replacement.</li>
<li>Both functions use <code>replicate()</code> to repeat the simulation <code>n_simulations</code> times.</li>
<li><code>sample()</code> is used to draw cards from the deck.</li>
</ul></li>
<li><strong>Run Simulations:</strong>
<ul>
<li>We call both simulation functions to generate results for each scenario.</li>
</ul></li>
<li><strong>Create Tibbles:</strong>
<ul>
<li>The results are converted to <code>tibbles</code> for easier manipulation.</li>
</ul></li>
<li><strong>Calculate Probabilities:</strong>
<ul>
<li>We calculate <span class="math inline">\(P(\text{King} | \text{Ace})\)</span> for both scenarios using <code>filter()</code> and <code>summarise()</code>.</li>
</ul></li>
<li><strong>Print Results:</strong>
<ul>
<li>The calculated probabilities are printed.</li>
</ul></li>
</ol>
<p><strong>Relation to the Text:</strong></p>
<p>This script illustrates the difference between sampling with and without replacement and how it affects <strong>conditional probabilities</strong>. This relates to <strong>Example 2.9</strong> in the text, where dealing two cards without replacement creates dependence between the events. The script demonstrates that <span class="math inline">\(P(\text{King} | \text{Ace})\)</span> is different when sampling with replacement (independent events) compared to sampling without replacement (dependent events). When sampling without replacement, the conditional probability will be affected by the outcome of the first draw, as the composition of the deck changes. When sampling with replacement the conditional probability will not be affected by the outcome of the first draw since each draw is independent and the composition of the deck remains unchanged between the draws.</p>
</section>
</section>
<section class="level2" id="youtube-videos">
<h2 class="anchored" data-anchor-id="youtube-videos">YouTube Videos</h2>
<p>Here are some videos that can help illustrate the concepts of conditional probability, independence, Bayes’ Theorem, and related ideas discussed in the text.</p>
<section class="level3" id="bayes-theorem---visual-explanation">
<h3 class="anchored" data-anchor-id="bayes-theorem---visual-explanation">Bayes’ Theorem - Visual Explanation</h3>
<ul>
<li><strong>Video Title:</strong> Bayes theorem, the geometry of changing beliefs - by 3Blue1Brown</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=HZGCoVF3YvM">https://www.youtube.com/watch?v=HZGCoVF3YvM</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Bayes’ Theorem</strong></li>
<li>Visual representation of Bayes’ Theorem</li>
<li>Prior and posterior probabilities.</li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video provides an excellent visual and intuitive explanation of <strong>Bayes’ Theorem</strong>, which is stated as <strong>Theorem 2.2</strong> in the text. It demonstrates how to update beliefs based on new evidence, mirroring the examples in the text (like the sequential trading model) where prior probabilities are updated to posterior probabilities. The presenter explains <strong>Bayes’ Theorem</strong> using geometry and explains all the concepts in the theorem including the <strong>prior probability</strong>, the <strong>likelihood</strong>, and the <strong>posterior probability</strong>.</li>
</ul>
</section>
<section class="level3" id="law-of-total-probability">
<h3 class="anchored" data-anchor-id="law-of-total-probability">Law of Total Probability</h3>
<ul>
<li><strong>Video Title:</strong> Probability: “Law of Total Probability” - by jbstatistics</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=7t9jyikrG7w">https://www.youtube.com/watch?v=7t9jyikrG7w</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Law of Total Probability</strong></li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video explains the <strong>Law of Total Probability</strong>, which is used extensively in the examples and solutions provided in the text, especially when calculating the denominator for Bayes’ Theorem. The formula <span class="math inline">\(P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)\)</span> is clearly presented and illustrated with examples.</li>
</ul>
</section>
<section class="level3" id="simpsons-paradox">
<h3 class="anchored" data-anchor-id="simpsons-paradox">Simpson’s Paradox</h3>
<ul>
<li><strong>Video Title:</strong> Simpson’s Paradox - by minutephysics</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=ebEkn-BiW5k">https://www.youtube.com/watch?v=ebEkn-BiW5k</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Simpson’s Paradox</strong></li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video provides a clear and concise explanation of <strong>Simpson’s Paradox</strong>, which is mentioned in the text. It shows how associations can be reversed when data is aggregated, highlighting the importance of considering conditional versus unconditional distributions.</li>
</ul>
</section>
<section class="level3" id="markov-chains">
<h3 class="anchored" data-anchor-id="markov-chains">Markov Chains</h3>
<ul>
<li><strong>Video Title:</strong> Markov Chains Clearly Explained! Part - 1 - by Normalized Nerd</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=i3AkTO9HLXo">https://www.youtube.com/watch?v=i3AkTO9HLXo</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Markov Chains</strong></li>
<li>Transition probabilities</li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video introduces the concept of <strong>Markov Chains</strong>, which is briefly discussed in <strong>Example 2.13</strong> of the text. It explains the idea of state transitions and the Markov property, where the future depends only on the present state and not the past.</li>
</ul>
</section>
<section class="level3" id="gamblers-ruin">
<h3 class="anchored" data-anchor-id="gamblers-ruin">Gambler’s Ruin</h3>
<ul>
<li><strong>Video Title:</strong> Gambler’s Ruin - by MIT OpenCourseWare</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=PNrqCdslGi4">https://www.youtube.com/watch?v=PNrqCdslGi4</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Gambler’s Ruin</strong></li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video provides a detailed explanation of the <strong>Gambler’s Ruin</strong> problem, which is presented in <strong>Example 2.14</strong> of the text. It derives the probability of ruin using the concept of difference equations.</li>
</ul>
</section>
<section class="level3" id="pairwise-independence-vs.-independence">
<h3 class="anchored" data-anchor-id="pairwise-independence-vs.-independence">Pairwise Independence vs. Independence</h3>
<ul>
<li><strong>Video Title:</strong> Pairwise Independence - by MIT OpenCourseWare</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=aJXfyfQs2Mc">https://www.youtube.com/watch?v=aJXfyfQs2Mc</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Pairwise Independence</strong></li>
<li><strong>Mutual Independence</strong></li>
<li>Difference between pairwise and mutual independence.</li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video explains the distinction between <strong>pairwise independence</strong> (<strong>Definition 2.4</strong>) and <strong>mutual independence</strong> (<strong>Definition 2.3</strong>). It provides examples to illustrate that pairwise independence does not necessarily imply mutual independence, which is a crucial concept for understanding the nuances of independence when dealing with more than two events.</li>
</ul>
</section>
<section class="level3" id="prosecutors-fallacy">
<h3 class="anchored" data-anchor-id="prosecutors-fallacy">Prosecutor’s Fallacy</h3>
<ul>
<li><strong>Video Title:</strong> The Prosecutor’s Fallacy - by Melissa Humphries</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=V4cMWoGxEwo">https://www.youtube.com/watch?v=V4cMWoGxEwo</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Prosecutor’s Fallacy</strong></li>
<li>Misinterpretation of conditional probability in legal contexts</li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video provides a detailed explanation and examples of the <strong>Prosecutor’s Fallacy</strong>. It explains the difference between the probability of A given B, and the probability of B given A using numerical examples. The <strong>Prosecutor’s Fallacy</strong> is briefly mentioned in the text after Example 2.4, in which the probability that a person is telling the truth given a positive reading on the Polygraph test is calculated using Bayes’ theorem.</li>
</ul>
</section>
<section class="level3" id="independence-of-events">
<h3 class="anchored" data-anchor-id="independence-of-events">Independence of events:</h3>
<ul>
<li><strong>Video Title:</strong> Independent Events - by The Organic Chemistry Tutor</li>
<li><strong>Link:</strong> <a href="https://www.youtube.com/watch?v=lWAdPyvm400">https://www.youtube.com/watch?v=lWAdPyvm400</a></li>
<li><strong>Key Concepts Covered:</strong>
<ul>
<li><strong>Independent Events</strong></li>
<li>Product rule of independent events</li>
</ul></li>
<li><strong>Relation to the Text:</strong> This video explains the concept of <strong>independence</strong> as defined in <strong>Definition 2.2</strong> of the text. It also explains the difference between independent and dependent events. It provides several numerical examples and demonstrates that for independent events <span class="math inline">\(P(A|B) = P(A)\)</span> and <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span>.</li>
</ul>
</section>
</section>
<section class="level2" id="multiple-choice-exercises">
<h2 class="anchored" data-anchor-id="multiple-choice-exercises">Multiple Choice Exercises</h2>
<section class="level3" id="sec-ch02mcexercise1">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise1">MC Exercise 1</h3>
<p><a href="#sec-ch02mcsolution1">MC Solution 1</a></p>
<p>Given two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, if <span class="math inline">\(P(A|B) = 0.5\)</span> and <span class="math inline">\(P(A \cap B) = 0.2\)</span>, what is <span class="math inline">\(P(B)\)</span>?</p>
<ol type="a">
<li><p>0.1</p></li>
<li><p>0.4</p></li>
<li><p>0.7</p></li>
<li><p>0.25</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise2">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise2">MC Exercise 2</h3>
<p><a href="#sec-ch02mcsolution2">MC Solution 2</a></p>
<p>If events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>mutually exclusive</strong>, which of the following is always true?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A|B) = P(A)\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = 1\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = 0\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(B)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise3">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise3">MC Exercise 3</h3>
<p><a href="#sec-ch02mcsolution3">MC Solution 3</a></p>
<p>Which of the following is the correct formula for <strong>Bayes’ Theorem</strong>?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(A|B)P(B)}{P(A)}\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(A)}\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(B|A)P(B)}{P(A)}\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise4">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise4">MC Exercise 4</h3>
<p><a href="#sec-ch02mcsolution4">MC Solution 4</a></p>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong>, which of the following is true?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A \cap B) = 0\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(A)P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise5">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise5">MC Exercise 5</h3>
<p><a href="#sec-ch02mcsolution5">MC Solution 5</a></p>
<p>A diagnostic test has a true positive rate of 90% and a false positive rate of 10%. If the prevalence of the disease in the population is 1%, what is the approximate probability that a person who tests positive actually has the disease?</p>
<ol type="a">
<li><p>9%</p></li>
<li><p>8.3%</p></li>
<li><p>90%</p></li>
<li><p>1%</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise6">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise6">MC Exercise 6</h3>
<p><a href="#sec-ch02mcsolution6">MC Solution 6</a></p>
<p>If <span class="math inline">\(P(A) = 0.6\)</span>, <span class="math inline">\(P(B) = 0.5\)</span>, and <span class="math inline">\(P(A \cap B) = 0.3\)</span>, what is <span class="math inline">\(P(A|B)\)</span>?</p>
<ol type="a">
<li><p>0.5</p></li>
<li><p>0.6</p></li>
<li><p>0.3</p></li>
<li><p>0.1</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise7">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise7">MC Exercise 7</h3>
<p><a href="#sec-ch02mcsolution7">MC Solution 7</a></p>
<p>The <strong>Law of Total Probability</strong> states that for any event <span class="math inline">\(A\)</span> and a set of mutually exclusive and exhaustive events <span class="math inline">\(B_1, B_2, ..., B_n\)</span>, which of the following is true?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)\)</span></p></li>
<li><p><span class="math inline">\(P(A) = \sum_{i=1}^{n} P(A \cap B_i)\)</span></p></li>
<li><p><span class="math inline">\(P(A) = \sum_{i=1}^{n} P(B_i|A)\)</span></p></li>
<li><p><span class="math inline">\(P(A) = P(A|B_1) + P(A|B_2) + ... + P(A|B_n)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise8">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise8">MC Exercise 8</h3>
<p><a href="#sec-ch02mcsolution8">MC Solution 8</a></p>
<p>If <span class="math inline">\(P(A|B) = 0.4\)</span>, <span class="math inline">\(P(A|B^c) = 0.2\)</span>, and <span class="math inline">\(P(B) = 0.6\)</span>, what is <span class="math inline">\(P(A)\)</span>?</p>
<ol type="a">
<li><p>0.28</p></li>
<li><p>0.32</p></li>
<li><p>0.6</p></li>
<li><p>0.2</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise9">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise9">MC Exercise 9</h3>
<p><a href="#sec-ch02mcsolution9">MC Solution 9</a></p>
<p>Which of the following is a measure of <strong>dependence</strong> between two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A) + P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cap B) - P(A)P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B)\)</span></p></li>
<li><p><span class="math inline">\(P(A) / P(B)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise10">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise10">MC Exercise 10</h3>
<p><a href="#sec-ch02mcsolution10">MC Solution 10</a></p>
<p><strong>Simpson’s Paradox</strong> occurs when:</p>
<ol type="a">
<li><p>The direction of association between two variables is reversed when conditioned on a third variable.</p></li>
<li><p>Two events are independent.</p></li>
<li><p>The probability of an event is 0.</p></li>
<li><p>The probability of an event is 1.</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise11">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise11">MC Exercise 11</h3>
<p><a href="#sec-ch02mcsolution11">MC Solution 11</a></p>
<p>In a <strong>Markov Chain</strong>, the future state depends:</p>
<ol type="a">
<li><p>Only on the present state.</p></li>
<li><p>On all past states.</p></li>
<li><p>On the initial state only.</p></li>
<li><p>On the present state and the initial state.</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise12">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise12">MC Exercise 12</h3>
<p><a href="#sec-ch02mcsolution12">MC Solution 12</a></p>
<p>If <span class="math inline">\(P(A) = 0.3\)</span>, <span class="math inline">\(P(B) = 0.4\)</span>, and <span class="math inline">\(P(A \cup B) = 0.5\)</span>, what is <span class="math inline">\(P(A \cap B)\)</span>?</p>
<ol type="a">
<li><p>0.12</p></li>
<li><p>0.2</p></li>
<li><p>0.7</p></li>
<li><p>0</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise13">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise13">MC Exercise 13</h3>
<p><a href="#sec-ch02mcsolution13">MC Solution 13</a></p>
<p>If <span class="math inline">\(A \subseteq B\)</span>, then which of the following is always true?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A|B) = 0\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(A)}{P(B)}\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = 1\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(A)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise14">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise14">MC Exercise 14</h3>
<p><a href="#sec-ch02mcsolution14">MC Solution 14</a></p>
<p>If events <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are <strong>mutually independent</strong>, which of the following must be true?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A \cap B \cap C) = 0\)</span></p></li>
<li><p><span class="math inline">\(P(A \cap B \cap C) = P(A) + P(B) + P(C)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B \cup C) = P(A) + P(B) + P(C)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise15">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise15">MC Exercise 15</h3>
<p><a href="#sec-ch02mcsolution15">MC Solution 15</a></p>
<p>The <strong>Gambler’s Ruin</strong> problem illustrates that:</p>
<ol type="a">
<li><p>A gambler with a higher initial capital always has a higher probability of winning.</p></li>
<li><p>Even with a fair game, a gambler with finite capital will eventually go bankrupt with probability 1.</p></li>
<li><p>A gambler can always win if they play long enough.</p></li>
<li><p>The probability of winning is always equal to the probability of losing.</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise16">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise16">MC Exercise 16</h3>
<p><a href="#sec-ch02mcsolution16">MC Solution 16</a></p>
<p>If <span class="math inline">\(P(A|B) = 0.6\)</span> and <span class="math inline">\(P(B) = 0.5\)</span>, what is <span class="math inline">\(P(A \cap B)\)</span>?</p>
<ol type="a">
<li><p>0.3</p></li>
<li><p>0.1</p></li>
<li><p>1.1</p></li>
<li><p>1.2</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise17">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise17">MC Exercise 17</h3>
<p><a href="#sec-ch02mcsolution17">MC Solution 17</a></p>
<p>Which of the following statements is true about <strong>conditional probability</strong>?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A|B) = P(B|A)\)</span> if and only if <span class="math inline">\(P(A) = P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(B|A)\)</span> for all events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = P(A)\)</span> if <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(B\)</span></p></li>
<li><p><span class="math inline">\(P(A|B) = \dfrac{P(B|A)P(B)}{P(A)}\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise18">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise18">MC Exercise 18</h3>
<p><a href="#sec-ch02mcsolution18">MC Solution 18</a></p>
<p>If events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong>, what is <span class="math inline">\(P(A \cup B)\)</span> in terms of <span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(P(A) + P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A)P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A) + P(B) - P(A)P(B)\)</span></p></li>
<li><p><span class="math inline">\(P(A) + P(B) + P(A)P(B)\)</span></p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise19">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise19">MC Exercise 19</h3>
<p><a href="#sec-ch02mcsolution19">MC Solution 19</a></p>
<p>In the sequential trading model (Example 2.5), if the probability of an informed trader (<span class="math inline">\(\mu\)</span>) increases, what happens to the posterior probability of the stock having a low value (<span class="math inline">\(V_L\)</span>) given a buy order?</p>
<ol type="a">
<li><p>Increases</p></li>
<li><p>Decreases</p></li>
<li><p>Stays the same</p></li>
<li><p>Cannot be determined</p></li>
</ol>
</section>
<section class="level3" id="sec-ch02mcexercise20">
<h3 class="anchored" data-anchor-id="sec-ch02mcexercise20">MC Exercise 20</h3>
<p><a href="#sec-ch02mcsolution20">MC Solution 20</a></p>
<p>What is the <strong>posterior probability</strong> in the context of Bayes’ Theorem?</p>
<ol type="a">
<li><p>The initial probability of an event before any new evidence is considered.</p></li>
<li><p>The probability of observing the evidence given that a hypothesis is true.</p></li>
<li><p>The updated probability of an event after considering new evidence.</p></li>
<li><p>The probability of the evidence occurring.</p></li>
</ol>
</section>
</section>
<section class="level2" id="multiple-choice-solutions">
<h2 class="anchored" data-anchor-id="multiple-choice-solutions">Multiple Choice Solutions</h2>
<section class="level3" id="sec-ch02mcsolution1">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution1">MC Solution 1</h3>
<p><a href="#sec-ch02mcexercise1">MC Exercise 1</a></p>
<p><strong>Correct Answer:</strong> b) 0.4</p>
<p><strong>Explanation:</strong></p>
<p>We are given <span class="math inline">\(P(A|B) = 0.5\)</span> and <span class="math inline">\(P(A \cap B) = 0.2\)</span>. We want to find <span class="math inline">\(P(B)\)</span>.</p>
<p>Using the definition of <strong>conditional probability</strong> (<strong>Definition 2.1</strong> in the text), we have:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)}\)</span>.</p>
<p>Rearranging to solve for <span class="math inline">\(P(B)\)</span>, we get:</p>
<p><span class="math inline">\(P(B) = \dfrac{P(A \cap B)}{P(A|B)} = \dfrac{0.2}{0.5} = 0.4\)</span>.</p>
<p>Therefore, <span class="math inline">\(P(B) = 0.4\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution2">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution2">MC Solution 2</h3>
<p><a href="#sec-ch02mcexercise2">MC Exercise 2</a></p>
<p><strong>Correct Answer:</strong> c) <span class="math inline">\(P(A|B) = 0\)</span></p>
<p><strong>Explanation:</strong></p>
<p>If events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>mutually exclusive</strong>, it means they cannot occur at the same time. Therefore, their intersection is empty, i.e., <span class="math inline">\(P(A \cap B) = 0\)</span>.</p>
<p>Using the definition of <strong>conditional probability</strong>, we have:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{0}{P(B)} = 0\)</span> (assuming <span class="math inline">\(P(B) &gt; 0\)</span>).</p>
<p>So, if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are mutually exclusive, <span class="math inline">\(P(A|B) = 0\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution3">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution3">MC Solution 3</h3>
<p><a href="#sec-ch02mcexercise3">MC Exercise 3</a></p>
<p><strong>Correct Answer:</strong> a) <span class="math inline">\(P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}\)</span></p>
<p><strong>Explanation:</strong></p>
<p>This is the standard formulation of <strong>Bayes’ Theorem</strong> (<strong>Theorem 2.2</strong> in the text). It describes how to update the probability of an event <span class="math inline">\(A\)</span> given new evidence <span class="math inline">\(B\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution4">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution4">MC Solution 4</h3>
<p><a href="#sec-ch02mcexercise4">MC Exercise 4</a></p>
<p><strong>Correct Answer:</strong> d) <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></p>
<p><strong>Explanation:</strong></p>
<p>This is the definition of <strong>independence</strong> for two events (<strong>Definition 2.2</strong> in the text). If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, the probability of their intersection is the product of their individual probabilities.</p>
</section>
<section class="level3" id="sec-ch02mcsolution5">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution5">MC Solution 5</h3>
<p><a href="#sec-ch02mcexercise5">MC Exercise 5</a></p>
<p><strong>Correct Answer:</strong> b) 8.3%</p>
<p><strong>Explanation:</strong></p>
<p>Let <span class="math inline">\(D\)</span> be the event of having the disease, and <span class="math inline">\(T\)</span> be the event of testing positive. We are given:</p>
<ul>
<li><span class="math inline">\(P(T|D) = 0.9\)</span> (True positive rate)</li>
<li><span class="math inline">\(P(T|D^c) = 0.1\)</span> (False positive rate)</li>
<li><span class="math inline">\(P(D) = 0.01\)</span> (Prevalence)</li>
<li><span class="math inline">\(P(D^c) = 1 - P(D) = 0.99\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(D|T)\)</span>. Using <strong>Bayes’ Theorem</strong>:</p>
<p><span class="math inline">\(P(D|T) = \dfrac{P(T|D)P(D)}{P(T)}\)</span>.</p>
<p>We need to find <span class="math inline">\(P(T)\)</span> using the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(T) &amp;= P(T|D)P(D) + P(T|D^c)P(D^c) \\
&amp;= (0.9)(0.01) + (0.1)(0.99) \\
&amp;= 0.009 + 0.099 \\
&amp;= 0.108
\end{aligned}\)</span>.</p>
<p>Now we can apply Bayes’ Theorem:</p>
<p><span class="math inline">\(\begin{aligned}
P(D|T) &amp;= \dfrac{P(T|D)P(D)}{P(T)} \\
&amp;= \dfrac{(0.9)(0.01)}{0.108} \\
&amp;= \dfrac{0.009}{0.108} \\
&amp;\approx 0.0833
\end{aligned}\)</span>.</p>
<p>So, the approximate probability is 8.3%.</p>
</section>
<section class="level3" id="sec-ch02mcsolution6">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution6">MC Solution 6</h3>
<p><a href="#sec-ch02mcexercise6">MC Exercise 6</a></p>
<p><strong>Correct Answer:</strong> b) 0.6</p>
<p><strong>Explanation:</strong></p>
<p>We are given <span class="math inline">\(P(A) = 0.6\)</span>, <span class="math inline">\(P(B) = 0.5\)</span>, and <span class="math inline">\(P(A \cap B) = 0.3\)</span>. We want to find <span class="math inline">\(P(A|B)\)</span>.</p>
<p>Using the definition of <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{0.3}{0.5} = 0.6\)</span>.</p>
<p>Therefore, <span class="math inline">\(P(A|B) = 0.6\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution7">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution7">MC Solution 7</h3>
<p><a href="#sec-ch02mcexercise7">MC Exercise 7</a></p>
<p><strong>Correct Answer:</strong> a) <span class="math inline">\(P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)\)</span> b) is also corrext</p>
<p><strong>Explanation:</strong></p>
<p>This is the correct formula for the <strong>Law of Total Probability</strong>. It states that the probability of an event <span class="math inline">\(A\)</span> can be calculated by summing the conditional probabilities of <span class="math inline">\(A\)</span> given each event <span class="math inline">\(B_i\)</span>, weighted by the probability of each <span class="math inline">\(B_i\)</span>, where the <span class="math inline">\(B_i\)</span> events form a partition of the sample space (mutually exclusive and exhaustive). This is just an expanded form of answer b).</p>
</section>
<section class="level3" id="sec-ch02mcsolution8">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution8">MC Solution 8</h3>
<p><a href="#sec-ch02mcexercise8">MC Exercise 8</a></p>
<p><strong>Correct Answer:</strong> b) 0.32</p>
<p><strong>Explanation:</strong></p>
<p>We are given <span class="math inline">\(P(A|B) = 0.4\)</span>, <span class="math inline">\(P(A|B^c) = 0.2\)</span>, and <span class="math inline">\(P(B) = 0.6\)</span>. We want to find <span class="math inline">\(P(A)\)</span>.</p>
<p>We can use the <strong>Law of Total Probability</strong>:</p>
<p><span class="math inline">\(\begin{aligned}
P(A) &amp;= P(A|B)P(B) + P(A|B^c)P(B^c) \\
&amp;= P(A|B)P(B) + P(A|B^c)(1 - P(B)) \\
&amp;= (0.4)(0.6) + (0.2)(1 - 0.6) \\
&amp;= 0.24 + 0.08 \\
&amp;= 0.32
\end{aligned}\)</span>.</p>
<p>Therefore, <span class="math inline">\(P(A) = 0.32\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution9">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution9">MC Solution 9</h3>
<p><a href="#sec-ch02mcexercise9">MC Exercise 9</a></p>
<p><strong>Correct Answer:</strong> b) <span class="math inline">\(P(A \cap B) - P(A)P(B)\)</span></p>
<p><strong>Explanation:</strong></p>
<p>This expression, denoted as <span class="math inline">\(\alpha(A, B)\)</span> in the text, is a <strong>measure of dependence</strong> between two events. If <span class="math inline">\(\alpha(A, B) = 0\)</span>, the events are independent. If <span class="math inline">\(\alpha(A, B) &gt; 0\)</span>, the events are positively dependent, and if <span class="math inline">\(\alpha(A, B) &lt; 0\)</span>, the events are negatively dependent.</p>
</section>
<section class="level3" id="sec-ch02mcsolution10">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution10">MC Solution 10</h3>
<p><a href="#sec-ch02mcexercise10">MC Exercise 10</a></p>
<p><strong>Correct Answer:</strong> a) The direction of association between two variables is reversed when conditioned on a third variable.</p>
<p><strong>Explanation:</strong></p>
<p>This is the definition of <strong>Simpson’s Paradox</strong>. It highlights the importance of considering potential confounding variables when analyzing relationships between variables.</p>
</section>
<section class="level3" id="sec-ch02mcsolution11">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution11">MC Solution 11</h3>
<p><a href="#sec-ch02mcexercise11">MC Exercise 11</a></p>
<p><strong>Correct Answer:</strong> a) Only on the present state.</p>
<p><strong>Explanation:</strong></p>
<p>This is the defining property of a <strong>Markov Chain</strong>, known as the <strong>Markov property</strong>. The future state is conditionally independent of the past states given the present state.</p>
</section>
<section class="level3" id="sec-ch02mcsolution12">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution12">MC Solution 12</h3>
<p><a href="#sec-ch02mcexercise12">MC Exercise 12</a></p>
<p><strong>Correct Answer:</strong> b) 0.2</p>
<p><strong>Explanation:</strong></p>
<p>We are given <span class="math inline">\(P(A) = 0.3\)</span>, <span class="math inline">\(P(B) = 0.4\)</span>, and <span class="math inline">\(P(A \cup B) = 0.5\)</span>. We want to find <span class="math inline">\(P(A \cap B)\)</span>.</p>
<p>Using the formula for the probability of the union of two events:</p>
<p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>.</p>
<p>Rearranging to solve for <span class="math inline">\(P(A \cap B)\)</span>, we get:</p>
<p><span class="math inline">\(\begin{aligned}
P(A \cap B) &amp;= P(A) + P(B) - P(A \cup B) \\
&amp;= 0.3 + 0.4 - 0.5 \\
&amp;= 0.2
\end{aligned}\)</span>.</p>
<p>Therefore, <span class="math inline">\(P(A \cap B) = 0.2\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution13">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution13">MC Solution 13</h3>
<p><a href="#sec-ch02mcexercise13">MC Exercise 13</a></p>
<p><strong>Correct Answer:</strong> b) <span class="math inline">\(P(A|B) = \dfrac{P(A)}{P(B)}\)</span></p>
<p><strong>Explanation:</strong></p>
<p>If <span class="math inline">\(A \subseteq B\)</span>, then <span class="math inline">\(A \cap B = A\)</span>. Using the definition of <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)} = \dfrac{P(A)}{P(B)}\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution14">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution14">MC Solution 14</h3>
<p><a href="#sec-ch02mcexercise14">MC Exercise 14</a></p>
<p><strong>Correct Answer:</strong> c) <span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span></p>
<p><strong>Explanation:</strong></p>
<p>This is part of the definition of <strong>mutual independence</strong> for three or more events (<strong>Definition 2.3</strong> in the text). In addition to pairwise independence, the probability of the intersection of all events must be equal to the product of their individual probabilities.</p>
</section>
<section class="level3" id="sec-ch02mcsolution15">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution15">MC Solution 15</h3>
<p><a href="#sec-ch02mcexercise15">MC Exercise 15</a></p>
<p><strong>Correct Answer:</strong> b) Even with a fair game, a gambler with finite capital will eventually go bankrupt with probability 1.</p>
<p><strong>Explanation:</strong></p>
<p>The <strong>Gambler’s Ruin</strong> problem demonstrates that in a fair game (where the probability of winning each round is 0.5), a gambler with finite capital playing against an opponent with infinite capital will eventually go bankrupt with probability 1. This is a surprising result that highlights the importance of considering long-term outcomes in situations with repeated trials.</p>
</section>
<section class="level3" id="sec-ch02mcsolution16">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution16">MC Solution 16</h3>
<p><a href="#sec-ch02mcexercise16">MC Exercise 16</a></p>
<p><strong>Correct Answer:</strong> a) 0.3</p>
<p><strong>Explanation:</strong></p>
<p>We are given <span class="math inline">\(P(A|B) = 0.6\)</span> and <span class="math inline">\(P(B) = 0.5\)</span>. We want to find <span class="math inline">\(P(A \cap B)\)</span>.</p>
<p>Using the definition of <strong>conditional probability</strong>:</p>
<p><span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)}\)</span>.</p>
<p>Rearranging to solve for <span class="math inline">\(P(A \cap B)\)</span>, we get:</p>
<p><span class="math inline">\(\begin{aligned}
P(A \cap B) &amp;= P(A|B)P(B) \\
&amp;= (0.6)(0.5) \\
&amp;= 0.3
\end{aligned}\)</span>.</p>
<p>Therefore, <span class="math inline">\(P(A \cap B) = 0.3\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution17">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution17">MC Solution 17</h3>
<p><a href="#sec-ch02mcexercise17">MC Exercise 17</a></p>
<p><strong>Correct Answer:</strong> a) <span class="math inline">\(P(A|B) = P(B|A)\)</span> if and only if <span class="math inline">\(P(A) = P(B)\)</span></p>
<p><strong>Explanation:</strong></p>
<p>From the definition of conditional probability, we have <span class="math inline">\(P(A|B) = \dfrac{P(A \cap B)}{P(B)}\)</span> and <span class="math inline">\(P(B|A) = \dfrac{P(A \cap B)}{P(A)}\)</span>.</p>
<p>If <span class="math inline">\(P(A|B) = P(B|A)\)</span>, then <span class="math inline">\(\dfrac{P(A \cap B)}{P(B)} = \dfrac{P(A \cap B)}{P(A)}\)</span>.</p>
<p>This implies that <span class="math inline">\(P(A \cap B)P(A) = P(A \cap B)P(B)\)</span>.</p>
<p>If <span class="math inline">\(P(A \cap B) \neq 0\)</span>, we can divide both sides by <span class="math inline">\(P(A \cap B)\)</span> and get <span class="math inline">\(P(A) = P(B)\)</span>.</p>
<p>If <span class="math inline">\(P(A \cap B) = 0\)</span>, then both <span class="math inline">\(P(A|B)\)</span> and <span class="math inline">\(P(B|A)\)</span> are 0, but we cannot conclude anything about the relationship between <span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span>.</p>
<p>Therefore, the statement is true: <span class="math inline">\(P(A|B) = P(B|A)\)</span> if and only if <span class="math inline">\(P(A) = P(B)\)</span> when <span class="math inline">\(P(A \cap B) \neq 0\)</span>. The case when <span class="math inline">\(P(A \cap B) = 0\)</span> does not contradict the statement.</p>
</section>
<section class="level3" id="sec-ch02mcsolution18">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution18">MC Solution 18</h3>
<p><a href="#sec-ch02mcexercise18">MC Exercise 18</a></p>
<p><strong>Correct Answer:</strong> c) <span class="math inline">\(P(A) + P(B) - P(A)P(B)\)</span></p>
<p><strong>Explanation:</strong></p>
<p>For any two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we have:</p>
<p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>.</p>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong>, then <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span>. Substituting this into the equation above, we get:</p>
<p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A)P(B)\)</span>.</p>
</section>
<section class="level3" id="sec-ch02mcsolution19">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution19">MC Solution 19</h3>
<p><a href="#sec-ch02mcexercise19">MC Exercise 19</a></p>
<p><strong>Correct Answer:</strong> b) Decreases</p>
<p><strong>Explanation:</strong></p>
<p>In the sequential trading model, a higher probability of an informed trader (<span class="math inline">\(\mu\)</span>) means that a buy order is more likely to come from an informed trader who knows the stock value is high (<span class="math inline">\(V_H\)</span>). Therefore, observing a buy order provides stronger evidence that the stock value is high, and the posterior probability of the stock having a low value (<span class="math inline">\(V_L\)</span>) given a buy order decreases.</p>
<p>Looking at the formula derived in the text:</p>
<p><span class="math inline">\(P(V = V_L | \text{buy}) = \dfrac{1 - \mu}{1 + \mu(1 - 2\delta)} \times \delta\)</span>.</p>
<p>As <span class="math inline">\(\mu\)</span> increases, the numerator <span class="math inline">\((1 - \mu)\)</span> decreases, and the denominator <span class="math inline">\((1 + \mu(1 - 2\delta))\)</span> increases (assuming <span class="math inline">\(\delta &lt; 0.5\)</span>, which is usually the case for a low value probability). Therefore, the overall fraction decreases as <span class="math inline">\(\mu\)</span> increases.</p>
</section>
<section class="level3" id="sec-ch02mcsolution20">
<h3 class="anchored" data-anchor-id="sec-ch02mcsolution20">MC Solution 20</h3>
<p><a href="#sec-ch02mcexercise20">MC Exercise 20</a></p>
<p><strong>Correct Answer:</strong> c) The updated probability of an event after considering new evidence.</p>
<p><strong>Explanation:</strong></p>
<p>In <strong>Bayes’ Theorem</strong>, the <strong>posterior probability</strong> <span class="math inline">\(P(A|B)\)</span> represents the updated probability of event <span class="math inline">\(A\)</span> after observing the evidence <span class="math inline">\(B\)</span>. It is calculated by combining the <strong>prior probability</strong> <span class="math inline">\(P(A)\)</span> with the <strong>likelihood</strong> <span class="math inline">\(P(B|A)\)</span> and the probability of the evidence <span class="math inline">\(P(B)\)</span>.</p>
</section>
</section>
</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>

</div> <!-- /content -->
<footer class="footer">
<div class="nav-footer">
<div class="nav-footer-left">
<p>Author: Peter Fuleky</p>
</div>
<div class="nav-footer-center">
       
    </div>
<div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a></p>
</div>
</div>
</footer>
</body></html>