<!DOCTYPE html>

<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
<meta charset="utf-8"/>
<meta content="quarto-1.5.57" name="generator"/>
<meta content="width=device-width, initial-scale=1.0, user-scalable=yes" name="viewport"/>
<meta content="Peter Fuleky" name="author"/>
<title>Chapter 13: Confidence Intervals and Sets – Study notes for Econometrics I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>
<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta content="../" name="quarto:offset"/>
<link href="../chapters/chap14.html" rel="next"/>
<link href="../chapters/chap12.html" rel="prev"/>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet"/>
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" id="quarto-text-highlighting-styles" rel="stylesheet"/>
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet"/>
<link data-mode="light" href="../site_libs/bootstrap/bootstrap.min.css" id="quarto-bootstrap" rel="stylesheet"/>
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<link href="../style.css" rel="stylesheet"/>
</head>
<body class="nav-sidebar floating">
<div id="quarto-search-results"></div>
<header class="headroom fixed-top" id="quarto-header">

</header>
<!-- content -->
<div class="quarto-container page-columns page-rows-contents page-layout-article" id="quarto-content">
<!-- sidebar -->

<div class="quarto-sidebar-collapse-item" data-bs-target=".quarto-sidebar-collapse-item" data-bs-toggle="collapse" id="quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
<div class="sidebar margin-sidebar" id="quarto-margin-sidebar">

</div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header class="quarto-title-block default" id="title-block-header">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 13: Confidence Intervals and Sets</span></h1>
</div>
<div class="quarto-title-meta">
</div>
</header>
<section class="level2" id="definitions">
<h2 class="anchored" data-anchor-id="definitions">13.1 DEFINITIONS</h2>
<p><strong>Confidence sets</strong> are a way of summarizing information about the precision of an estimator <span class="math inline">\(\hat{\theta}\)</span> of a parameter <span class="math inline">\(\theta\)</span>. A confidence set <span class="math inline">\(C_{\alpha}(X^{n}) \subseteq \Theta \subseteq \mathbb{R}^{p}\)</span> is chosen such that</p>
<p><span class="math display">\[
\text{Exact} \quad \text{Pr}[\theta \in C_{\alpha}(X^{n})] = 1 - \alpha
\]</span></p>
<p><span class="math display">\[
\text{Approximate} \quad \lim_{n \to \infty} \text{Pr}[\theta \in C_{\alpha}(X^{n})] = 1 - \alpha.
\]</span></p>
<p>We say that the <strong>coverage</strong> of this set is <span class="math inline">\(1 - \alpha\)</span> (or approximate coverage), e.g., if <span class="math inline">\(\alpha \sim 0.05\)</span>, the set has 95% coverage. Note that <span class="math inline">\(C_{\alpha}(X^{n})\)</span> is a <strong>random set</strong>, designed to vary from sample to sample to achieve the stated coverage. For a univariate parameter, <span class="math inline">\(C_{\alpha}(X^{n})\)</span> will usually be an interval</p>
<p><span class="math display">\[
[L(X^{n}), U(X^{n})] \subset \Theta \subset \mathbb{R}.
\]</span></p>
<p>The smaller the interval the more confidence we have in the estimate.</p>
<section class="level3" id="example-13.1.">
<h3 class="anchored" data-anchor-id="example-13.1.">Example 13.1.</h3>
<p>The opinion poll might say that of all voters 45% <span class="math inline">\(\pm\)</span> 3% would vote for President Trump. Here, 45% is an estimate derived from a sample of voters and 3% is the ‘margin of error.’ This says that if we were to draw a large number of similar samples and form the interval from them, then the true value (parameter) lies in these intervals with the stated probability, usually 95%. What is the probability that he wins the election?</p>
<p>A general method for constructing confidence intervals can be based on a statistic <span class="math inline">\(T(X^{n}, \theta)\)</span> whose distribution is known exactly or approximately. We let</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \{\theta: L \leq T(X^{n}, \theta) \leq U\},
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\text{Exact} \quad \text{Pr}(L \leq T(X^{n}, \theta) \leq U) = 1 - \alpha,
\]</span></p>
<p><span class="math display">\[
\text{Approximate} \quad \lim_{n \to \infty} \text{Pr}(L \leq T(X^{n}, \theta) \leq U) = 1 - \alpha,
\]</span></p>
<p>and the probability is calculated under <span class="math inline">\(\theta\)</span>. The confidence interval is basically the set of non-rejectable null hypotheses about <span class="math inline">\(\theta\)</span>.</p>
</section>
<section class="level3" id="example-13.2.">
<h3 class="anchored" data-anchor-id="example-13.2.">Example 13.2.</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, \sigma^{2})\)</span> with <span class="math inline">\(\sigma^{2}\)</span> known. Then</p>
<p><span class="math display">\[
T = \frac{X - \mu}{\sigma / \sqrt{n}} \sim N(0, 1).
\]</span></p>
<p>It follows that a two-sided coverage <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[
\begin{aligned}
C_{\alpha}(X^{n}) &amp;= \left\{\mu: -z_{\alpha/2} \leq T \leq z_{\alpha/2} \right\} \\
&amp;= \left\{\mu: -z_{\alpha/2} \leq \frac{X - \mu}{\sigma / \sqrt{n}} \leq z_{\alpha/2} \right\}.
\end{aligned}
\]</span></p>
<p>We may rewrite this interval as</p>
<p><span class="math display">\[
\begin{aligned}
C_{\alpha}(X^{n}) &amp;= \left[X - \frac{\sigma z_{\alpha/2}}{\sqrt{n}}, X + \frac{\sigma z_{\alpha/2}}{\sqrt{n}} \right] \\
&amp;= X \pm \frac{\sigma z_{\alpha/2}}{\sqrt{n}}.
\end{aligned}
\]</span></p>
<p>The acceptance region of the test of the null hypothesis that <span class="math inline">\(\mu = \mu_{0}\)</span> (against two-sided alternative) using</p>
<p><span class="math display">\[
T = \frac{X - \mu_{0}}{\sigma / \sqrt{n}}
\]</span></p>
<p>is <span class="math inline">\(\{T: -z_{\alpha/2} \leq T \leq z_{\alpha/2}\}\)</span>, which can be rewritten for <span class="math inline">\(X\)</span> as</p>
<p><span class="math display">\[
\begin{aligned}
C_{\alpha}(\mu_{0}) &amp;= \left\{x: x \in \left[\mu_{0} - \frac{\sigma z_{\alpha/2}}{\sqrt{n}}, \mu_{0} + \frac{\sigma z_{\alpha/2}}{\sqrt{n}} \right] \right\} \\
&amp;= \mu_{0} \pm \frac{\sigma z_{\alpha/2}}{\sqrt{n}}.
\end{aligned}
\]</span></p>
<p>We accept the null hypothesis when <span class="math inline">\(X \in C_{\alpha}(\mu_{0})\)</span>. We have for any <span class="math inline">\(\mu_{0} \in C_{\alpha}(X^{n})\)</span> that <span class="math inline">\(X \in C_{\alpha}(\mu_{0})\)</span>. A <strong>confidence interval</strong> is a region of parameter space determined by the data that contains the true parameter with given probability. An <strong>acceptance region</strong> is a region of the data (test statistic) determined by the null hypothesis that contains the test statistic with given probability.</p>
</section>
<section class="level3" id="example-13.3.">
<h3 class="anchored" data-anchor-id="example-13.3.">Example 13.3.</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, \sigma^{2})\)</span> with <span class="math inline">\(\sigma^{2}\)</span> unknown. Then, a two-sided coverage <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[
\begin{aligned}
C_{\alpha}(X^{n}) &amp;= \left[X - \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}}, X + \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}} \right] \\
&amp;= X \pm \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}}.
\end{aligned}
\]</span></p>
<p>The acceptance region for the test of <span class="math inline">\(\mu = \mu_{0}\)</span> is the set where <span class="math inline">\(X\)</span> lies in</p>
<p><span class="math display">\[
C_{\alpha} = \mu_{0} \pm \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}}.
\]</span></p>
</section>
<section class="level3" id="example-13.4.">
<h3 class="anchored" data-anchor-id="example-13.4.">Example 13.4.</h3>
<p>A two-sided asymptotic coverage <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[
\begin{aligned}
C_{\alpha}(X^{n}) &amp;= \left[X - \frac{s z_{\alpha/2}}{\sqrt{n}}, X + \frac{s z_{\alpha/2}}{\sqrt{n}} \right] \\
&amp;= X \pm \frac{s z_{\alpha/2}}{\sqrt{n}}.
\end{aligned}
\]</span></p>
</section>
<section class="level3" id="example-13.5.">
<h3 class="anchored" data-anchor-id="example-13.5.">Example 13.5.</h3>
<p>Suppose that <span class="math inline">\(X \sim N(0, \sigma^{2})\)</span> with <span class="math inline">\(\sigma^{2}\)</span> unknown. We make use of the fact that in this case</p>
<p><span class="math display">\[
\frac{n s^{2}}{\sigma^{2}} \sim \chi^{2}(n) \tag{13.1}
\]</span></p>
<p>so that</p>
<p><span class="math display">\[
\text{Pr} \left( \chi^{2}_{\alpha/2}(n) \leq \frac{n s^{2}}{\sigma^{2}} \leq \chi^{2}_{1 - \alpha/2}(n) \right) = 1 - \alpha.
\]</span></p>
<p>Then, a two-sided coverage <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\sigma^{2}\)</span> is given by</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left[ \frac{n s^{2}}{\chi^{2}_{1 - \alpha/2}(n)}, \frac{n s^{2}}{\chi^{2}_{\alpha/2}(n)} \right].
\]</span></p>
<p>This confidence interval is not symmetric because the chi-squared distribution is not symmetric. Note that with probability one <span class="math inline">\(C_{\alpha}(X^{n}) \subset (0, \infty)\)</span>, i.e., it respects that fact that <span class="math inline">\(\sigma^{2} &gt; 0\)</span>.</p>
</section>
</section>
<section class="level2" id="general-large-sample-setting">
<h2 class="anchored" data-anchor-id="general-large-sample-setting">13.1.1 General Large Sample Setting</h2>
<p>Suppose that</p>
<p><span class="math display">\[
T_{n} = \sqrt{n} (\hat{\theta} - \theta) \xrightarrow{D} N(0, V(\theta, \phi)),
\]</span></p>
<p>where <span class="math inline">\(V(\theta, \phi)\)</span> is a known unknown (i.e., a known function of the unknown parameters <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\phi\)</span>). Then provided <span class="math inline">\(V\)</span> is continuous in <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\phi\)</span> and we have a consistent estimator <span class="math inline">\(\hat{\phi} \xrightarrow{P} \phi\)</span>, we have</p>
<p><span class="math display">\[
\frac{\sqrt{n} (\hat{\theta} - \theta)}{\sqrt{V(\hat{\theta}, \hat{\phi})}} \xrightarrow{D} N(0, 1).
\]</span></p>
<p>Therefore, we may take the confidence interval</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \hat{\theta} \pm \frac{z_{\alpha/2} \sqrt{V(\hat{\theta}, \hat{\phi})}}{\sqrt{n}}.
\]</span></p>
<section class="level3" id="example-13.6.">
<h3 class="anchored" data-anchor-id="example-13.6.">Example 13.6.</h3>
<p>Suppose I want to predict future stock returns <span class="math inline">\(Y\)</span> and I have a predictor, <span class="math inline">\(X\)</span>. Suppose that <span class="math inline">\(E(X) = E(Y) = 0\)</span> and <span class="math inline">\(E(XY) = \rho\)</span>. Furthermore, define <span class="math inline">\(\text{var}(XY) = v = E(X^{2} Y^{2}) - E^{2}(XY)\)</span>. Suppose that we observe a random sample <span class="math inline">\(\{X_{1}, Y_{1}, \dots, X_{n}, Y_{n}\}\)</span>. Let</p>
<p><span class="math display">\[
\hat{\rho} = \frac{1}{n} \sum_{i = 1}^{n} X_{i} Y_{i}.
\]</span></p>
<p>The CLT says that</p>
<p><span class="math display">\[
\sqrt{n} (\hat{\rho} - \rho) = \frac{1}{\sqrt{n}} \sum_{i = 1}^{n} (X_{i} Y_{i} - E(X_{i} Y_{i})) \xrightarrow{D} N(0, v).
\]</span></p>
<p>The confidence interval is</p>
<p><span class="math display">\[
\hat{\rho} \pm z_{\alpha/2} \frac{\sqrt{\hat{v}}}{\sqrt{n}}; \quad \hat{v} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}^{2} Y_{i}^{2} - \left( \frac{1}{n} \sum_{i = 1}^{n} X_{i} Y_{i} \right)^{2}.
\]</span> Let <span class="math inline">\(Y_i=r_i\)</span> and <span class="math inline">\(X_i = r_{i-j}\)</span>; and <span class="math inline">\(Y_i=|r_i|\)</span> and <span class="math inline">\(X_i = |r_{i-j}|\)</span>, where <span class="math inline">\(r_i\)</span> is the stock return at period <span class="math inline">\(i\)</span>. See Figures 13.1, 13.2 and 13.3 for examples with S&amp;P500 daily returns.</p>
<p>A good confidence interval shrinks with sample size, that is, as <span class="math inline">\(n \to \infty\)</span> we have <span class="math inline">\(C_{\alpha}(X^{n}) \to \{\theta\}\)</span> in some sense, because <span class="math inline">\(\hat{\theta} \to \theta\)</span> and <span class="math inline">\(V(\hat{\theta}, \hat{\phi}) / n \to 0\)</span>.</p>
</section>
</section>
<section class="level2" id="likelihood-ratio-confidence-interval">
<h2 class="anchored" data-anchor-id="likelihood-ratio-confidence-interval">13.2 LIKELIHOOD RATIO CONFIDENCE INTERVAL</h2>
<p>The <strong>likelihood ratio statistic</strong> for the simple null of <span class="math inline">\(\theta = \theta_{0}\)</span> is</p>
<p><span class="math display">\[
\lambda(X^{n}; \theta_{0}) = \frac{\max_{\theta \in \Theta} L(\theta | X^{n})}{L(\theta_{0} | X^{n})}.
\]</span></p>
<p>An LRT is any test that accepts when <span class="math inline">\(\lambda(X^{n}; \theta_{0}) \leq c_{\alpha}\)</span> for some determined <span class="math inline">\(c_{\alpha}\)</span>. An LR confidence interval is of the form</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \{\theta_{0}: \lambda(X^{n}; \theta_{0}) \leq c_{\alpha}\}.
\]</span></p>
<section class="level3" id="example-13.7.">
<h3 class="anchored" data-anchor-id="example-13.7.">Example 13.7.</h3>
<p><span class="math inline">\(X \sim N(\mu, 1)\)</span>. <span class="math inline">\(H_{0}: \mu = \mu_{0}\)</span> vs. <span class="math inline">\(H_{A}: \mu \neq \mu_{0}\)</span>. In this case</p>
<p><span class="math display">\[
\log \lambda(X^{n}) = \frac{n}{2} (X - \mu_{0})^{2}.
\]</span></p>
<p>The distribution of <span class="math inline">\(2 \log \lambda(X^{n})\)</span> is <span class="math inline">\(\chi^{2}(1)\)</span>. Therefore, we have</p>
<p><span class="math display">\[
\begin{aligned}
\left\{\mu_{0}: n (X - \mu_{0})^{2} \leq \chi^{2}_{\alpha}(1) \right\}
&amp;= \left\{\mu_{0}: -\sqrt{\frac{\chi^{2}_{\alpha}(1)}{n}} \leq X - \mu_{0} \leq \sqrt{\frac{\chi^{2}_{\alpha}(1)}{n}} \right\} \\
&amp;= \left\{\mu_{0}: X - \sqrt{\frac{\chi^{2}_{\alpha}(1)}{n}} \leq \mu_{0} \leq X + \sqrt{\frac{\chi^{2}_{\alpha}(1)}{n}} \right\} \\
&amp;= \left\{\mu_{0}: X - \frac{z_{\alpha/2}}{\sqrt{n}} \leq \mu_{0} \leq X + \frac{z_{\alpha/2}}{\sqrt{n}} \right\}.
\end{aligned}
\]</span></p>
<p>In general, the method is to obtain the critical value from the large sample distribution of LRT.</p>
</section>
<section class="level3" id="example-13.8.">
<h3 class="anchored" data-anchor-id="example-13.8.">Example 13.8.</h3>
<p>Consider the Exponential distribution with <span class="math inline">\(f(x | \theta) = \frac{1}{\theta} e^{-x / \theta}\)</span>, <span class="math inline">\(0 \leq x &lt; \infty\)</span>, <span class="math inline">\(\theta &gt; 0\)</span>. <span class="math inline">\(H_{0}: \theta = \theta_{0}\)</span></p>
<p><span class="math display">\[
l(\theta | X_{n}) = -n \log \theta - \frac{1}{\theta} \sum_{i = 1}^{n} X_{i},
\]</span></p>
<p>which implies that <span class="math inline">\(\hat{\theta}_{MLE} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}\)</span>. Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
\lambda &amp;= \exp(l_{n}(\theta_{0}) - l_{n}(\hat{\theta}_{MLE})) \\
&amp;= \frac{\theta_{0}^{n} \exp \left( - \sum_{i = 1}^{n} X_{i} / \theta_{0} \right)}{\left( \frac{1}{n} \sum_{i = 1}^{n} X_{i} \right)^{n} \exp(-n)} \\
&amp;= \frac{\theta_{0}^{n} e^{- \sum_{i = 1}^{n} X_{i} / \theta_{0}}}{\left( \frac{\sum_{i = 1}^{n} X_{i}}{n} \right)^{n} e^{-n}}.
\end{aligned}
\]</span></p>
<p><span class="math display">\[
A(\theta_{0}) = \left\{ X^{n}: \left( \frac{\sum_{i = 1}^{n} X_{i}}{\theta_{0}} \right)^{n} e^{- \frac{\sum_{i = 1}^{n} X_{i}}{\theta_{0}}} \geq c_{\alpha} \right\},
\]</span></p>
<p>where <span class="math inline">\(c_{\alpha}\)</span> satisfied <span class="math inline">\(\text{Pr}(X^{n} \in A(\theta_{0})) = 1 - \alpha\)</span>. The confidence set is</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left\{\theta: \left( \frac{\sum_{i = 1}^{n} X_{i}}{\theta} \right)^{n} e^{- \frac{\sum_{i = 1}^{n} X_{i}}{\theta}} \geq c_{\alpha} \right\}.
\]</span></p>
<p>This is a nonlinear equation in <span class="math inline">\(\theta\)</span>. Note that this set is determined only by <span class="math inline">\(\sum_{i = 1}^{n} X_{i}\)</span> and <span class="math inline">\(n\)</span>. Therefore, we can express this set equivalently as</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left\{\theta: a_{n} \cdot \sum_{i = 1}^{n} X_{i} \leq \theta \leq b_{n} \cdot \sum_{i = 1}^{n} X_{i} \right\},
\]</span></p>
<p>where <span class="math inline">\(a_{n}\)</span>, <span class="math inline">\(b_{n}\)</span> are chosen to satisfy coverage <span class="math inline">\(1 - \alpha\)</span>. Note these are not the usual symmetric intervals we have in normal theory because the parameter space is restricted, and <span class="math inline">\(X &gt; 0\)</span> and has a skewed distribution. However, in large samples the confidence interval is going to approach the usual interval <span class="math inline">\(X \pm z_{\alpha/2} \sigma / \sqrt{n}\)</span> because of the asymptotic normality of <span class="math inline">\(\sum_{i = 1}^{n} X_{i}\)</span> after standardization.</p>
</section>
<section class="level3" id="example-13.9.">
<h3 class="anchored" data-anchor-id="example-13.9.">Example 13.9.</h3>
<p>Suppose that <span class="math inline">\(X \sim U(0, \theta)\)</span>, and consider the hypothesis <span class="math inline">\(\theta = \theta_{0}\)</span>. We have</p>
<p><span class="math display">\[
\begin{gathered}
\hat{\theta} = \max\{X_{1}, \dots, X_{n}\} \\
L(\theta | X^{n}) = \frac{1}{\theta^{n}} \mathbb{1}_{\{\max_{1 \leq i \leq n} X_{i} \leq \theta\}} \\
\lambda(X^{n}) = \left( \frac{\hat{\theta}}{\theta_{0}} \right)^{n} \mathbb{1}_{\{\max_{1 \leq i \leq n} X_{i} \leq \theta_{0}\}}.
\end{gathered}
\]</span></p>
<p>If <span class="math inline">\(\theta_{0} &lt; \max_{1 \leq i \leq n} X_{i}\)</span> you clearly reject, but under the null this never happens. Reject if <span class="math inline">\(\lambda(X^{n}) \leq c_{\alpha}\)</span>. The confidence interval is</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left\{ \theta_{0}: \left( \frac{\hat{\theta}}{\theta_{0}} \right)^{n} \mathbb{1}_{\{\max_{1 \leq i \leq n} X_{i} \leq \theta_{0}\}} \geq c_{\alpha} \right\}.
\]</span></p>
<p>It is going to be of the form (<span class="math inline">\(c_{\alpha}\)</span> is going to be less than 1)</p>
<p><span class="math display">\[
\left[ \hat{\theta}, \frac{\hat{\theta}}{c_{\alpha}^{1/n}} \right].
\]</span></p>
<p>In this case, <span class="math inline">\(\hat{\theta}\)</span> is not asymptotically normal; in fact it converges at rate <span class="math inline">\(n\)</span> to an extreme value distribution. The confidence set is naturally one-sided. The asymptotic interval can be obtained from the limiting distribution of <span class="math inline">\(\hat{\theta}\)</span>, which is extreme value.</p>
</section>
<section class="level3" id="example-13.10.">
<h3 class="anchored" data-anchor-id="example-13.10.">Example 13.10.</h3>
<p>Suppose that <span class="math inline">\(X \sim \text{Be}(p)\)</span> want an interval for the binary proportion <span class="math inline">\(p\)</span>. Recall that</p>
<p><span class="math display">\[
\text{Pr} \left( \sum_{i = 1}^{n} X_{i} \leq k \right) = \sum_{j = 0}^{k} \binom{n}{j} p^{j} (1 - p)^{n - j}.
\]</span></p>
<p>Therefore, an exact interval <span class="math inline">\([p_{L}, p_{U}]\)</span> could be obtained by solving the two equations</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{j = 0}^{\sum_{i = 1}^{n} X_{i}} \binom{n}{j} p_{U}^{j} (1 - p_{U})^{n - j} &amp;= 1 - \frac{\alpha}{2} \\
\sum_{j = 0}^{\sum_{i = 1}^{n} X_{i}} \binom{n}{j} p_{L}^{j} (1 - p_{L})^{n - j} &amp;= \frac{\alpha}{2}.
\end{aligned}
\]</span></p>
<p>This can only be solved for certain values of <span class="math inline">\(\alpha\)</span>, depending on <span class="math inline">\(n\)</span>. Blyth (1986) showed that for those <span class="math inline">\(\alpha\)</span></p>
<p><span class="math display">\[
\frac{1}{1 + \frac{n - x + 1}{x} F_{\alpha/2}(2(n - x + 1), 2x)} \leq p \leq \frac{\frac{x + 1}{n - x} F_{\alpha/2}(2(x + 1), 2(n - x))}{1 + \frac{x + 1}{n - x} F_{\alpha/2}(2(x + 1), 2(n - x))}
\]</span></p>
<p>forms an exact interval.</p>
</section>
<section class="level3" id="example-13.11.">
<h3 class="anchored" data-anchor-id="example-13.11.">Example 13.11.</h3>
<p>We next consider large sample confidence intervals. Try the (Wald) test statistic for <span class="math inline">\(H_{0}: p = p_{0}\)</span>, <span class="math inline">\(H_{A}: p \neq p_{0}\)</span></p>
<p><span class="math display">\[
T = \sqrt{n} \frac{(\hat{p} - p_{0})}{\sqrt{\hat{p} (1 - \hat{p})}}; \quad \hat{p} = \frac{1}{n} \sum_{i = 1}^{n} X_{i} = \frac{k}{n}.
\]</span></p>
<p>We know that under <span class="math inline">\(H_{0}\)</span></p>
<p><span class="math display">\[
T \xrightarrow{D} N(0, 1).
\]</span></p>
<p>It follows that a two-sided coverage <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(p\)</span> is given by</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \{p: -z_{\alpha/2} \leq T \leq z_{\alpha/2}\},
\]</span></p>
<p>which can be rewritten as</p>
<p><span class="math display">\[
\hat{p} \pm \frac{\sqrt{\hat{p} (1 - \hat{p})}}{\sqrt{n}} z_{\alpha/2}.
\]</span></p>
<p>Take <span class="math inline">\(n = 60\)</span>, <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(\hat{p} \pm 0.253 \sqrt{\hat{p} (1 - \hat{p})}\)</span>. This is fine except when either <span class="math inline">\(\hat{p} = 0\)</span> or <span class="math inline">\(\hat{p} = 1\)</span>, which can happen when the sample size is small and <span class="math inline">\(p_{0}\)</span> is close to <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. Consider an alternative (LM) test statistic</p>
<p><span class="math display">\[
T^{*} = \frac{\sqrt{n} (\hat{p} - p_{0})}{\sqrt{p_{0} (1 - p_{0})}}. \tag{13.2}
\]</span></p>
<p>The corresponding confidence interval is</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \{p_{0}: -z_{\alpha/2} \leq T^{*} \leq z_{\alpha/2}\}. \tag{13.3}
\]</span></p>
<p>What is this set? We have</p>
<p><span class="math display">\[
\begin{aligned}
\left\{ p_{0}: \frac{n (\hat{p} - p_{0})^{2}}{p_{0} (1 - p_{0})} \leq z_{\alpha/2}^{2} \right\}
&amp;= \left\{ p_{0}: n (\hat{p} - p_{0})^{2} \leq z_{\alpha/2}^{2} p_{0} (1 - p_{0}) \right\} \\
&amp;= \left\{ p_{0}: n \hat{p}^{2} - 2 n \hat{p} p_{0} + n p_{0}^{2} - z_{\alpha/2}^{2} p_{0} + z_{\alpha/2}^{2} p_{0}^{2} \leq 0 \right\} \\
&amp;= \left\{ p_{0}: (n + z_{\alpha/2}^{2}) p_{0}^{2} - (2 n \hat{p} + z_{\alpha/2}^{2}) p_{0} + n \hat{p}^{2} \leq 0 \right\}.
\end{aligned}
\]</span></p>
<p>The set consists of all points between the two roots of the quadratic equation, i.e.,</p>
<p><span class="math display">\[
\frac{(2 n \hat{p} + z_{\alpha/2}^{2}) \pm \sqrt{(2 n \hat{p} + z_{\alpha/2}^{2})^{2} - 4 (n + z_{\alpha/2}^{2}) n \hat{p}^{2}}}{2 (n + z_{\alpha/2}^{2})}.
\]</span></p>
<p>This works also when <span class="math inline">\(\hat{p} \in \{0, 1\}\)</span>. For example, suppose that <span class="math inline">\(\hat{p} = 0\)</span>. Then</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left\{p_{0}: p_{0} \leq \frac{z_{\alpha/2}^{2}}{n + z_{\alpha/2}^{2}} \right\}.
\]</span></p>
<p>For <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(n = 10\)</span>, we get <span class="math inline">\([0, 0.28]\)</span>. For <span class="math inline">\(n = 100\)</span>, we get <span class="math inline">\([0, 0.037]\)</span>.</p>
</section>
</section>
<section class="level2" id="a-bayesian-interval">
<h2 class="anchored" data-anchor-id="a-bayesian-interval">13.2.1 A Bayesian Interval</h2>
<p>We consider how to construct a Bayesian confidence interval. We will work with the specific Binomial case for simplicity. Suppose that one observes <span class="math inline">\(k\)</span> values of <span class="math inline">\(X = 1\)</span> and <span class="math inline">\(n - k\)</span> values of <span class="math inline">\(X = 0\)</span>, and suppose that the prior distribution on <span class="math inline">\(p\)</span>, <span class="math inline">\(\pi(p)\)</span>, is uniform over <span class="math inline">\([0, 1]\)</span>. In this case, we have seen that the posterior density of <span class="math inline">\(p\)</span> is</p>
<p><span class="math display">\[
\pi(p | X^{n}) = \frac{(n + 1)!}{k! (n - k)!} p^{k} (1 - p)^{n - k}.
\]</span></p>
<p>In fact, this is the distribution of a <span class="math inline">\(\text{Beta}(k + 1, n - k + 1)\)</span> random variable. A Bayesian interval <span class="math inline">\([L, U]\)</span> satisfies</p>
<p><span class="math display">\[
\int_{L}^{U} \pi(p | X^{n}) dp = 1 - \alpha.
\]</span></p>
<p>In general there are many solutions to this equation. The simplest approach is to take equal tail probabilities, that is, <span class="math inline">\(\int_{0}^{L} \pi(p | X^{n}) dp = \int_{U}^{1} \pi(p | X^{n}) dp = \alpha / 2\)</span>. An alternative approach is called <strong>Highest Posterior Density</strong> (HPD), which selects <span class="math inline">\(L\)</span>, <span class="math inline">\(U\)</span> subject to the criterion that <span class="math inline">\(\pi(p | X^{n}) \geq c\)</span> for some constant <span class="math inline">\(c\)</span> (to be determined). That is, we find <span class="math inline">\(L\)</span>, <span class="math inline">\(U\)</span> such that <span class="math inline">\(\pi(p | X^{n})\)</span> is maximized. May find simulation methods convenient to calculate the integral.</p>
<p>Consider the special case that <span class="math inline">\(k = 0\)</span> so that <span class="math inline">\(\hat{p} = 0\)</span>, in which case we have to solve</p>
<p><span class="math display">\[
(n + 1) \int_{0}^{U} (1 - p)^{n} dp = 1 - \alpha = (1 - (1 - U)^{n + 1}).
\]</span></p>
<p>Therefore, <span class="math inline">\(U = 1 - \alpha^{1 / (n + 1)}\)</span>. When taking the significance level <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(n = 10\)</span>, one obtains <span class="math inline">\(U = 0.238\)</span>, which means that with 95% confidence we may assert that the random set <span class="math inline">\([0, 0.238]\)</span> contains <span class="math inline">\(p\)</span>. When <span class="math inline">\(n = 100\)</span> we obtain <span class="math inline">\([0, 0.029]\)</span>.</p>
<section class="level3" id="example-13.12.">
<h3 class="anchored" data-anchor-id="example-13.12.">Example 13.12.</h3>
<p>Suppose that the population probability in favour of Remain is <span class="math inline">\(p \in [0, 1]\)</span> and we sample <span class="math inline">\(n = 100\)</span> individuals and find that <span class="math inline">\(k = 55\)</span> of them are in favour of Remain. What is the probability that <span class="math inline">\(p &gt; 1/2\)</span>? We suppose again the ignorance prior, whence</p>
<p><span class="math display">\[
\frac{101!}{55! 45!} \int_{0.5}^{1} p^{55} (1 - p)^{45} dp = 0.84014.
\]</span></p>
</section>
</section>
<section class="level2" id="methods-of-evaluating-intervals">
<h2 class="anchored" data-anchor-id="methods-of-evaluating-intervals">13.3 METHODS OF EVALUATING INTERVALS</h2>
<ol type="1">
<li><p><strong>Intrinsic beauty</strong> of <span class="math inline">\(C_{\alpha}(X^{n})\)</span>, or rather convenience and plausibility. One might prefer intervals and connected sets in general to sets with holes in. One might also wish that the confidence interval respects the parameter space, such as in the case of a variance parameter.</p></li>
<li><p>We generally want as small a confidence set as possible as this is most revealing. Formally, since the set is random, we consider the <strong>expected length</strong> (or volume) of <span class="math inline">\(C_{\alpha}(X^{n})\)</span>. The interval for the normal mean</p>
<p><span class="math display">\[
X \pm \frac{s_{*}}{\sqrt{n}} t_{\alpha/2}
\]</span></p>
<p>has length <span class="math inline">\(\frac{2 s_{*}}{\sqrt{n}} t_{\alpha/2}\)</span>, and expected squared length <span class="math inline">\(\frac{4 \sigma^{2}}{n} t_{\alpha/2}^{2}\)</span>. Any other interval has longer length, which we next show. Consider the interval</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left[X - \frac{s_{*} t_{\alpha_{1}}(n - 1)}{\sqrt{n}}, X + \frac{s_{*} t_{\alpha_{2}}(n - 1)}{\sqrt{n}} \right],
\]</span></p>
<p>where <span class="math inline">\(\alpha_{1} + \alpha_{2} = \alpha\)</span>. Let <span class="math inline">\(\alpha_{2} = \theta\)</span> and then <span class="math inline">\(\alpha_{1} = \alpha - \theta\)</span>, so we consider minimizing the length of the interval which is equivalent to</p>
<p><span class="math display">\[
\min_{\theta \in [0, \alpha]} Q(\theta) = \min_{\theta \in [0, \alpha]} F^{-1}(1 - \theta) - F^{-1}(\alpha - \theta), \tag{13.4}
\]</span></p>
<p>where <span class="math inline">\(F\)</span> is the c.d.f. of the t-distribution, which is symmetric about zero. The first order condition is</p>
<p><span class="math display">\[
Q'(\theta) = - \frac{1}{f(F^{-1}(1 - \theta))} + \frac{1}{f(F^{-1}(\alpha - \theta))} = 0,
\]</span></p>
<p>where <span class="math inline">\(f\)</span> is the density. When <span class="math inline">\(\theta = \alpha / 2\)</span>, <span class="math inline">\(F^{-1}(1 - \alpha / 2) = F^{-1}(\alpha / 2)\)</span> by symmetry. Therefore, the result follows (check the second order condition!).</p></li>
<li><p>A <strong>Uniformly Most Accurate</strong> (UMA) confidence interval minimizes the probability of <strong>False Coverage</strong></p>
<p><span class="math display">\[
\text{Pr}(\theta' \in C_{\alpha}(X^{n}) | \theta)
\]</span></p>
<p>uniformly over <span class="math inline">\(\theta' \in \Theta\)</span> with <span class="math inline">\(\theta' \neq \theta\)</span>. This is perhaps a more sensible notion of the length of the interval than the Lebesgue measure discussed above. This corresponds to the notion in testing theory of UMP tests. Such an interval is only available in the same special cases [i.e., one sided intervals].</p></li>
<li><p>One can restrict the optimality criterion by requiring that the confidence interval be <strong>unbiased</strong>, i.e.,</p>
<p><span class="math display">\[
\text{Pr}(\theta' \in C_{\alpha}(X^{n}) | \theta) \leq 1 - \alpha \quad \text{for all} \quad \theta' \neq \theta.
\]</span></p>
<p>We then have a theory of UMAU intervals which applies to two sided intervals. This parallels the theory of similar tests.</p></li>
</ol>
</section>
<section class="level2" id="exercises">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<section class="level3" id="sec-ch13exercise1">
<h3 class="anchored" data-anchor-id="sec-ch13exercise1">Exercise 1</h3>
<p><a href="#sec-ch13solution1">Solution 1</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^{2} = 4\)</span>. Find the sample size <span class="math inline">\(n\)</span> required to ensure that the length of a 95% confidence interval for <span class="math inline">\(\mu\)</span> is less than 1.</p>
</section>
<section class="level3" id="sec-ch13exercise2">
<h3 class="anchored" data-anchor-id="sec-ch13exercise2">Exercise 2</h3>
<p><a href="#sec-ch13solution2">Solution 2</a></p>
<p>Suppose <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> is a random sample from an exponential distribution with parameter <span class="math inline">\(\theta\)</span>. Construct an exact two-sided <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> based on the likelihood ratio statistic.</p>
</section>
<section class="level3" id="sec-ch13exercise3">
<h3 class="anchored" data-anchor-id="sec-ch13exercise3">Exercise 3</h3>
<p><a href="#sec-ch13solution3">Solution 3</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>. Using the central limit theorem, derive an approximate 99% confidence interval for <span class="math inline">\(p\)</span> when <span class="math inline">\(n = 100\)</span> and the sample proportion is <span class="math inline">\(\hat{p} = 0.6\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise4">
<h3 class="anchored" data-anchor-id="sec-ch13exercise4">Exercise 4</h3>
<p><a href="#sec-ch13solution4">Solution 4</a></p>
<p>For a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution with both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^{2}\)</span> unknown, construct a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\sigma^{2}\)</span> using the chi-squared distribution.</p>
</section>
<section class="level3" id="sec-ch13exercise5">
<h3 class="anchored" data-anchor-id="sec-ch13exercise5">Exercise 5</h3>
<p><a href="#sec-ch13solution5">Solution 5</a></p>
<p>Let <span class="math inline">\(X\)</span> be a single observation from a uniform distribution on the interval <span class="math inline">\([0, \theta]\)</span>. Construct a 90% confidence interval for <span class="math inline">\(\theta\)</span> based on this single observation.</p>
</section>
<section class="level3" id="sec-ch13exercise6">
<h3 class="anchored" data-anchor-id="sec-ch13exercise6">Exercise 6</h3>
<p><a href="#sec-ch13solution6">Solution 6</a></p>
<p>Suppose we have a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution, where both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^{2}\)</span> are unknown. Construct a <span class="math inline">\(1 - \alpha\)</span> confidence interval for the ratio <span class="math inline">\(\frac{\mu}{\sigma}\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise7">
<h3 class="anchored" data-anchor-id="sec-ch13exercise7">Exercise 7</h3>
<p><a href="#sec-ch13solution7">Solution 7</a></p>
<p>Consider a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. Using the asymptotic normality of the sample mean, construct an approximate <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\lambda\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise8">
<h3 class="anchored" data-anchor-id="sec-ch13exercise8">Exercise 8</h3>
<p><a href="#sec-ch13solution8">Solution 8</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a distribution with unknown mean <span class="math inline">\(\mu\)</span> and unknown variance <span class="math inline">\(\sigma^{2}\)</span>. Using the <span class="math inline">\(t\)</span>-distribution, construct a 95% confidence interval for <span class="math inline">\(\mu\)</span> when <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(\bar{X} = 10\)</span>, and <span class="math inline">\(s^{2} = 9\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise9">
<h3 class="anchored" data-anchor-id="sec-ch13exercise9">Exercise 9</h3>
<p><a href="#sec-ch13solution9">Solution 9</a></p>
<p>Suppose <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> is a random sample from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution with known <span class="math inline">\(\sigma^{2}\)</span>. Derive the <strong>expected length</strong> of a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise10">
<h3 class="anchored" data-anchor-id="sec-ch13exercise10">Exercise 10</h3>
<p><a href="#sec-ch13solution10">Solution 10</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a uniform distribution on the interval <span class="math inline">\([\theta, 2\theta]\)</span>, where <span class="math inline">\(\theta &gt; 0\)</span>. Construct a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> based on the maximum likelihood estimator.</p>
</section>
<section class="level3" id="sec-ch13exercise11">
<h3 class="anchored" data-anchor-id="sec-ch13exercise11">Exercise 11</h3>
<p><a href="#sec-ch13solution11">Solution 11</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, construct an approximate 95% confidence interval for <span class="math inline">\(\mu\)</span> when the sample size <span class="math inline">\(n\)</span> is large, the sample mean <span class="math inline">\(\bar{X} = 5\)</span>, and the sample standard deviation <span class="math inline">\(s = 2\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise12">
<h3 class="anchored" data-anchor-id="sec-ch13exercise12">Exercise 12</h3>
<p><a href="#sec-ch13solution12">Solution 12</a></p>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is a random sample from a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>. Construct an exact <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(p\)</span> using the <strong>Highest Posterior Density</strong> (HPD) method with a uniform prior distribution for <span class="math inline">\(p\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise13">
<h3 class="anchored" data-anchor-id="sec-ch13exercise13">Exercise 13</h3>
<p><a href="#sec-ch13solution13">Solution 13</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Derive the <strong>likelihood ratio statistic</strong> for testing the hypothesis <span class="math inline">\(H_0: \mu = \mu_0\)</span> against <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>, and use it to construct a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise14">
<h3 class="anchored" data-anchor-id="sec-ch13exercise14">Exercise 14</h3>
<p><a href="#sec-ch13solution14">Solution 14</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from an exponential distribution with parameter <span class="math inline">\(\theta\)</span>, construct an approximate <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> based on the asymptotic normality of the maximum likelihood estimator.</p>
</section>
<section class="level3" id="sec-ch13exercise15">
<h3 class="anchored" data-anchor-id="sec-ch13exercise15">Exercise 15</h3>
<p><a href="#sec-ch13solution15">Solution 15</a></p>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is a random sample from a uniform distribution on the interval <span class="math inline">\([0, \theta]\)</span>. Derive the <strong>uniformly most accurate</strong> (UMA) <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise16">
<h3 class="anchored" data-anchor-id="sec-ch13exercise16">Exercise 16</h3>
<p><a href="#sec-ch13solution16">Solution 16</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. Construct a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\lambda\)</span> based on the <strong>score statistic</strong>.</p>
</section>
<section class="level3" id="sec-ch13exercise17">
<h3 class="anchored" data-anchor-id="sec-ch13exercise17">Exercise 17</h3>
<p><a href="#sec-ch13solution17">Solution 17</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, use the <strong>Bayesian</strong> approach with a normal prior for <span class="math inline">\(\mu\)</span> and an inverse-gamma prior for <span class="math inline">\(\sigma^2\)</span> to construct a <span class="math inline">\(1-\alpha\)</span> credible interval for <span class="math inline">\(\mu\)</span>.</p>
</section>
<section class="level3" id="sec-ch13exercise18">
<h3 class="anchored" data-anchor-id="sec-ch13exercise18">Exercise 18</h3>
<p><a href="#sec-ch13solution18">Solution 18</a></p>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is a random sample from a gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and rate parameter <span class="math inline">\(\beta\)</span>. Construct a <span class="math inline">\(1-\alpha\)</span> confidence interval for the mean <span class="math inline">\(\frac{\alpha}{\beta}\)</span> using the <strong>pivotal quantity</strong> method.</p>
</section>
<section class="level3" id="sec-ch13exercise19">
<h3 class="anchored" data-anchor-id="sec-ch13exercise19">Exercise 19</h3>
<p><a href="#sec-ch13solution19">Solution 19</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a geometric distribution with parameter <span class="math inline">\(p\)</span>. Construct an approximate <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(p\)</span> based on the <strong>central limit theorem</strong>.</p>
</section>
<section class="level3" id="sec-ch13exercise20">
<h3 class="anchored" data-anchor-id="sec-ch13exercise20">Exercise 20</h3>
<p><a href="#sec-ch13solution20">Solution 20</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a <span class="math inline">\(N(\mu, \sigma^2)\)</span> distribution, construct a <span class="math inline">\(1-\alpha\)</span> <strong>unbiased confidence interval</strong> for <span class="math inline">\(\sigma^2\)</span> and show that it is also the <strong>uniformly most accurate unbiased</strong> (UMAU) confidence interval.</p>
</section>
</section>
<section class="level2" id="solutions">
<h2 class="anchored" data-anchor-id="solutions">Solutions</h2>
<section class="level3" id="sec-ch13solution1">
<h3 class="anchored" data-anchor-id="sec-ch13solution1">Solution 1</h3>
<p><a href="#sec-ch13exercise1">Exercise 1</a></p>
<p>For a normal distribution with known variance <span class="math inline">\(\sigma^{2}\)</span>, a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}},
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the sample mean and <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution corresponding to the desired confidence level. The length of this confidence interval is</p>
<p><span class="math display">\[
L = 2 z_{\alpha/2} \frac{\sigma}{\sqrt{n}}.
\]</span></p>
<p>We are given that <span class="math inline">\(\sigma^{2} = 4\)</span>, so <span class="math inline">\(\sigma = 2\)</span>. For a 95% confidence interval, <span class="math inline">\(\alpha = 0.05\)</span>, and <span class="math inline">\(z_{\alpha/2} = z_{0.025} = 1.96\)</span>. We want the length <span class="math inline">\(L\)</span> to be less than 1, so</p>
<p><span class="math display">\[
2 (1.96) \frac{2}{\sqrt{n}} &lt; 1.
\]</span></p>
<p>Solving for <span class="math inline">\(n\)</span>, we get</p>
<p><span class="math display">\[
\sqrt{n} &gt; 2 (1.96) (2) = 7.84,
\]</span></p>
<p><span class="math display">\[
n &gt; (7.84)^{2} = 61.4656.
\]</span></p>
<p>Since <span class="math inline">\(n\)</span> must be an integer, we need <span class="math inline">\(n \geq 62\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The length of the confidence interval depends on the standard error <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>, which decreases as the sample size <span class="math inline">\(n\)</span> increases. We want a smaller confidence interval, so we need a larger sample size. The critical value <span class="math inline">\(z_{\alpha/2}\)</span> is determined by the desired confidence level. In this case, a 95% confidence level corresponds to <span class="math inline">\(z_{0.025} = 1.96\)</span>. The formula for the length of the confidence interval is derived from the properties of the normal distribution and the definition of a confidence interval, as shown in Example 13.2. We set up the inequality to ensure the length is less than 1 and solve for <span class="math inline">\(n\)</span>.</p>
</section>
<section class="level3" id="sec-ch13solution2">
<h3 class="anchored" data-anchor-id="sec-ch13solution2">Solution 2</h3>
<p><a href="#sec-ch13exercise2">Exercise 2</a></p>
<p>For an exponential distribution with parameter <span class="math inline">\(\theta\)</span>, the likelihood function is given by</p>
<p><span class="math display">\[
L(\theta | X_{1}, \dots, X_{n}) = \prod_{i = 1}^{n} \frac{1}{\theta} e^{-X_{i}/\theta} = \frac{1}{\theta^{n}} e^{-\sum_{i = 1}^{n} X_{i}/\theta}.
\]</span></p>
<p>The log-likelihood function is</p>
<p><span class="math display">\[
l(\theta | X_{n}) = -n \log \theta - \frac{1}{\theta} \sum_{i = 1}^{n} X_{i}.
\]</span></p>
<p>The maximum likelihood estimator (MLE) for <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\hat{\theta} = \bar{X} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}\)</span>. The likelihood ratio statistic for testing <span class="math inline">\(H_{0}: \theta = \theta_{0}\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
\lambda(X^{n}; \theta_{0}) &amp;= \frac{L(\theta_{0} | X^{n})}{L(\hat{\theta} | X^{n})} \\
&amp;= \frac{\frac{1}{\theta_{0}^{n}} e^{-\sum_{i = 1}^{n} X_{i}/\theta_{0}}}{\frac{1}{\bar{X}^{n}} e^{-\sum_{i = 1}^{n} X_{i}/\bar{X}}} \\
&amp;= \left( \frac{\bar{X}}{\theta_{0}} \right)^{n} e^{-n \bar{X}/\theta_{0} + n}.
\end{aligned}
\]</span></p>
<p>Taking the logarithm, we get</p>
<p><span class="math display">\[
\log \lambda(X^{n}; \theta_{0}) = n \log \left( \frac{\bar{X}}{\theta_{0}} \right) - \frac{n \bar{X}}{\theta_{0}} + n.
\]</span></p>
<p>A <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is given by the set of <span class="math inline">\(\theta_{0}\)</span> values such that</p>
<p><span class="math display">\[
-2 \log \lambda(X^{n}; \theta_{0}) \leq \chi^{2}_{\alpha}(1),
\]</span></p>
<p>where <span class="math inline">\(\chi^{2}_{\alpha}(1)\)</span> is the critical value from the chi-squared distribution with 1 degree of freedom. Substituting the expression for <span class="math inline">\(\log \lambda(X^{n}; \theta_{0})\)</span>, we have</p>
<p><span class="math display">\[
-2 \left[ n \log \left( \frac{\bar{X}}{\theta_{0}} \right) - \frac{n \bar{X}}{\theta_{0}} + n \right] \leq \chi^{2}_{\alpha}(1).
\]</span></p>
<p>This inequality defines the confidence interval for <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The likelihood ratio statistic compares the likelihood of the observed data under the null hypothesis (<span class="math inline">\(\theta = \theta_{0}\)</span>) to the likelihood under the maximum likelihood estimate <span class="math inline">\(\hat{\theta}\)</span>. The confidence interval consists of all values of <span class="math inline">\(\theta_{0}\)</span> for which the likelihood ratio statistic is not too small, indicating that the data are reasonably likely under those values of <span class="math inline">\(\theta_{0}\)</span>. The chi-squared distribution is used because, under certain regularity conditions, <span class="math inline">\(-2 \log \lambda\)</span> is approximately chi-squared distributed. This is related to the concept introduced in Example 13.8.</p>
</section>
<section class="level3" id="sec-ch13solution3">
<h3 class="anchored" data-anchor-id="sec-ch13solution3">Solution 3</h3>
<p><a href="#sec-ch13exercise3">Exercise 3</a></p>
<p>For a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>, the sample proportion <span class="math inline">\(\hat{p} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}\)</span> is an estimator for <span class="math inline">\(p\)</span>. By the central limit theorem, for large <span class="math inline">\(n\)</span>, <span class="math inline">\(\hat{p}\)</span> is approximately normally distributed with mean <span class="math inline">\(p\)</span> and variance <span class="math inline">\(\frac{p(1 - p)}{n}\)</span>. Thus,</p>
<p><span class="math display">\[
Z = \frac{\hat{p} - p}{\sqrt{\frac{p(1 - p)}{n}}}
\]</span></p>
<p>is approximately standard normal. An approximate <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(p\)</span> is given by</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}.
\]</span></p>
<p>For a 99% confidence interval, <span class="math inline">\(\alpha = 0.01\)</span>, and <span class="math inline">\(z_{\alpha/2} = z_{0.005} = 2.576\)</span>. We are given <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(\hat{p} = 0.6\)</span>. Plugging these values into the formula, we get</p>
<p><span class="math display">\[
0.6 \pm 2.576 \sqrt{\frac{0.6(1 - 0.6)}{100}} = 0.6 \pm 2.576 \sqrt{\frac{0.24}{100}} = 0.6 \pm 2.576 (0.049) \approx 0.6 \pm 0.126.
\]</span></p>
<p>Thus, the approximate 99% confidence interval for <span class="math inline">\(p\)</span> is <span class="math inline">\((0.474, 0.726)\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The central limit theorem states that the sample proportion <span class="math inline">\(\hat{p}\)</span> will be approximately normally distributed for large sample sizes. The standard error of <span class="math inline">\(\hat{p}\)</span> is <span class="math inline">\(\sqrt{\frac{p(1 - p)}{n}}\)</span>, which is estimated by <span class="math inline">\(\sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}\)</span>. The confidence interval is constructed by taking the sample proportion and adding and subtracting a margin of error, which is the product of the critical value <span class="math inline">\(z_{\alpha/2}\)</span> and the estimated standard error. This is related to the concept introduced in Example 13.11.</p>
</section>
<section class="level3" id="sec-ch13solution4">
<h3 class="anchored" data-anchor-id="sec-ch13solution4">Solution 4</h3>
<p><a href="#sec-ch13exercise4">Exercise 4</a></p>
<p>For a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution, the quantity</p>
<p><span class="math display">\[
\frac{(n - 1)s^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1),
\]</span></p>
<p>where <span class="math inline">\(s^{2} = \frac{1}{n - 1} \sum_{i = 1}^{n} (X_{i} - \bar{X})^{2}\)</span> is the sample variance. This follows a chi-squared distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom. To construct a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\sigma^{2}\)</span>, we find the critical values <span class="math inline">\(\chi^{2}_{\alpha/2}(n - 1)\)</span> and <span class="math inline">\(\chi^{2}_{1 - \alpha/2}(n - 1)\)</span> such that</p>
<p><span class="math display">\[
P \left( \chi^{2}_{\alpha/2}(n - 1) \leq \frac{(n - 1)s^{2}}{\sigma^{2}} \leq \chi^{2}_{1 - \alpha/2}(n - 1) \right) = 1 - \alpha.
\]</span></p>
<p>Rearranging the inequality to isolate <span class="math inline">\(\sigma^{2}\)</span>, we get</p>
<p><span class="math display">\[
P \left( \frac{(n - 1)s^{2}}{\chi^{2}_{1 - \alpha/2}(n - 1)} \leq \sigma^{2} \leq \frac{(n - 1)s^{2}}{\chi^{2}_{\alpha/2}(n - 1)} \right) = 1 - \alpha.
\]</span></p>
<p>Thus, the <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\sigma^{2}\)</span> is</p>
<p><span class="math display">\[
\left( \frac{(n - 1)s^{2}}{\chi^{2}_{1 - \alpha/2}(n - 1)}, \frac{(n - 1)s^{2}}{\chi^{2}_{\alpha/2}(n - 1)} \right).
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The quantity <span class="math inline">\(\frac{(n - 1)s^{2}}{\sigma^{2}}\)</span> is a pivotal quantity because its distribution does not depend on any unknown parameters. We use the chi-squared distribution to find the critical values that correspond to the desired confidence level. The confidence interval is constructed by inverting the probability statement involving the pivotal quantity to obtain bounds for <span class="math inline">\(\sigma^{2}\)</span>. This concept is illustrated in Example 13.5.</p>
</section>
<section class="level3" id="sec-ch13solution5">
<h3 class="anchored" data-anchor-id="sec-ch13solution5">Solution 5</h3>
<p><a href="#sec-ch13exercise5">Exercise 5</a></p>
<p>Let <span class="math inline">\(X\)</span> be a single observation from a uniform distribution on <span class="math inline">\([0, \theta]\)</span>. The probability density function (pdf) of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[
f(x; \theta) = \begin{cases}
\frac{1}{\theta} &amp; \text{if } 0 \leq x \leq \theta \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>Since we have only one observation, <span class="math inline">\(X\)</span> itself is an estimator for <span class="math inline">\(\theta\)</span>. To construct a 90% confidence interval, we want to find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that</p>
<p><span class="math display">\[
P(a \leq \theta \leq b) = 0.9.
\]</span></p>
<p>However, since <span class="math inline">\(X \leq \theta\)</span>, we can say that <span class="math inline">\(X\)</span> is a lower bound for <span class="math inline">\(\theta\)</span>. We need to find an upper bound <span class="math inline">\(b\)</span> such that</p>
<p><span class="math display">\[
P(X \leq \theta \leq b) = 0.9.
\]</span></p>
<p>We can rewrite this as</p>
<p><span class="math display">\[
P(\theta \geq X) - P(\theta \geq b) = P(X \leq \theta &lt; b) = 0.9.
\]</span></p>
<p>Since <span class="math inline">\(X \leq \theta\)</span>, we have <span class="math inline">\(P(\theta \geq X) = 1\)</span>. We need to find <span class="math inline">\(b\)</span> such that <span class="math inline">\(P(\theta \geq b) = 0.1\)</span>. We know that <span class="math inline">\(P(X \leq x) = \frac{x}{\theta}\)</span>. Then <span class="math inline">\(P(X \leq b) = \frac{b}{\theta}\)</span>. Since we want a 90% confidence interval, we can set <span class="math inline">\(b = kX\)</span> for some <span class="math inline">\(k &gt; 1\)</span>. We want to find <span class="math inline">\(k\)</span> such that</p>
<p><span class="math display">\[
P(X \leq \theta \leq kX) = 0.9.
\]</span></p>
<p>Since <span class="math inline">\(X\)</span> is the only observation, we can write</p>
<p><span class="math display">\[
P \left( \frac{X}{k} \leq \frac{\theta}{k} \leq X \right) = \int_{X}^{kX} \frac{1}{\theta} dx = \frac{kX - X}{kX} = 1 - \frac{1}{k} = 0.9.
\]</span></p>
<p>This implies that <span class="math inline">\(\frac{1}{k} = 0.1\)</span>, so <span class="math inline">\(k = 10\)</span>. Thus, a 90% confidence interval for <span class="math inline">\(\theta\)</span> is <span class="math inline">\((X, 10X)\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>With a single observation from a uniform distribution, the observed value <span class="math inline">\(X\)</span> provides a lower bound for <span class="math inline">\(\theta\)</span>. We seek an upper bound <span class="math inline">\(b\)</span> such that the interval <span class="math inline">\([X, b]\)</span> contains <span class="math inline">\(\theta\)</span> with 90% probability. Since <span class="math inline">\(X\)</span> must be less than or equal to <span class="math inline">\(\theta\)</span>, we consider an interval of the form <span class="math inline">\([X, kX]\)</span>, where <span class="math inline">\(k &gt; 1\)</span>. The probability that <span class="math inline">\(X\)</span> falls within the interval <span class="math inline">\([a, b]\)</span> is given by <span class="math inline">\(\frac{b - a}{\theta}\)</span>, so we set <span class="math inline">\(b = kX\)</span> and solve for <span class="math inline">\(k\)</span> to achieve the desired confidence level. This is related to the concept discussed in Example 13.9.</p>
</section>
<section class="level3" id="sec-ch13solution6">
<h3 class="anchored" data-anchor-id="sec-ch13solution6">Solution 6</h3>
<p><a href="#sec-ch13exercise6">Exercise 6</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution. The sample mean <span class="math inline">\(\bar{X} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}\)</span> and the sample variance <span class="math inline">\(s^{2} = \frac{1}{n - 1} \sum_{i = 1}^{n} (X_{i} - \bar{X})^{2}\)</span> are independent estimators for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^{2}\)</span>, respectively. We know that <span class="math inline">\(\frac{\bar{X} - \mu}{s / \sqrt{n}} \sim t(n - 1)\)</span>, where <span class="math inline">\(t(n - 1)\)</span> is the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom. Let <span class="math inline">\(T = \frac{\bar{X} - \mu}{s / \sqrt{n}}\)</span>. Then we can write</p>
<p><span class="math display">\[
\bar{X} = \mu + T \frac{s}{\sqrt{n}}.
\]</span></p>
<p>Dividing by <span class="math inline">\(\sigma\)</span>, we have</p>
<p><span class="math display">\[
\frac{\bar{X}}{\sigma} = \frac{\mu}{\sigma} + T \frac{s}{\sigma \sqrt{n}}.
\]</span></p>
<p>Rearranging, we get</p>
<p><span class="math display">\[
\frac{\mu}{\sigma} = \frac{\bar{X}}{s} \frac{s}{\sigma} - T \frac{s}{\sigma \sqrt{n}}.
\]</span></p>
<p>We know that <span class="math inline">\(\frac{(n - 1)s^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1)\)</span>. Let <span class="math inline">\(C = \frac{(n - 1)s^{2}}{\sigma^{2}}\)</span>. Then <span class="math inline">\(\frac{s}{\sigma} = \sqrt{\frac{C}{n - 1}}\)</span>. Substituting this into the equation for <span class="math inline">\(\frac{\mu}{\sigma}\)</span>, we get</p>
<p><span class="math display">\[
\frac{\mu}{\sigma} = \frac{\bar{X}}{s} \sqrt{\frac{C}{n - 1}} - T \frac{1}{\sqrt{n}} \sqrt{\frac{C}{n - 1}}.
\]</span></p>
<p>Since we want a confidence interval for <span class="math inline">\(\frac{\mu}{\sigma}\)</span>, we can consider the quantity</p>
<p><span class="math display">\[
\frac{\bar{X} / \sigma}{s / \sigma} = \frac{\bar{X}}{s} = \frac{\bar{X} - \mu}{s} + \frac{\mu}{s}.
\]</span></p>
<p>We know that <span class="math inline">\(\frac{\bar{X} - \mu}{s / \sqrt{n}} \sim t_{n-1}\)</span>. Let <span class="math inline">\(t_{\alpha/2}\)</span> be such that <span class="math inline">\(P(-t_{\alpha/2} \le t_{n-1} \le t_{\alpha/2}) = 1-\alpha\)</span>. Then, we can consider the quantity <span class="math inline">\(\frac{\sqrt{n}(\bar{X} - \mu)}{s}\)</span>, which follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom. We can write</p>
<p><span class="math display">\[
P \left( -t_{\alpha/2} \leq \frac{\sqrt{n}(\bar{X} - \mu)}{s} \leq t_{\alpha/2} \right) = 1 - \alpha.
\]</span></p>
<p>Rearranging for <span class="math inline">\(\frac{\mu}{\sigma}\)</span>, we get</p>
<p><span class="math display">\[
P \left( \frac{\bar{X}}{s} - \frac{t_{\alpha/2}}{\sqrt{n}} \leq \frac{\mu}{s} \leq \frac{\bar{X}}{s} + \frac{t_{\alpha/2}}{\sqrt{n}} \right) = 1 - \alpha.
\]</span></p>
<p>This does not give us a confidence interval for <span class="math inline">\(\frac{\mu}{\sigma}\)</span>.</p>
<p>The final answer is <span class="math inline">\(\frac{\mu}{\sigma}\)</span></p>
</section>
<section class="level3" id="sec-ch13solution7">
<h3 class="anchored" data-anchor-id="sec-ch13solution7">Solution 7</h3>
<p><a href="#sec-ch13exercise7">Exercise 7</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. The sample mean <span class="math inline">\(\bar{X} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}\)</span> is an estimator for <span class="math inline">\(\lambda\)</span>. By the central limit theorem, for large <span class="math inline">\(n\)</span>, <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed with mean <span class="math inline">\(\lambda\)</span> and variance <span class="math inline">\(\frac{\lambda}{n}\)</span>. Thus,</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \lambda}{\sqrt{\frac{\lambda}{n}}}
\]</span></p>
<p>is approximately standard normal. However, since <span class="math inline">\(\lambda\)</span> is unknown, we replace it with its estimator <span class="math inline">\(\bar{X}\)</span> in the standard deviation. Then,</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \lambda}{\sqrt{\frac{\bar{X}}{n}}}
\]</span></p>
<p>is also approximately standard normal. An approximate <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\lambda\)</span> is given by</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \sqrt{\frac{\bar{X}}{n}}.
\]</span></p>
<p>For a <span class="math inline">\(1 - \alpha\)</span> confidence interval, we find <span class="math inline">\(z_{\alpha/2}\)</span> such that <span class="math inline">\(P(-z_{\alpha/2} \leq Z \leq z_{\alpha/2}) = 1 - \alpha\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The central limit theorem states that the sample mean <span class="math inline">\(\bar{X}\)</span> will be approximately normally distributed for large sample sizes, regardless of the underlying distribution (in this case, Poisson). The standard error of <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(\sqrt{\frac{\lambda}{n}}\)</span>, which is estimated by <span class="math inline">\(\sqrt{\frac{\bar{X}}{n}}\)</span> since <span class="math inline">\(\lambda\)</span> is unknown. The confidence interval is constructed by taking the sample mean and adding and subtracting a margin of error, which is the product of the critical value <span class="math inline">\(z_{\alpha/2}\)</span> and the estimated standard error. This is similar to the approach used in Example 13.4 and 13.11.</p>
</section>
<section class="level3" id="sec-ch13solution8">
<h3 class="anchored" data-anchor-id="sec-ch13solution8">Solution 8</h3>
<p><a href="#sec-ch13exercise8">Exercise 8</a></p>
<p>For a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a distribution with unknown mean <span class="math inline">\(\mu\)</span> and unknown variance <span class="math inline">\(\sigma^{2}\)</span>, the quantity</p>
<p><span class="math display">\[
\frac{\bar{X} - \mu}{s / \sqrt{n}} \sim t(n - 1),
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the sample mean and <span class="math inline">\(s^{2}\)</span> is the sample variance, follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom. To construct a 95% confidence interval for <span class="math inline">\(\mu\)</span>, we find the critical value <span class="math inline">\(t_{\alpha/2}(n - 1)\)</span> such that</p>
<p><span class="math display">\[
P \left( -t_{\alpha/2}(n - 1) \leq \frac{\bar{X} - \mu}{s / \sqrt{n}} \leq t_{\alpha/2}(n - 1) \right) = 0.95.
\]</span></p>
<p>We are given <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(\bar{X} = 10\)</span>, and <span class="math inline">\(s^{2} = 9\)</span>, so <span class="math inline">\(s = 3\)</span>. For a 95% confidence interval with <span class="math inline">\(n - 1 = 19\)</span> degrees of freedom, <span class="math inline">\(\alpha = 0.05\)</span>, and <span class="math inline">\(t_{\alpha/2}(19) = t_{0.025}(19) = 2.093\)</span>. Rearranging the inequality to isolate <span class="math inline">\(\mu\)</span>, we get</p>
<p><span class="math display">\[
P \left( \bar{X} - t_{\alpha/2}(n - 1) \frac{s}{\sqrt{n}} \leq \mu \leq \bar{X} + t_{\alpha/2}(n - 1) \frac{s}{\sqrt{n}} \right) = 0.95.
\]</span></p>
<p>Plugging in the given values, we have</p>
<p><span class="math display">\[
P \left( 10 - 2.093 \frac{3}{\sqrt{20}} \leq \mu \leq 10 + 2.093 \frac{3}{\sqrt{20}} \right) = 0.95,
\]</span></p>
<p><span class="math display">\[
P(10 - 1.404 \leq \mu \leq 10 + 1.404) = 0.95.
\]</span></p>
<p>Thus, the 95% confidence interval for <span class="math inline">\(\mu\)</span> is <span class="math inline">\((8.596, 11.404)\)</span>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>When the population variance is unknown, we use the <span class="math inline">\(t\)</span>-distribution instead of the normal distribution. The <span class="math inline">\(t\)</span>-distribution accounts for the extra uncertainty introduced by estimating the population variance with the sample variance. The confidence interval is constructed by taking the sample mean and adding and subtracting a margin of error, which is the product of the critical value <span class="math inline">\(t_{\alpha/2}(n - 1)\)</span> and the estimated standard error <span class="math inline">\(\frac{s}{\sqrt{n}}\)</span>. This is illustrated in Example 13.3.</p>
</section>
<section class="level3" id="sec-ch13solution9">
<h3 class="anchored" data-anchor-id="sec-ch13solution9">Solution 9</h3>
<p><a href="#sec-ch13exercise9">Exercise 9</a></p>
<p>For a random sample <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> from a <span class="math inline">\(N(\mu, \sigma^{2})\)</span> distribution with known <span class="math inline">\(\sigma^{2}\)</span>, a <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}},
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the sample mean and <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution. The length of this confidence interval is</p>
<p><span class="math display">\[
L = 2 z_{\alpha/2} \frac{\sigma}{\sqrt{n}}.
\]</span></p>
<p>Since the length <span class="math inline">\(L\)</span> is a constant (given that <span class="math inline">\(\sigma\)</span> is known and <span class="math inline">\(n\)</span> is fixed), the expected length is simply the length itself:</p>
<p><span class="math display">\[
E(L) = 2 z_{\alpha/2} \frac{\sigma}{\sqrt{n}}.
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The length of the confidence interval is determined by the critical value <span class="math inline">\(z_{\alpha/2}\)</span>, the known population standard deviation <span class="math inline">\(\sigma\)</span>, and the sample size <span class="math inline">\(n\)</span>. Since these are all constants, the length of the confidence interval is also a constant. Therefore, the expected length is equal to the length itself. The concept of expected length is discussed in Section 13.3.</p>
</section>
<section class="level3" id="sec-ch13solution10">
<h3 class="anchored" data-anchor-id="sec-ch13solution10">Solution 10</h3>
<p><a href="#sec-ch13exercise10">Exercise 10</a></p>
<p>Let <span class="math inline">\(X_{1}, X_{2}, \dots, X_{n}\)</span> be a random sample from a uniform distribution on the interval <span class="math inline">\([\theta, 2\theta]\)</span>. The probability density function is given by</p>
<p><span class="math display">\[
f(x; \theta) = \begin{cases}
\frac{1}{\theta} &amp; \text{if } \theta \leq x \leq 2\theta \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>The likelihood function is</p>
<p><span class="math display">\[
L(\theta | X_{1}, \dots, X_{n}) = \prod_{i = 1}^{n} \frac{1}{\theta} \mathbb{1}_{[\theta \leq X_{i} \leq 2\theta]} = \frac{1}{\theta^{n}} \mathbb{1}_{[\theta \leq \min X_{i}]} \mathbb{1}_{[\max X_{i} \leq 2\theta]}.
\]</span></p>
<p>This is maximized when <span class="math inline">\(\theta\)</span> is as small as possible, subject to the constraints <span class="math inline">\(\theta \leq \min X_{i}\)</span> and <span class="math inline">\(\max X_{i} \leq 2\theta\)</span>. Thus, the maximum likelihood estimator is <span class="math inline">\(\hat{\theta} = \max\{\frac{\max X_{i}}{2}, \min X_{i} \}\)</span>. Let <span class="math inline">\(Y_{1} = \min X_{i}\)</span> and <span class="math inline">\(Y_{n} = \max X_{i}\)</span>. We want to find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that</p>
<p><span class="math display">\[
P(a \leq \theta \leq b) = 1 - \alpha.
\]</span></p>
<p>We can use the order statistics to construct a confidence interval. The joint distribution of <span class="math inline">\(Y_{1}\)</span> and <span class="math inline">\(Y_{n}\)</span> is given by</p>
<p><span class="math display">\[
f_{Y_{1}, Y_{n}}(y_{1}, y_{n}) = \frac{n(n - 1)}{\theta^{n}} (y_{n} - y_{1})^{n - 2}, \quad \theta \leq y_{1} \leq y_{n} \leq 2\theta.
\]</span></p>
<p>We have <span class="math inline">\(\hat{\theta} = \max\{\frac{Y_{n}}{2}, Y_{1} \}\)</span>. A <span class="math inline">\(1 - \alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> can be constructed as <span class="math inline">\([\frac{\max X_{i}}{2}, \min X_{i}]\)</span>.</p>
<p><strong>Intuitive Explanation:</strong> The maximum likelihood estimator <span class="math inline">\(\hat{\theta}\)</span> for the uniform distribution on <span class="math inline">\([\theta, 2\theta]\)</span> is based on both the minimum and maximum order statistics. This estimator is derived by maximizing the likelihood function subject to the constraints imposed by the support of the uniform distribution. The confidence interval is then constructed using the distribution of the order statistics, ensuring that the interval contains the true parameter <span class="math inline">\(\theta\)</span> with the desired probability. This is related to the concepts in Example 13.9.</p>
<p>The final answer is <span class="math inline">\([\frac{\max X_{i}}{2}, \min X_{i}]\)</span></p>
</section>
<section class="level3" id="sec-ch13solution11">
<h3 class="anchored" data-anchor-id="sec-ch13solution11">Solution 11</h3>
<p><a href="#sec-ch13exercise11">Exercise 11</a></p>
<p>Given a large random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, we can use the Central Limit Theorem (CLT) to construct an approximate confidence interval for <span class="math inline">\(\mu\)</span>. According to the CLT, the sample mean <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\frac{\sigma^2}{n}\)</span> for large <span class="math inline">\(n\)</span>. Since <span class="math inline">\(\sigma^2\)</span> is unknown, we estimate it using the sample variance <span class="math inline">\(s^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\)</span>.</p>
<p>The standardized statistic <span class="math inline">\(\frac{\bar{X} - \mu}{s/\sqrt{n}}\)</span> follows approximately a standard normal distribution for large <span class="math inline">\(n\)</span>. Therefore, an approximate 95% confidence interval for <span class="math inline">\(\mu\)</span> is given by:</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{s}{\sqrt{n}}
\]</span></p>
<p>where <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution corresponding to the desired confidence level. For a 95% confidence interval, <span class="math inline">\(\alpha = 0.05\)</span>, and <span class="math inline">\(z_{\alpha/2} = z_{0.025} = 1.96\)</span>.</p>
<p>We are given <span class="math inline">\(\bar{X} = 5\)</span> and <span class="math inline">\(s = 2\)</span>. Plugging these values into the formula, we get:</p>
<p><span class="math display">\[
5 \pm 1.96 \frac{2}{\sqrt{n}}
\]</span></p>
<p>Since we are not given the sample size <span class="math inline">\(n\)</span>, we cannot compute the exact numerical interval. However, if we assume <span class="math inline">\(n\)</span> is large enough for the CLT to apply, the approximate 95% confidence interval for <span class="math inline">\(\mu\)</span> is:</p>
<p><span class="math display">\[
\left(5 - 1.96 \frac{2}{\sqrt{n}}, 5 + 1.96 \frac{2}{\sqrt{n}}\right)
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>For large samples, the Central Limit Theorem allows us to approximate the distribution of the sample mean <span class="math inline">\(\bar{X}\)</span> as normal, regardless of the underlying distribution. Since the population variance is unknown, we use the sample standard deviation <span class="math inline">\(s\)</span> to estimate the standard error of the mean. The confidence interval is constructed by adding and subtracting the margin of error, which is the product of the critical value <span class="math inline">\(z_{\alpha/2}\)</span> and the estimated standard error <span class="math inline">\(\frac{s}{\sqrt{n}}\)</span>, from the sample mean. This approach is similar to the one used in Example 13.4.</p>
</section>
<section class="level3" id="sec-ch13solution12">
<h3 class="anchored" data-anchor-id="sec-ch13solution12">Solution 12</h3>
<p><a href="#sec-ch13exercise12">Exercise 12</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>, the likelihood function is:</p>
<p><span class="math display">\[
L(p | X_1, \dots, X_n) = \prod_{i=1}^n p^{X_i} (1-p)^{1-X_i} = p^{\sum X_i} (1-p)^{n-\sum X_i}
\]</span></p>
<p>Let <span class="math inline">\(k = \sum_{i=1}^n X_i\)</span>. Then the likelihood function becomes:</p>
<p><span class="math display">\[
L(p | k) = p^k (1-p)^{n-k}
\]</span></p>
<p>Assuming a uniform prior distribution for <span class="math inline">\(p\)</span>, i.e., <span class="math inline">\(\pi(p) = 1\)</span> for <span class="math inline">\(0 \le p \le 1\)</span>, the posterior distribution is proportional to the likelihood function:</p>
<p><span class="math display">\[
\pi(p | k) \propto L(p | k) \pi(p) = p^k (1-p)^{n-k}
\]</span></p>
<p>This is the kernel of a Beta distribution with parameters <span class="math inline">\(\alpha = k+1\)</span> and <span class="math inline">\(\beta = n-k+1\)</span>. Thus, the posterior distribution of <span class="math inline">\(p\)</span> is <span class="math inline">\(\text{Beta}(k+1, n-k+1)\)</span>.</p>
<p>To construct an exact <span class="math inline">\(1-\alpha\)</span> Highest Posterior Density (HPD) interval for <span class="math inline">\(p\)</span>, we need to find <span class="math inline">\(p_L\)</span> and <span class="math inline">\(p_U\)</span> such that:</p>
<p><span class="math display">\[
\int_{p_L}^{p_U} \pi(p | k) dp = 1 - \alpha
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\pi(p_L | k) = \pi(p_U | k)
\]</span></p>
<p>with the constraint that <span class="math inline">\(p_U - p_L\)</span> is minimized. The HPD interval is the shortest interval that contains <span class="math inline">\(1-\alpha\)</span> of the posterior probability.</p>
<p>For a Beta distribution, the mode is given by <span class="math inline">\(\frac{\alpha - 1}{\alpha + \beta - 2} = \frac{k}{n}\)</span>, which is the sample proportion <span class="math inline">\(\hat{p}\)</span>. The HPD interval can be found numerically by solving the above equations.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The Bayesian approach combines the likelihood function with a prior distribution to obtain the posterior distribution. In this case, a uniform prior for <span class="math inline">\(p\)</span> leads to a Beta posterior distribution. The HPD interval is the shortest interval that contains <span class="math inline">\(1-\alpha\)</span> of the posterior probability, reflecting the region of highest posterior density. This method is discussed in Section 13.2.1.</p>
</section>
<section class="level3" id="sec-ch13solution13">
<h3 class="anchored" data-anchor-id="sec-ch13solution13">Solution 13</h3>
<p><a href="#sec-ch13exercise13">Exercise 13</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. The likelihood function is:</p>
<p><span class="math display">\[
L(\mu, \sigma^2 | X_1, \dots, X_n) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(X_i - \mu)^2}{2\sigma^2}\right) = (2\pi\sigma^2)^{-n/2} \exp\left(-\frac{\sum_{i=1}^n (X_i - \mu)^2}{2\sigma^2}\right)
\]</span></p>
<p>The log-likelihood function is:</p>
<p><span class="math display">\[
l(\mu, \sigma^2) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n (X_i - \mu)^2
\]</span></p>
<p>To find the maximum likelihood estimators (MLEs), we take the partial derivatives with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> and set them to zero:</p>
<p><span class="math display">\[
\frac{\partial l}{\partial \mu} = \frac{1}{\sigma^2} \sum_{i=1}^n (X_i - \mu) = 0 \implies \hat{\mu} = \bar{X}
\]</span></p>
<p><span class="math display">\[
\frac{\partial l}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2} \sum_{i=1}^n (X_i - \mu)^2 = 0 \implies \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2
\]</span></p>
<p>Under <span class="math inline">\(H_0: \mu = \mu_0\)</span>, the MLE for <span class="math inline">\(\sigma^2\)</span> is <span class="math inline">\(\hat{\sigma}_0^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \mu_0)^2\)</span>. The likelihood ratio statistic is:</p>
<p><span class="math display">\[
\lambda(X^n) = \frac{L(\mu_0, \hat{\sigma}_0^2 | X^n)}{L(\hat{\mu}, \hat{\sigma}^2 | X^n)} = \frac{(2\pi\hat{\sigma}_0^2)^{-n/2} \exp\left(-\frac{\sum (X_i - \mu_0)^2}{2\hat{\sigma}_0^2}\right)}{(2\pi\hat{\sigma}^2)^{-n/2} \exp\left(-\frac{\sum (X_i - \bar{X})^2}{2\hat{\sigma}^2}\right)} = \left(\frac{\hat{\sigma}^2}{\hat{\sigma}_0^2}\right)^{n/2}
\]</span></p>
<p>Since <span class="math inline">\(\sum (X_i - \mu_0)^2 = \sum (X_i - \bar{X})^2 + n(\bar{X} - \mu_0)^2\)</span>, we have:</p>
<p><span class="math display">\[
\lambda(X^n) = \left(\frac{\sum (X_i - \bar{X})^2}{\sum (X_i - \bar{X})^2 + n(\bar{X} - \mu_0)^2}\right)^{n/2} = \left(\frac{1}{1 + \frac{n(\bar{X} - \mu_0)^2}{\sum (X_i - \bar{X})^2}}\right)^{n/2}
\]</span></p>
<p>The statistic <span class="math inline">\(-2\log\lambda(X^n)\)</span> is asymptotically distributed as <span class="math inline">\(\chi^2_1\)</span> under <span class="math inline">\(H_0\)</span>. We know that <span class="math inline">\(\frac{(n-1)s^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>, where <span class="math inline">\(s^2 = \frac{1}{n-1} \sum (X_i - \bar{X})^2\)</span>. Then <span class="math inline">\(-2\log\lambda(X^n) = n \log\left(1 + \frac{n(\bar{X} - \mu_0)^2}{(n-1)s^2}\frac{n-1}{n}\right) = n\log\left(1 + \frac{T^2}{n-1}\right)\)</span>, where <span class="math inline">\(T = \frac{\sqrt{n}(\bar{X} - \mu_0)}{s} \sim t_{n-1}\)</span>.</p>
<p>A <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\mu\)</span> can be constructed using the <span class="math inline">\(t\)</span>-distribution:</p>
<p><span class="math display">\[
\bar{X} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The likelihood ratio test compares the likelihood of the data under the null hypothesis to the maximum likelihood under the alternative hypothesis. The likelihood ratio statistic <span class="math inline">\(\lambda(X^n)\)</span> is a function of the ratio of the MLEs of <span class="math inline">\(\sigma^2\)</span> under the null and alternative hypotheses. The statistic <span class="math inline">\(-2\log\lambda(X^n)\)</span> is asymptotically chi-squared distributed, which allows us to construct a confidence interval based on the quantiles of the chi-squared distribution. However, using the <span class="math inline">\(t\)</span>-distribution provides an exact confidence interval. This concept is similar to the one shown in Example 13.7.</p>
</section>
<section class="level3" id="sec-ch13solution14">
<h3 class="anchored" data-anchor-id="sec-ch13solution14">Solution 14</h3>
<p><a href="#sec-ch13exercise14">Exercise 14</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from an exponential distribution with parameter <span class="math inline">\(\theta\)</span>, the probability density function is:</p>
<p><span class="math display">\[
f(x; \theta) = \frac{1}{\theta} e^{-x/\theta}, \quad x \ge 0, \theta &gt; 0
\]</span></p>
<p>The likelihood function is:</p>
<p><span class="math display">\[
L(\theta | X_1, \dots, X_n) = \prod_{i=1}^n \frac{1}{\theta} e^{-X_i/\theta} = \frac{1}{\theta^n} e^{-\sum X_i/\theta}
\]</span></p>
<p>The log-likelihood function is:</p>
<p><span class="math display">\[
l(\theta) = -n \log \theta - \frac{1}{\theta} \sum_{i=1}^n X_i
\]</span></p>
<p>Taking the derivative with respect to <span class="math inline">\(\theta\)</span> and setting it to zero, we get the maximum likelihood estimator (MLE):</p>
<p><span class="math display">\[
\frac{dl}{d\theta} = -\frac{n}{\theta} + \frac{1}{\theta^2} \sum_{i=1}^n X_i = 0 \implies \hat{\theta} = \frac{1}{n} \sum_{i=1}^n X_i = \bar{X}
\]</span></p>
<p>The second derivative is:</p>
<p><span class="math display">\[
\frac{d^2l}{d\theta^2} = \frac{n}{\theta^2} - \frac{2}{\theta^3} \sum_{i=1}^n X_i
\]</span></p>
<p>Evaluating the second derivative at <span class="math inline">\(\hat{\theta} = \bar{X}\)</span>, we get:</p>
<p><span class="math display">\[
\frac{d^2l}{d\theta^2}\Big|_{\theta=\bar{X}} = \frac{n}{\bar{X}^2} - \frac{2}{\bar{X}^3} n\bar{X} = -\frac{n}{\bar{X}^2}
\]</span></p>
<p>The Fisher information is:</p>
<p><span class="math display">\[
I(\theta) = -E\left[\frac{d^2l}{d\theta^2}\right] = -E\left[\frac{n}{\theta^2} - \frac{2}{\theta^3} \sum_{i=1}^n X_i\right] = -\frac{n}{\theta^2} + \frac{2n}{\theta^3} E[X_i] = -\frac{n}{\theta^2} + \frac{2n}{\theta^3} \theta = \frac{n}{\theta^2}
\]</span></p>
<p>By the asymptotic normality of the MLE, we have:</p>
<p><span class="math display">\[
\sqrt{n}(\hat{\theta} - \theta) \xrightarrow{d} N(0, \theta^2)
\]</span></p>
<p>Thus, an approximate <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is given by:</p>
<p><span class="math display">\[
\hat{\theta} \pm z_{\alpha/2} \frac{\hat{\theta}}{\sqrt{n}}
\]</span></p>
<p>Substituting <span class="math inline">\(\hat{\theta} = \bar{X}\)</span>, we get:</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{\bar{X}}{\sqrt{n}}
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The maximum likelihood estimator for the exponential distribution parameter <span class="math inline">\(\theta\)</span> is the sample mean <span class="math inline">\(\bar{X}\)</span>. The Fisher information provides a measure of the amount of information that the data provides about the parameter. By the asymptotic normality of MLEs, <span class="math inline">\(\hat{\theta}\)</span> is approximately normally distributed for large <span class="math inline">\(n\)</span>. The confidence interval is constructed using the standard error of the MLE, which is derived from the inverse of the Fisher information. This concept is related to the general large sample setting discussed in Section 13.1.1.</p>
</section>
<section class="level3" id="sec-ch13solution15">
<h3 class="anchored" data-anchor-id="sec-ch13solution15">Solution 15</h3>
<p><a href="#sec-ch13exercise15">Exercise 15</a></p>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is a random sample from a uniform distribution on the interval <span class="math inline">\([0, \theta]\)</span>. The probability density function is:</p>
<p><span class="math display">\[
f(x; \theta) = \frac{1}{\theta}, \quad 0 \le x \le \theta
\]</span></p>
<p>The likelihood function is:</p>
<p><span class="math display">\[
L(\theta | X_1, \dots, X_n) = \prod_{i=1}^n \frac{1}{\theta} I(0 \le X_i \le \theta) = \frac{1}{\theta^n} I(0 \le X_{(1)} \le X_{(n)} \le \theta)
\]</span></p>
<p>where <span class="math inline">\(X_{(1)} = \min(X_1, \dots, X_n)\)</span> and <span class="math inline">\(X_{(n)} = \max(X_1, \dots, X_n)\)</span>. The MLE for <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\hat{\theta} = X_{(n)}\)</span>. The cumulative distribution function (CDF) of <span class="math inline">\(X_{(n)}\)</span> is:</p>
<p><span class="math display">\[
F_{X_{(n)}}(x) = P(X_{(n)} \le x) = \left(\frac{x}{\theta}\right)^n, \quad 0 \le x \le \theta
\]</span></p>
<p>To construct a <span class="math inline">\(1-\alpha\)</span> confidence interval, we want to find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that:</p>
<p><span class="math display">\[
P(a \le \theta \le b) = 1 - \alpha
\]</span></p>
<p>We can use the pivotal quantity <span class="math inline">\(\frac{X_{(n)}}{\theta}\)</span>, which has a distribution independent of <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
P\left(\frac{X_{(n)}}{\theta} \le x\right) = P(X_{(n)} \le \theta x) = \left(\frac{\theta x}{\theta}\right)^n = x^n, \quad 0 \le x \le 1
\]</span></p>
<p>Let <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> be such that <span class="math inline">\(P(c_1 \le \frac{X_{(n)}}{\theta} \le c_2) = 1-\alpha\)</span>. Then:</p>
<p><span class="math display">\[
\int_{c_1}^{c_2} n x^{n-1} dx = c_2^n - c_1^n = 1 - \alpha
\]</span></p>
<p>To find the uniformly most accurate (UMA) interval, we want to minimize the length of the interval <span class="math inline">\([a, b] = [\frac{X_{(n)}}{c_2}, \frac{X_{(n)}}{c_1}]\)</span> subject to <span class="math inline">\(c_2^n - c_1^n = 1-\alpha\)</span>. We choose <span class="math inline">\(c_1 = \alpha^{1/n}\)</span> and <span class="math inline">\(c_2 = 1\)</span>. Then the UMA <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is:</p>
<p><span class="math display">\[
\left[X_{(n)}, \frac{X_{(n)}}{\alpha^{1/n}}\right]
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The maximum likelihood estimator for <span class="math inline">\(\theta\)</span> in a uniform distribution on <span class="math inline">\([0, \theta]\)</span> is the largest order statistic <span class="math inline">\(X_{(n)}\)</span>. The pivotal quantity <span class="math inline">\(\frac{X_{(n)}}{\theta}\)</span> has a distribution that does not depend on <span class="math inline">\(\theta\)</span>. To construct the UMA interval, we choose constants <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> that minimize the length of the interval while maintaining the desired confidence level. The choice of <span class="math inline">\(c_1 = \alpha^{1/n}\)</span> and <span class="math inline">\(c_2 = 1\)</span> achieves this by concentrating the probability on the right tail of the distribution. This concept is related to the discussion on UMA confidence intervals in Section 13.3.</p>
</section>
<section class="level3" id="sec-ch13solution16">
<h3 class="anchored" data-anchor-id="sec-ch13solution16">Solution 16</h3>
<p><a href="#sec-ch13exercise16">Exercise 16</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. The probability mass function is:</p>
<p><span class="math display">\[
P(X=x) = \frac{e^{-\lambda}\lambda^x}{x!}, \quad x = 0, 1, 2, \dots
\]</span></p>
<p>The likelihood function is:</p>
<p><span class="math display">\[
L(\lambda | X_1, \dots, X_n) = \prod_{i=1}^n \frac{e^{-\lambda}\lambda^{X_i}}{X_i!} = \frac{e^{-n\lambda}\lambda^{\sum X_i}}{\prod X_i!}
\]</span></p>
<p>The log-likelihood function is:</p>
<p><span class="math display">\[
l(\lambda) = -n\lambda + \left(\sum_{i=1}^n X_i\right) \log\lambda - \sum_{i=1}^n \log(X_i!)
\]</span></p>
<p>The score function is:</p>
<p><span class="math display">\[
S(\lambda) = \frac{dl}{d\lambda} = -n + \frac{\sum X_i}{\lambda}
\]</span></p>
<p>The maximum likelihood estimator (MLE) is <span class="math inline">\(\hat{\lambda} = \bar{X}\)</span>. The Fisher information is:</p>
<p><span class="math display">\[
I(\lambda) = -E\left[\frac{d^2l}{d\lambda^2}\right] = -E\left[-\frac{\sum X_i}{\lambda^2}\right] = \frac{n\lambda}{\lambda^2} = \frac{n}{\lambda}
\]</span></p>
<p>The score statistic is:</p>
<p><span class="math display">\[
Z = \frac{S(\lambda)}{\sqrt{I(\lambda)}} = \frac{-n + \frac{\sum X_i}{\lambda}}{\sqrt{\frac{n}{\lambda}}} = \frac{\bar{X} - \lambda}{\sqrt{\frac{\lambda}{n}}}
\]</span></p>
<p>Under the null hypothesis <span class="math inline">\(H_0: \lambda = \lambda_0\)</span>, the score statistic <span class="math inline">\(Z\)</span> is asymptotically distributed as <span class="math inline">\(N(0,1)\)</span>. A <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\lambda\)</span> can be constructed by solving:</p>
<p><span class="math display">\[
\left|\frac{\bar{X} - \lambda}{\sqrt{\frac{\lambda}{n}}}\right| \le z_{\alpha/2}
\]</span></p>
<p>Squaring both sides, we get:</p>
<p><span class="math display">\[
(\bar{X} - \lambda)^2 \le z_{\alpha/2}^2 \frac{\lambda}{n}
\]</span></p>
<p><span class="math display">\[
\bar{X}^2 - 2\bar{X}\lambda + \lambda^2 \le z_{\alpha/2}^2 \frac{\lambda}{n}
\]</span></p>
<p><span class="math display">\[
\lambda^2 - \left(2\bar{X} + \frac{z_{\alpha/2}^2}{n}\right)\lambda + \bar{X}^2 \le 0
\]</span></p>
<p>Solving this quadratic inequality for <span class="math inline">\(\lambda\)</span> gives the confidence interval.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The score function is the derivative of the log-likelihood function, and the score statistic is obtained by standardizing the score function using the Fisher information. The score statistic is asymptotically normally distributed under the null hypothesis. The confidence interval is constructed by finding the values of <span class="math inline">\(\lambda\)</span> for which the score statistic is within the critical values of the standard normal distribution. This method is related to the general large sample setting discussed in Section 13.1.1.</p>
</section>
<section class="level3" id="sec-ch13solution17">
<h3 class="anchored" data-anchor-id="sec-ch13solution17">Solution 17</h3>
<p><a href="#sec-ch13exercise17">Exercise 17</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, we want to construct a <span class="math inline">\(1-\alpha\)</span> credible interval for <span class="math inline">\(\mu\)</span> using the Bayesian approach. We assume a normal prior for <span class="math inline">\(\mu\)</span> and an inverse-gamma prior for <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
\mu | \sigma^2 \sim N(\mu_0, \frac{\sigma^2}{\kappa_0})
\]</span></p>
<p><span class="math display">\[
\sigma^2 \sim \text{Inv-Gamma}(\frac{\nu_0}{2}, \frac{\nu_0 \sigma_0^2}{2})
\]</span></p>
<p>The likelihood function is:</p>
<p><span class="math display">\[
L(\mu, \sigma^2 | X_1, \dots, X_n) = (2\pi\sigma^2)^{-n/2} \exp\left(-\frac{1}{2\sigma^2}\sum_{i=1}^n (X_i - \mu)^2\right)
\]</span></p>
<p>The posterior distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> is proportional to the product of the likelihood and the priors:</p>
<p><span class="math display">\[
\pi(\mu, \sigma^2 | X_1, \dots, X_n) \propto L(\mu, \sigma^2 | X_1, \dots, X_n) \pi(\mu | \sigma^2) \pi(\sigma^2)
\]</span></p>
<p>After some algebra, the posterior distributions are:</p>
<p><span class="math display">\[
\mu | \sigma^2, X_1, \dots, X_n \sim N(\mu_n, \frac{\sigma^2}{\kappa_n})
\]</span></p>
<p><span class="math display">\[
\sigma^2 | X_1, \dots, X_n \sim \text{Inv-Gamma}(\frac{\nu_n}{2}, \frac{\nu_n \sigma_n^2}{2})
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\kappa_n = \kappa_0 + n, \quad \mu_n = \frac{\kappa_0 \mu_0 + n\bar{X}}{\kappa_n}, \quad \nu_n = \nu_0 + n
\]</span></p>
<p><span class="math display">\[
\nu_n \sigma_n^2 = \nu_0 \sigma_0^2 + (n-1)s^2 + \frac{\kappa_0 n}{\kappa_0 + n}(\bar{X} - \mu_0)^2
\]</span></p>
<p>The marginal posterior distribution of <span class="math inline">\(\mu\)</span> is a <span class="math inline">\(t\)</span>-distribution:</p>
<p><span class="math display">\[
\frac{\mu - \mu_n}{\sqrt{\sigma_n^2 / \kappa_n}} \sim t_{\nu_n}
\]</span></p>
<p>A <span class="math inline">\(1-\alpha\)</span> credible interval for <span class="math inline">\(\mu\)</span> is given by:</p>
<p><span class="math display">\[
\mu_n \pm t_{\alpha/2, \nu_n} \sqrt{\frac{\sigma_n^2}{\kappa_n}}
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>In the Bayesian approach, we combine prior information about the parameters with the likelihood function to obtain the posterior distribution. The normal and inverse-gamma priors are conjugate priors for the normal likelihood, which means that the posterior distributions have the same form as the priors. The credible interval is constructed using the quantiles of the posterior distribution, in this case, a <span class="math inline">\(t\)</span>-distribution. This method is related to the Bayesian interval discussed in Section 13.2.1.</p>
</section>
<section class="level3" id="sec-ch13solution18">
<h3 class="anchored" data-anchor-id="sec-ch13solution18">Solution 18</h3>
<p><a href="#sec-ch13exercise18">Exercise 18</a></p>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is a random sample from a gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and rate parameter <span class="math inline">\(\beta\)</span>. The probability density function is:</p>
<p><span class="math display">\[
f(x; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}, \quad x &gt; 0
\]</span></p>
<p>The mean of the gamma distribution is <span class="math inline">\(\frac{\alpha}{\beta}\)</span>. Let <span class="math inline">\(\theta = \frac{\alpha}{\beta}\)</span> be the parameter of interest. The sum of independent gamma random variables with the same rate parameter is also gamma distributed. Specifically, if <span class="math inline">\(X_i \sim \text{Gamma}(\alpha, \beta)\)</span>, then <span class="math inline">\(Y = \sum_{i=1}^n X_i \sim \text{Gamma}(n\alpha, \beta)\)</span>.</p>
<p>We can use the fact that <span class="math inline">\(2\beta Y \sim \chi^2_{2n\alpha}\)</span> as a pivotal quantity. Let <span class="math inline">\(Y = \sum_{i=1}^n X_i\)</span>. Then <span class="math inline">\(2\beta Y\)</span> follows a chi-squared distribution with <span class="math inline">\(2n\alpha\)</span> degrees of freedom. We can write:</p>
<p><span class="math display">\[
P\left(\chi^2_{1-\alpha/2, 2n\alpha} \le 2\beta \sum_{i=1}^n X_i \le \chi^2_{\alpha/2, 2n\alpha}\right) = 1 - \alpha
\]</span></p>
<p>Since <span class="math inline">\(\theta = \frac{\alpha}{\beta}\)</span>, we have <span class="math inline">\(\beta = \frac{\alpha}{\theta}\)</span>. Substituting this into the inequality, we get:</p>
<p><span class="math display">\[
P\left(\frac{\chi^2_{1-\alpha/2, 2n\alpha}}{2\sum X_i} \le \frac{\alpha}{\theta} \le \frac{\chi^2_{\alpha/2, 2n\alpha}}{2\sum X_i}\right) = 1 - \alpha
\]</span></p>
<p><span class="math display">\[
P\left(\frac{2\alpha\sum X_i}{\chi^2_{\alpha/2, 2n\alpha}} \le \theta \le \frac{2\alpha\sum X_i}{\chi^2_{1-\alpha/2, 2n\alpha}}\right) = 1-\alpha
\]</span> Thus, a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta = \frac{\alpha}{\beta}\)</span> is given by: <span class="math display">\[
\left(\frac{2\alpha\sum_{i=1}^n X_i}{\chi^2_{\alpha/2, 2n\alpha}}, \frac{2\alpha\sum_{i=1}^n X_i}{\chi^2_{1-\alpha/2, 2n\alpha}}\right)
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A pivotal quantity is a function of the data and parameters whose distribution does not depend on any unknown parameters. In this case, <span class="math inline">\(2\beta Y\)</span> is a pivotal quantity that follows a chi-squared distribution. By finding the quantiles of the chi-squared distribution, we can construct a confidence interval for <span class="math inline">\(\beta\)</span> and then transform it into a confidence interval for the mean <span class="math inline">\(\theta = \frac{\alpha}{\beta}\)</span>. This method is similar to the one used in Example 13.5.</p>
</section>
<section class="level3" id="sec-ch13solution19">
<h3 class="anchored" data-anchor-id="sec-ch13solution19">Solution 19</h3>
<p><a href="#sec-ch13exercise19">Exercise 19</a></p>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a random sample from a geometric distribution with parameter <span class="math inline">\(p\)</span>. The probability mass function is:</p>
<p><span class="math display">\[
P(X=k) = (1-p)^{k-1} p, \quad k = 1, 2, \dots
\]</span></p>
<p>The mean of the geometric distribution is <span class="math inline">\(\mu = \frac{1}{p}\)</span>, and the variance is <span class="math inline">\(\sigma^2 = \frac{1-p}{p^2}\)</span>. The maximum likelihood estimator (MLE) for <span class="math inline">\(p\)</span> is <span class="math inline">\(\hat{p} = \frac{1}{\bar{X}}\)</span>, where <span class="math inline">\(\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i\)</span> is the sample mean.</p>
<p>By the Central Limit Theorem (CLT), for large <span class="math inline">\(n\)</span>, the sample mean <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed:</p>
<p><span class="math display">\[
\bar{X} \sim N\left(\frac{1}{p}, \frac{1-p}{np^2}\right)
\]</span></p>
<p>We can standardize <span class="math inline">\(\bar{X}\)</span>:</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \frac{1}{p}}{\sqrt{\frac{1-p}{np^2}}} = \frac{\bar{X} - \frac{1}{p}}{\frac{1}{p}\sqrt{\frac{1-p}{n}}} \sim N(0,1)
\]</span></p>
<p>Since <span class="math inline">\(\hat{p} = \frac{1}{\bar{X}}\)</span>, we can rewrite the standardized statistic in terms of <span class="math inline">\(\hat{p}\)</span>:</p>
<p><span class="math display">\[
Z = \frac{\frac{1}{\hat{p}} - \frac{1}{p}}{\frac{1}{p}\sqrt{\frac{1-p}{n}}} = \frac{p - \hat{p}}{\hat{p}} \sqrt{\frac{n}{1-p}}
\]</span></p>
<p>However, this expression still depends on the unknown parameter <span class="math inline">\(p\)</span>. We can use the delta method to approximate the distribution of <span class="math inline">\(\hat{p}\)</span>. Since <span class="math inline">\(\hat{p} = g(\bar{X}) = \frac{1}{\bar{X}}\)</span>, we have <span class="math inline">\(g'(\bar{X}) = -\frac{1}{\bar{X}^2}\)</span>. By the delta method:</p>
<p><span class="math display">\[
\sqrt{n}(\hat{p} - p) \xrightarrow{d} N(0, (g'(\mu))^2 \sigma^2)
\]</span></p>
<p><span class="math display">\[
\sqrt{n}(\hat{p} - p) \xrightarrow{d} N\left(0, \left(-\frac{1}{(1/p)^2}\right)^2 \frac{1-p}{p^2}\right) = N(0, p^2(1-p))
\]</span></p>
<p>Thus, an approximate <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(p\)</span> is given by:</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}^2(1-\hat{p})}{n}}
\]</span></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The Central Limit Theorem allows us to approximate the distribution of the sample mean <span class="math inline">\(\bar{X}\)</span> as normal for large <span class="math inline">\(n\)</span>. Since the MLE <span class="math inline">\(\hat{p}\)</span> is a function of <span class="math inline">\(\bar{X}\)</span>, we can use the delta method to approximate the distribution of <span class="math inline">\(\hat{p}\)</span>. The delta method provides a way to approximate the variance of a function of a random variable. The confidence interval is then constructed using the estimated standard error of <span class="math inline">\(\hat{p}\)</span>. This method is related to the general large sample setting discussed in Section 13.1.1.</p>
</section>
<section class="level3" id="sec-ch13solution20">
<h3 class="anchored" data-anchor-id="sec-ch13solution20">Solution 20</h3>
<p><a href="#sec-ch13exercise20">Exercise 20</a></p>
<p>Given a random sample <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> from a <span class="math inline">\(N(\mu, \sigma^2)\)</span> distribution, we know that:</p>
<p><span class="math display">\[
\frac{(n-1)s^2}{\sigma^2} \sim \chi^2_{n-1}
\]</span></p>
<p>where <span class="math inline">\(s^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\)</span> is the sample variance. Let <span class="math inline">\(\chi^2_{\alpha/2, n-1}\)</span> and <span class="math inline">\(\chi^2_{1-\alpha/2, n-1}\)</span> be the lower and upper <span class="math inline">\(\alpha/2\)</span> quantiles of the <span class="math inline">\(\chi^2_{n-1}\)</span> distribution. Then:</p>
<p><span class="math display">\[
P\left(\chi^2_{1-\alpha/2, n-1} \le \frac{(n-1)s^2}{\sigma^2} \le \chi^2_{\alpha/2, n-1}\right) = 1 - \alpha
\]</span></p>
<p>Rearranging for <span class="math inline">\(\sigma^2\)</span>, we get a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
\left(\frac{(n-1)s^2}{\chi^2_{\alpha/2, n-1}}, \frac{(n-1)s^2}{\chi^2_{1-\alpha/2, n-1}}\right)
\]</span></p>
<p>This interval is unbiased, meaning that the probability of covering any false value <span class="math inline">\(\sigma'^2\)</span> is less than or equal to <span class="math inline">\(1-\alpha\)</span>. To show that it is also the uniformly most accurate unbiased (UMAU) confidence interval, we need to consider the expected length of the interval. The expected length of the interval is:</p>
<p><span class="math display">\[
E\left[\frac{(n-1)s^2}{\chi^2_{1-\alpha/2, n-1}} - \frac{(n-1)s^2}{\chi^2_{\alpha/2, n-1}}\right] = (n-1)\sigma^2 \left(\frac{1}{\chi^2_{1-\alpha/2, n-1}} - \frac{1}{\chi^2_{\alpha/2, n-1}}\right)
\]</span></p>
<p>Minimizing this expected length is equivalent to minimizing the difference <span class="math inline">\(\frac{1}{\chi^2_{1-\alpha/2, n-1}} - \frac{1}{\chi^2_{\alpha/2, n-1}}\)</span>. It can be shown that the UMAU interval is obtained by choosing <span class="math inline">\(\chi^2_{1-\alpha/2, n-1}\)</span> and <span class="math inline">\(\chi^2_{\alpha/2, n-1}\)</span> such that the interval is unbiased.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The confidence interval for <span class="math inline">\(\sigma^2\)</span> is derived from the chi-squared distribution of the scaled sample variance. The unbiasedness property ensures that the interval is more likely to cover the true value of <span class="math inline">\(\sigma^2\)</span> than any other false value. The UMAU property means that among all unbiased confidence intervals, this interval has the shortest expected length. The construction of the interval is based on the pivotal quantity <span class="math inline">\(\frac{(n-1)s^2}{\sigma^2}\)</span>, similar to the method used in Example 13.5. The concepts of unbiased and UMAU confidence intervals are discussed in Section 13.3.</p>
</section>
</section>
<section class="level2" id="r-script-examples">
<h2 class="anchored" data-anchor-id="r-script-examples">R Script Examples</h2>
<section class="level3" id="r-script-1-constructing-and-visualizing-confidence-intervals-for-the-mean-of-a-normal-distribution-with-known-variance">
<h3 class="anchored" data-anchor-id="r-script-1-constructing-and-visualizing-confidence-intervals-for-the-mean-of-a-normal-distribution-with-known-variance">R Script 1: Constructing and visualizing confidence intervals for the mean of a normal distribution with known variance</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a aria-hidden="true" href="#cb1-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1-2"><a aria-hidden="true" href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a aria-hidden="true" href="#cb3-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-2"><a aria-hidden="true" href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a aria-hidden="true" href="#cb3-3" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb3-4"><a aria-hidden="true" href="#cb3-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb3-5"><a aria-hidden="true" href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a aria-hidden="true" href="#cb3-6" tabindex="-1"></a><span class="co"># Define parameters</span></span>
<span id="cb3-7"><a aria-hidden="true" href="#cb3-7" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">10</span>  <span class="co"># True mean</span></span>
<span id="cb3-8"><a aria-hidden="true" href="#cb3-8" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">2</span>  <span class="co"># True standard deviation</span></span>
<span id="cb3-9"><a aria-hidden="true" href="#cb3-9" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># Sample size</span></span>
<span id="cb3-10"><a aria-hidden="true" href="#cb3-10" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb3-11"><a aria-hidden="true" href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a aria-hidden="true" href="#cb3-12" tabindex="-1"></a><span class="co"># Generate a random sample from a normal distribution</span></span>
<span id="cb3-13"><a aria-hidden="true" href="#cb3-13" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma)</span>
<span id="cb3-14"><a aria-hidden="true" href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a aria-hidden="true" href="#cb3-15" tabindex="-1"></a><span class="co"># Calculate the sample mean</span></span>
<span id="cb3-16"><a aria-hidden="true" href="#cb3-16" tabindex="-1"></a>sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_data)</span>
<span id="cb3-17"><a aria-hidden="true" href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a aria-hidden="true" href="#cb3-18" tabindex="-1"></a><span class="co"># Calculate the critical value from the standard normal distribution</span></span>
<span id="cb3-19"><a aria-hidden="true" href="#cb3-19" tabindex="-1"></a>z_critical <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb3-20"><a aria-hidden="true" href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a aria-hidden="true" href="#cb3-21" tabindex="-1"></a><span class="co"># Calculate the margin of error</span></span>
<span id="cb3-22"><a aria-hidden="true" href="#cb3-22" tabindex="-1"></a>margin_of_error <span class="ot">&lt;-</span> z_critical <span class="sc">*</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb3-23"><a aria-hidden="true" href="#cb3-23" tabindex="-1"></a></span>
<span id="cb3-24"><a aria-hidden="true" href="#cb3-24" tabindex="-1"></a><span class="co"># Calculate the confidence interval</span></span>
<span id="cb3-25"><a aria-hidden="true" href="#cb3-25" tabindex="-1"></a>confidence_interval <span class="ot">&lt;-</span> <span class="fu">c</span>(sample_mean <span class="sc">-</span> margin_of_error, sample_mean <span class="sc">+</span> margin_of_error)</span>
<span id="cb3-26"><a aria-hidden="true" href="#cb3-26" tabindex="-1"></a></span>
<span id="cb3-27"><a aria-hidden="true" href="#cb3-27" tabindex="-1"></a><span class="co"># Print the confidence interval</span></span>
<span id="cb3-28"><a aria-hidden="true" href="#cb3-28" tabindex="-1"></a><span class="fu">print</span>(confidence_interval)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  9.190115 10.621470</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a aria-hidden="true" href="#cb5-1" tabindex="-1"></a><span class="co"># Create a data frame for visualization</span></span>
<span id="cb5-2"><a aria-hidden="true" href="#cb5-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> sample_data)</span>
<span id="cb5-3"><a aria-hidden="true" href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a aria-hidden="true" href="#cb5-4" tabindex="-1"></a><span class="co"># Visualize the sample data and the confidence interval</span></span>
<span id="cb5-5"><a aria-hidden="true" href="#cb5-5" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb5-6"><a aria-hidden="true" href="#cb5-6" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.5</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb5-7"><a aria-hidden="true" href="#cb5-7" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> sample_mean, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb5-8"><a aria-hidden="true" href="#cb5-8" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> confidence_interval[<span class="dv">1</span>], <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb5-9"><a aria-hidden="true" href="#cb5-9" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> confidence_interval[<span class="dv">2</span>], <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb5-10"><a aria-hidden="true" href="#cb5-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Sample Data with 95% Confidence Interval for the Mean"</span>,</span>
<span id="cb5-11"><a aria-hidden="true" href="#cb5-11" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Data"</span>,</span>
<span id="cb5-12"><a aria-hidden="true" href="#cb5-12" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb5-13"><a aria-hidden="true" href="#cb5-13" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap13_files/figure-html/unnamed-chunk-1-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Intuitive Explanation:</strong></p>
<ol type="1">
<li><p><strong>Load Libraries and Set Parameters:</strong> We load the <code>tidyverse</code> and <code>ggplot2</code> libraries for data manipulation and visualization. We set the seed for reproducibility and define the true mean (<code>mu</code>), true standard deviation (<code>sigma</code>), sample size (<code>n</code>), and significance level (<code>alpha</code>).</p></li>
<li><p><strong>Generate Sample:</strong> We generate a random sample of size <code>n</code> from a normal distribution with mean <code>mu</code> and standard deviation <code>sigma</code> using <code>rnorm()</code>.</p></li>
<li><p><strong>Calculate Sample Mean:</strong> We calculate the sample mean using <code>mean()</code>.</p></li>
<li><p><strong>Calculate Critical Value:</strong> We find the critical value <code>z_critical</code> from the standard normal distribution corresponding to the desired confidence level (1 - <code>alpha</code>) using <code>qnorm()</code>.</p></li>
<li><p><strong>Calculate Margin of Error:</strong> We calculate the margin of error using the formula:</p>
<p><span class="math display">\[
\text{Margin of Error} = z_{\alpha/2} \frac{\sigma}{\sqrt{n}}
\]</span></p></li>
<li><p><strong>Calculate Confidence Interval:</strong> We calculate the confidence interval by adding and subtracting the margin of error from the sample mean:</p>
<p><span class="math display">\[
\text{Confidence Interval} = \left( \bar{X} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{X} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \right)
\]</span></p></li>
<li><p><strong>Visualize:</strong> We create a histogram of the sample data and overlay vertical lines for the sample mean (dashed red line) and the confidence interval limits (dotted blue lines) using <code>ggplot2</code>.</p></li>
</ol>
<p><strong>Relationship to Text:</strong></p>
<p>This script illustrates the concepts discussed in <strong>Example 13.2</strong> of the text, where a confidence interval for the mean of a normal distribution with known variance is derived. The script demonstrates how to calculate the confidence interval using the formula mentioned in the example and visualizes the interval along with the sample data.</p>
</section>
<section class="level3" id="r-script-2-constructing-confidence-intervals-for-the-difference-in-means-of-two-normal-distributions-with-unknown-but-equal-variances">
<h3 class="anchored" data-anchor-id="r-script-2-constructing-confidence-intervals-for-the-difference-in-means-of-two-normal-distributions-with-unknown-but-equal-variances">R Script 2: Constructing confidence intervals for the difference in means of two normal distributions with unknown but equal variances</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a aria-hidden="true" href="#cb6-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb6-2"><a aria-hidden="true" href="#cb6-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb6-3"><a aria-hidden="true" href="#cb6-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-4"><a aria-hidden="true" href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a aria-hidden="true" href="#cb6-5" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb6-6"><a aria-hidden="true" href="#cb6-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb6-7"><a aria-hidden="true" href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a aria-hidden="true" href="#cb6-8" tabindex="-1"></a><span class="co"># Define parameters for the two populations</span></span>
<span id="cb6-9"><a aria-hidden="true" href="#cb6-9" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb6-10"><a aria-hidden="true" href="#cb6-10" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb6-11"><a aria-hidden="true" href="#cb6-11" tabindex="-1"></a>sigma_common <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb6-12"><a aria-hidden="true" href="#cb6-12" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb6-13"><a aria-hidden="true" href="#cb6-13" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb6-14"><a aria-hidden="true" href="#cb6-14" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb6-15"><a aria-hidden="true" href="#cb6-15" tabindex="-1"></a></span>
<span id="cb6-16"><a aria-hidden="true" href="#cb6-16" tabindex="-1"></a><span class="co"># Generate random samples from two normal distributions</span></span>
<span id="cb6-17"><a aria-hidden="true" href="#cb6-17" tabindex="-1"></a>sample1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n1, <span class="at">mean =</span> mu1, <span class="at">sd =</span> sigma_common)</span>
<span id="cb6-18"><a aria-hidden="true" href="#cb6-18" tabindex="-1"></a>sample2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n2, <span class="at">mean =</span> mu2, <span class="at">sd =</span> sigma_common)</span>
<span id="cb6-19"><a aria-hidden="true" href="#cb6-19" tabindex="-1"></a></span>
<span id="cb6-20"><a aria-hidden="true" href="#cb6-20" tabindex="-1"></a><span class="co"># Calculate sample means and variances</span></span>
<span id="cb6-21"><a aria-hidden="true" href="#cb6-21" tabindex="-1"></a>xbar1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample1)</span>
<span id="cb6-22"><a aria-hidden="true" href="#cb6-22" tabindex="-1"></a>xbar2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample2)</span>
<span id="cb6-23"><a aria-hidden="true" href="#cb6-23" tabindex="-1"></a>s1_sq <span class="ot">&lt;-</span> <span class="fu">var</span>(sample1)</span>
<span id="cb6-24"><a aria-hidden="true" href="#cb6-24" tabindex="-1"></a>s2_sq <span class="ot">&lt;-</span> <span class="fu">var</span>(sample2)</span>
<span id="cb6-25"><a aria-hidden="true" href="#cb6-25" tabindex="-1"></a></span>
<span id="cb6-26"><a aria-hidden="true" href="#cb6-26" tabindex="-1"></a><span class="co"># Calculate the pooled variance</span></span>
<span id="cb6-27"><a aria-hidden="true" href="#cb6-27" tabindex="-1"></a>s_pooled_sq <span class="ot">&lt;-</span> ((n1 <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> s1_sq <span class="sc">+</span> (n2 <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> s2_sq) <span class="sc">/</span> (n1 <span class="sc">+</span> n2 <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb6-28"><a aria-hidden="true" href="#cb6-28" tabindex="-1"></a></span>
<span id="cb6-29"><a aria-hidden="true" href="#cb6-29" tabindex="-1"></a><span class="co"># Calculate the standard error of the difference in means</span></span>
<span id="cb6-30"><a aria-hidden="true" href="#cb6-30" tabindex="-1"></a>se_diff <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(s_pooled_sq <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">/</span> n1 <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> n2))</span>
<span id="cb6-31"><a aria-hidden="true" href="#cb6-31" tabindex="-1"></a></span>
<span id="cb6-32"><a aria-hidden="true" href="#cb6-32" tabindex="-1"></a><span class="co"># Calculate the degrees of freedom</span></span>
<span id="cb6-33"><a aria-hidden="true" href="#cb6-33" tabindex="-1"></a>df <span class="ot">&lt;-</span> n1 <span class="sc">+</span> n2 <span class="sc">-</span> <span class="dv">2</span></span>
<span id="cb6-34"><a aria-hidden="true" href="#cb6-34" tabindex="-1"></a></span>
<span id="cb6-35"><a aria-hidden="true" href="#cb6-35" tabindex="-1"></a><span class="co"># Calculate the critical value from the t-distribution</span></span>
<span id="cb6-36"><a aria-hidden="true" href="#cb6-36" tabindex="-1"></a>t_critical <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>, df)</span>
<span id="cb6-37"><a aria-hidden="true" href="#cb6-37" tabindex="-1"></a></span>
<span id="cb6-38"><a aria-hidden="true" href="#cb6-38" tabindex="-1"></a><span class="co"># Calculate the margin of error</span></span>
<span id="cb6-39"><a aria-hidden="true" href="#cb6-39" tabindex="-1"></a>margin_of_error <span class="ot">&lt;-</span> t_critical <span class="sc">*</span> se_diff</span>
<span id="cb6-40"><a aria-hidden="true" href="#cb6-40" tabindex="-1"></a></span>
<span id="cb6-41"><a aria-hidden="true" href="#cb6-41" tabindex="-1"></a><span class="co"># Calculate the confidence interval for the difference in means</span></span>
<span id="cb6-42"><a aria-hidden="true" href="#cb6-42" tabindex="-1"></a>confidence_interval <span class="ot">&lt;-</span> <span class="fu">c</span>((xbar1 <span class="sc">-</span> xbar2) <span class="sc">-</span> margin_of_error, (xbar1 <span class="sc">-</span> xbar2) <span class="sc">+</span> margin_of_error)</span>
<span id="cb6-43"><a aria-hidden="true" href="#cb6-43" tabindex="-1"></a></span>
<span id="cb6-44"><a aria-hidden="true" href="#cb6-44" tabindex="-1"></a><span class="co"># Print the confidence interval</span></span>
<span id="cb6-45"><a aria-hidden="true" href="#cb6-45" tabindex="-1"></a><span class="fu">print</span>(confidence_interval)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -6.205530 -2.580305</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a aria-hidden="true" href="#cb8-1" tabindex="-1"></a><span class="co"># Create a data frame for visualization</span></span>
<span id="cb8-2"><a aria-hidden="true" href="#cb8-2" tabindex="-1"></a>df_samples <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb8-3"><a aria-hidden="true" href="#cb8-3" tabindex="-1"></a>  <span class="at">sample =</span> <span class="fu">c</span>(sample1, sample2),</span>
<span id="cb8-4"><a aria-hidden="true" href="#cb8-4" tabindex="-1"></a>  <span class="at">group =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Sample 1"</span>, <span class="st">"Sample 2"</span>), <span class="fu">c</span>(n1, n2))</span>
<span id="cb8-5"><a aria-hidden="true" href="#cb8-5" tabindex="-1"></a>)</span>
<span id="cb8-6"><a aria-hidden="true" href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a aria-hidden="true" href="#cb8-7" tabindex="-1"></a><span class="co"># Visualize the sample data and the confidence interval</span></span>
<span id="cb8-8"><a aria-hidden="true" href="#cb8-8" tabindex="-1"></a><span class="fu">ggplot</span>(df_samples, <span class="fu">aes</span>(<span class="at">x =</span> group, <span class="at">y =</span> sample)) <span class="sc">+</span></span>
<span id="cb8-9"><a aria-hidden="true" href="#cb8-9" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb8-10"><a aria-hidden="true" href="#cb8-10" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb8-11"><a aria-hidden="true" href="#cb8-11" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Sample Data with 95% Confidence Interval for Difference in Means"</span>,</span>
<span id="cb8-12"><a aria-hidden="true" href="#cb8-12" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Group"</span>,</span>
<span id="cb8-13"><a aria-hidden="true" href="#cb8-13" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Sample Value"</span></span>
<span id="cb8-14"><a aria-hidden="true" href="#cb8-14" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb8-15"><a aria-hidden="true" href="#cb8-15" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb8-16"><a aria-hidden="true" href="#cb8-16" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb8-17"><a aria-hidden="true" href="#cb8-17" tabindex="-1"></a>    <span class="at">yintercept =</span> xbar1 <span class="sc">-</span> xbar2,</span>
<span id="cb8-18"><a aria-hidden="true" href="#cb8-18" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"red"</span>,</span>
<span id="cb8-19"><a aria-hidden="true" href="#cb8-19" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dashed"</span></span>
<span id="cb8-20"><a aria-hidden="true" href="#cb8-20" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb8-21"><a aria-hidden="true" href="#cb8-21" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb8-22"><a aria-hidden="true" href="#cb8-22" tabindex="-1"></a>    <span class="at">yintercept =</span> confidence_interval[<span class="dv">1</span>],</span>
<span id="cb8-23"><a aria-hidden="true" href="#cb8-23" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"blue"</span>,</span>
<span id="cb8-24"><a aria-hidden="true" href="#cb8-24" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dotted"</span></span>
<span id="cb8-25"><a aria-hidden="true" href="#cb8-25" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb8-26"><a aria-hidden="true" href="#cb8-26" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb8-27"><a aria-hidden="true" href="#cb8-27" tabindex="-1"></a>    <span class="at">yintercept =</span> confidence_interval[<span class="dv">2</span>],</span>
<span id="cb8-28"><a aria-hidden="true" href="#cb8-28" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"blue"</span>,</span>
<span id="cb8-29"><a aria-hidden="true" href="#cb8-29" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dotted"</span></span>
<span id="cb8-30"><a aria-hidden="true" href="#cb8-30" tabindex="-1"></a>  )</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap13_files/figure-html/unnamed-chunk-2-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Intuitive Explanation:</strong></p>
<ol type="1">
<li><p><strong>Load Libraries and Set Parameters:</strong> We load the <code>tidyverse</code> and <code>ggplot2</code> libraries. We set the seed and define the true means (<code>mu1</code>, <code>mu2</code>), common standard deviation (<code>sigma_common</code>), sample sizes (<code>n1</code>, <code>n2</code>), and significance level (<code>alpha</code>).</p></li>
<li><p><strong>Generate Samples:</strong> We generate random samples from two normal distributions with the specified parameters.</p></li>
<li><p><strong>Calculate Sample Statistics:</strong> We calculate the sample means (<code>xbar1</code>, <code>xbar2</code>) and sample variances (<code>s1_sq</code>, <code>s2_sq</code>).</p></li>
<li><p><strong>Calculate Pooled Variance:</strong> We calculate the pooled variance, which is an estimate of the common variance, using the formula:</p>
<p><span class="math display">\[
s_{p}^{2} = \frac{(n_{1} - 1)s_{1}^{2} + (n_{2} - 1)s_{2}^{2}}{n_{1} + n_{2} - 2}
\]</span></p></li>
<li><p><strong>Calculate Standard Error:</strong> We calculate the standard error of the difference in means using the formula:</p>
<p><span class="math display">\[
SE(\bar{X}_{1} - \bar{X}_{2}) = \sqrt{s_{p}^{2} \left( \frac{1}{n_{1}} + \frac{1}{n_{2}} \right)}
\]</span></p></li>
<li><p><strong>Calculate Degrees of Freedom:</strong> We calculate the degrees of freedom as <code>df</code> = <code>n1</code> + <code>n2</code> - 2.</p></li>
<li><p><strong>Calculate Critical Value:</strong> We find the critical value <code>t_critical</code> from the <span class="math inline">\(t\)</span>-distribution corresponding to the desired confidence level and degrees of freedom using <code>qt()</code>.</p></li>
<li><p><strong>Calculate Margin of Error:</strong> We calculate the margin of error as:</p>
<p><span class="math display">\[
\text{Margin of Error} = t_{\alpha/2, df} \times SE(\bar{X}_{1} - \bar{X}_{2})
\]</span></p></li>
<li><p><strong>Calculate Confidence Interval:</strong> We calculate the confidence interval for the difference in means as:</p>
<p><span class="math display">\[
\text{Confidence Interval} = (\bar{X}_{1} - \bar{X}_{2}) \pm \text{Margin of Error}
\]</span></p></li>
<li><p><strong>Visualize:</strong> We create boxplots of the two samples using <code>ggplot2</code> and overlay horizontal lines for the difference in sample means (dashed red line) and the confidence interval limits (dotted blue lines).</p></li>
</ol>
<p><strong>Relationship to Text:</strong></p>
<p>This script extends the concept of confidence intervals to the difference in means of two normal populations with unknown but equal variances. It demonstrates the use of the pooled variance and the <span class="math inline">\(t\)</span>-distribution, which are related to the concepts discussed in <strong>Example 13.3</strong> where the <span class="math inline">\(t\)</span>-distribution is used for constructing confidence intervals when the population variance is unknown. Although Example 13.3 focuses on a single population, the principles of using the <span class="math inline">\(t\)</span>-distribution and estimating the variance are similar.</p>
</section>
<section class="level3" id="r-script-3-constructing-and-visualizing-confidence-intervals-for-a-population-proportion">
<h3 class="anchored" data-anchor-id="r-script-3-constructing-and-visualizing-confidence-intervals-for-a-population-proportion">R Script 3: Constructing and visualizing confidence intervals for a population proportion</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a aria-hidden="true" href="#cb9-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb9-2"><a aria-hidden="true" href="#cb9-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb9-3"><a aria-hidden="true" href="#cb9-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb9-4"><a aria-hidden="true" href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a aria-hidden="true" href="#cb9-5" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb9-6"><a aria-hidden="true" href="#cb9-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb9-7"><a aria-hidden="true" href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a aria-hidden="true" href="#cb9-8" tabindex="-1"></a><span class="co"># Define parameters</span></span>
<span id="cb9-9"><a aria-hidden="true" href="#cb9-9" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.6</span>  <span class="co"># True proportion</span></span>
<span id="cb9-10"><a aria-hidden="true" href="#cb9-10" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Sample size</span></span>
<span id="cb9-11"><a aria-hidden="true" href="#cb9-11" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb9-12"><a aria-hidden="true" href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a aria-hidden="true" href="#cb9-13" tabindex="-1"></a><span class="co"># Generate a random sample from a Bernoulli distribution</span></span>
<span id="cb9-14"><a aria-hidden="true" href="#cb9-14" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> p)</span>
<span id="cb9-15"><a aria-hidden="true" href="#cb9-15" tabindex="-1"></a></span>
<span id="cb9-16"><a aria-hidden="true" href="#cb9-16" tabindex="-1"></a><span class="co"># Calculate the sample proportion</span></span>
<span id="cb9-17"><a aria-hidden="true" href="#cb9-17" tabindex="-1"></a>p_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_data)</span>
<span id="cb9-18"><a aria-hidden="true" href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a aria-hidden="true" href="#cb9-19" tabindex="-1"></a><span class="co"># Calculate the standard error of the sample proportion</span></span>
<span id="cb9-20"><a aria-hidden="true" href="#cb9-20" tabindex="-1"></a>se_p_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(p_hat <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p_hat) <span class="sc">/</span> n)</span>
<span id="cb9-21"><a aria-hidden="true" href="#cb9-21" tabindex="-1"></a></span>
<span id="cb9-22"><a aria-hidden="true" href="#cb9-22" tabindex="-1"></a><span class="co"># Calculate the critical value from the standard normal distribution</span></span>
<span id="cb9-23"><a aria-hidden="true" href="#cb9-23" tabindex="-1"></a>z_critical <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb9-24"><a aria-hidden="true" href="#cb9-24" tabindex="-1"></a></span>
<span id="cb9-25"><a aria-hidden="true" href="#cb9-25" tabindex="-1"></a><span class="co"># Calculate the margin of error</span></span>
<span id="cb9-26"><a aria-hidden="true" href="#cb9-26" tabindex="-1"></a>margin_of_error <span class="ot">&lt;-</span> z_critical <span class="sc">*</span> se_p_hat</span>
<span id="cb9-27"><a aria-hidden="true" href="#cb9-27" tabindex="-1"></a></span>
<span id="cb9-28"><a aria-hidden="true" href="#cb9-28" tabindex="-1"></a><span class="co"># Calculate the confidence interval</span></span>
<span id="cb9-29"><a aria-hidden="true" href="#cb9-29" tabindex="-1"></a>confidence_interval <span class="ot">&lt;-</span> <span class="fu">c</span>(p_hat <span class="sc">-</span> margin_of_error, p_hat <span class="sc">+</span> margin_of_error)</span>
<span id="cb9-30"><a aria-hidden="true" href="#cb9-30" tabindex="-1"></a></span>
<span id="cb9-31"><a aria-hidden="true" href="#cb9-31" tabindex="-1"></a><span class="co"># Print the confidence interval</span></span>
<span id="cb9-32"><a aria-hidden="true" href="#cb9-32" tabindex="-1"></a><span class="fu">print</span>(confidence_interval)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5671548 0.7528452</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a aria-hidden="true" href="#cb11-1" tabindex="-1"></a><span class="co"># Create a data frame for visualization</span></span>
<span id="cb11-2"><a aria-hidden="true" href="#cb11-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> sample_data)</span>
<span id="cb11-3"><a aria-hidden="true" href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a aria-hidden="true" href="#cb11-4" tabindex="-1"></a><span class="co"># Visualize the sample data and the confidence interval</span></span>
<span id="cb11-5"><a aria-hidden="true" href="#cb11-5" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(x))) <span class="sc">+</span></span>
<span id="cb11-6"><a aria-hidden="true" href="#cb11-6" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb11-7"><a aria-hidden="true" href="#cb11-7" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> p_hat <span class="sc">*</span> n, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb11-8"><a aria-hidden="true" href="#cb11-8" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> confidence_interval[<span class="dv">1</span>] <span class="sc">*</span> n, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb11-9"><a aria-hidden="true" href="#cb11-9" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> confidence_interval[<span class="dv">2</span>] <span class="sc">*</span> n, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb11-10"><a aria-hidden="true" href="#cb11-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Sample Data with 95% Confidence Interval for Proportion"</span>,</span>
<span id="cb11-11"><a aria-hidden="true" href="#cb11-11" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Outcome"</span>,</span>
<span id="cb11-12"><a aria-hidden="true" href="#cb11-12" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb11-13"><a aria-hidden="true" href="#cb11-13" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap13_files/figure-html/unnamed-chunk-3-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Intuitive Explanation:</strong></p>
<ol type="1">
<li><p><strong>Load Libraries and Set Parameters:</strong> We load the <code>tidyverse</code> and <code>ggplot2</code> libraries. We set the seed and define the true proportion (<code>p</code>), sample size (<code>n</code>), and significance level (<code>alpha</code>).</p></li>
<li><p><strong>Generate Sample:</strong> We generate a random sample of size <code>n</code> from a Bernoulli distribution with probability of success <code>p</code> using <code>rbinom()</code>.</p></li>
<li><p><strong>Calculate Sample Proportion:</strong> We calculate the sample proportion <code>p_hat</code> using <code>mean()</code>.</p></li>
<li><p><strong>Calculate Standard Error:</strong> We calculate the standard error of the sample proportion using the formula:</p>
<p><span class="math display">\[
SE(\hat{p}) = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
\]</span></p></li>
<li><p><strong>Calculate Critical Value:</strong> We find the critical value <code>z_critical</code> from the standard normal distribution corresponding to the desired confidence level using <code>qnorm()</code>.</p></li>
<li><p><strong>Calculate Margin of Error:</strong> We calculate the margin of error as:</p>
<p><span class="math display">\[
\text{Margin of Error} = z_{\alpha/2} \times SE(\hat{p})
\]</span></p></li>
<li><p><strong>Calculate Confidence Interval:</strong> We calculate the confidence interval for the population proportion as:</p>
<p><span class="math display">\[
\text{Confidence Interval} = \hat{p} \pm \text{Margin of Error}
\]</span></p></li>
<li><p><strong>Visualize:</strong> We create a bar chart of the sample data using <code>ggplot2</code> and overlay horizontal lines for the sample proportion (dashed red line) and the confidence interval limits (dotted blue lines). We multiply the proportions by n to place the horizontal lines at the appropriate frequency levels on the chart.</p></li>
</ol>
<p><strong>Relationship to Text:</strong></p>
<p>This script illustrates the concepts discussed in <strong>Example 13.11</strong> of the text, where a large sample confidence interval for a population proportion is derived. The script demonstrates how to calculate the confidence interval using the formula mentioned in the example and visualizes the interval along with the sample data.</p>
</section>
<section class="level3" id="r-script-4-constructing-and-visualizing-confidence-intervals-using-the-likelihood-ratio-method">
<h3 class="anchored" data-anchor-id="r-script-4-constructing-and-visualizing-confidence-intervals-using-the-likelihood-ratio-method">R Script 4: Constructing and visualizing confidence intervals using the likelihood ratio method</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a aria-hidden="true" href="#cb12-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb12-2"><a aria-hidden="true" href="#cb12-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb12-3"><a aria-hidden="true" href="#cb12-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb12-4"><a aria-hidden="true" href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a aria-hidden="true" href="#cb12-5" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb12-6"><a aria-hidden="true" href="#cb12-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb12-7"><a aria-hidden="true" href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a aria-hidden="true" href="#cb12-8" tabindex="-1"></a><span class="co"># Define parameters for the exponential distribution</span></span>
<span id="cb12-9"><a aria-hidden="true" href="#cb12-9" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb12-10"><a aria-hidden="true" href="#cb12-10" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb12-11"><a aria-hidden="true" href="#cb12-11" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb12-12"><a aria-hidden="true" href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a aria-hidden="true" href="#cb12-13" tabindex="-1"></a><span class="co"># Generate a random sample from an exponential distribution</span></span>
<span id="cb12-14"><a aria-hidden="true" href="#cb12-14" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> <span class="fu">rexp</span>(n, <span class="at">rate =</span> <span class="dv">1</span> <span class="sc">/</span> theta)</span>
<span id="cb12-15"><a aria-hidden="true" href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a aria-hidden="true" href="#cb12-16" tabindex="-1"></a><span class="co"># Calculate the sample mean (MLE for theta)</span></span>
<span id="cb12-17"><a aria-hidden="true" href="#cb12-17" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_data)</span>
<span id="cb12-18"><a aria-hidden="true" href="#cb12-18" tabindex="-1"></a></span>
<span id="cb12-19"><a aria-hidden="true" href="#cb12-19" tabindex="-1"></a><span class="co"># Define the log-likelihood function for the exponential distribution</span></span>
<span id="cb12-20"><a aria-hidden="true" href="#cb12-20" tabindex="-1"></a>log_likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data) {</span>
<span id="cb12-21"><a aria-hidden="true" href="#cb12-21" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb12-22"><a aria-hidden="true" href="#cb12-22" tabindex="-1"></a>  <span class="sc">-</span>n <span class="sc">*</span> <span class="fu">log</span>(theta) <span class="sc">-</span> <span class="fu">sum</span>(data) <span class="sc">/</span> theta</span>
<span id="cb12-23"><a aria-hidden="true" href="#cb12-23" tabindex="-1"></a>}</span>
<span id="cb12-24"><a aria-hidden="true" href="#cb12-24" tabindex="-1"></a></span>
<span id="cb12-25"><a aria-hidden="true" href="#cb12-25" tabindex="-1"></a><span class="co"># Calculate the observed log-likelihood at the MLE</span></span>
<span id="cb12-26"><a aria-hidden="true" href="#cb12-26" tabindex="-1"></a>observed_loglik <span class="ot">&lt;-</span> <span class="fu">log_likelihood</span>(theta_hat, sample_data)</span>
<span id="cb12-27"><a aria-hidden="true" href="#cb12-27" tabindex="-1"></a></span>
<span id="cb12-28"><a aria-hidden="true" href="#cb12-28" tabindex="-1"></a><span class="co"># Define the function to find the critical value for the likelihood ratio test</span></span>
<span id="cb12-29"><a aria-hidden="true" href="#cb12-29" tabindex="-1"></a>find_critical_value <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data, observed_loglik, alpha) {</span>
<span id="cb12-30"><a aria-hidden="true" href="#cb12-30" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">log_likelihood</span>(theta, data) <span class="sc">-</span> observed_loglik) <span class="sc">-</span> <span class="fu">qchisq</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb12-31"><a aria-hidden="true" href="#cb12-31" tabindex="-1"></a>}</span>
<span id="cb12-32"><a aria-hidden="true" href="#cb12-32" tabindex="-1"></a></span>
<span id="cb12-33"><a aria-hidden="true" href="#cb12-33" tabindex="-1"></a><span class="co"># Find the lower and upper bounds of the confidence interval</span></span>
<span id="cb12-34"><a aria-hidden="true" href="#cb12-34" tabindex="-1"></a>lower_bound <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(find_critical_value,</span>
<span id="cb12-35"><a aria-hidden="true" href="#cb12-35" tabindex="-1"></a>  <span class="at">interval =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, theta_hat),</span>
<span id="cb12-36"><a aria-hidden="true" href="#cb12-36" tabindex="-1"></a>  <span class="at">data =</span> sample_data,</span>
<span id="cb12-37"><a aria-hidden="true" href="#cb12-37" tabindex="-1"></a>  <span class="at">observed_loglik =</span> observed_loglik,</span>
<span id="cb12-38"><a aria-hidden="true" href="#cb12-38" tabindex="-1"></a>  <span class="at">alpha =</span> alpha</span>
<span id="cb12-39"><a aria-hidden="true" href="#cb12-39" tabindex="-1"></a>)<span class="sc">$</span>root</span>
<span id="cb12-40"><a aria-hidden="true" href="#cb12-40" tabindex="-1"></a>upper_bound <span class="ot">&lt;-</span> <span class="fu">uniroot</span>(find_critical_value,</span>
<span id="cb12-41"><a aria-hidden="true" href="#cb12-41" tabindex="-1"></a>  <span class="at">interval =</span> <span class="fu">c</span>(theta_hat, <span class="dv">5</span> <span class="sc">*</span> theta_hat),</span>
<span id="cb12-42"><a aria-hidden="true" href="#cb12-42" tabindex="-1"></a>  <span class="at">data =</span> sample_data,</span>
<span id="cb12-43"><a aria-hidden="true" href="#cb12-43" tabindex="-1"></a>  <span class="at">observed_loglik =</span> observed_loglik,</span>
<span id="cb12-44"><a aria-hidden="true" href="#cb12-44" tabindex="-1"></a>  <span class="at">alpha =</span> alpha</span>
<span id="cb12-45"><a aria-hidden="true" href="#cb12-45" tabindex="-1"></a>)<span class="sc">$</span>root</span>
<span id="cb12-46"><a aria-hidden="true" href="#cb12-46" tabindex="-1"></a></span>
<span id="cb12-47"><a aria-hidden="true" href="#cb12-47" tabindex="-1"></a><span class="co"># Create a sequence of theta values for plotting</span></span>
<span id="cb12-48"><a aria-hidden="true" href="#cb12-48" tabindex="-1"></a>theta_values <span class="ot">&lt;-</span> <span class="fu">seq</span>(lower_bound <span class="sc">-</span> <span class="fl">0.5</span>, upper_bound <span class="sc">+</span> <span class="fl">0.5</span>, <span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb12-49"><a aria-hidden="true" href="#cb12-49" tabindex="-1"></a></span>
<span id="cb12-50"><a aria-hidden="true" href="#cb12-50" tabindex="-1"></a><span class="co"># Calculate the log-likelihood for each theta value</span></span>
<span id="cb12-51"><a aria-hidden="true" href="#cb12-51" tabindex="-1"></a>loglik_values <span class="ot">&lt;-</span> <span class="fu">sapply</span>(theta_values, log_likelihood, <span class="at">data =</span> sample_data)</span>
<span id="cb12-52"><a aria-hidden="true" href="#cb12-52" tabindex="-1"></a></span>
<span id="cb12-53"><a aria-hidden="true" href="#cb12-53" tabindex="-1"></a><span class="co"># Create a data frame for visualization</span></span>
<span id="cb12-54"><a aria-hidden="true" href="#cb12-54" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">theta =</span> theta_values, <span class="at">loglik =</span> loglik_values)</span>
<span id="cb12-55"><a aria-hidden="true" href="#cb12-55" tabindex="-1"></a></span>
<span id="cb12-56"><a aria-hidden="true" href="#cb12-56" tabindex="-1"></a><span class="co"># Visualize the log-likelihood function and the confidence interval</span></span>
<span id="cb12-57"><a aria-hidden="true" href="#cb12-57" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> loglik)) <span class="sc">+</span></span>
<span id="cb12-58"><a aria-hidden="true" href="#cb12-58" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb12-59"><a aria-hidden="true" href="#cb12-59" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> lower_bound, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb12-60"><a aria-hidden="true" href="#cb12-60" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> upper_bound, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb12-61"><a aria-hidden="true" href="#cb12-61" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb12-62"><a aria-hidden="true" href="#cb12-62" tabindex="-1"></a>    <span class="at">yintercept =</span> observed_loglik <span class="sc">-</span> <span class="fu">qchisq</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="at">df =</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span>,</span>
<span id="cb12-63"><a aria-hidden="true" href="#cb12-63" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"red"</span>,</span>
<span id="cb12-64"><a aria-hidden="true" href="#cb12-64" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dashed"</span></span>
<span id="cb12-65"><a aria-hidden="true" href="#cb12-65" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-66"><a aria-hidden="true" href="#cb12-66" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-67"><a aria-hidden="true" href="#cb12-67" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Log-Likelihood Function with 95% Confidence Interval"</span>,</span>
<span id="cb12-68"><a aria-hidden="true" href="#cb12-68" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Theta"</span>,</span>
<span id="cb12-69"><a aria-hidden="true" href="#cb12-69" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Log-Likelihood"</span></span>
<span id="cb12-70"><a aria-hidden="true" href="#cb12-70" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-71"><a aria-hidden="true" href="#cb12-71" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap13_files/figure-html/unnamed-chunk-4-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Intuitive Explanation:</strong></p>
<ol type="1">
<li><p><strong>Load Libraries and Set Parameters:</strong> We load the <code>tidyverse</code> and <code>ggplot2</code> libraries. We set the seed and define the true parameter <code>theta</code> for the exponential distribution, the sample size <code>n</code>, and the significance level <code>alpha</code>.</p></li>
<li><p><strong>Generate Sample:</strong> We generate a random sample of size <code>n</code> from an exponential distribution with rate <code>1 / theta</code> using <code>rexp()</code>.</p></li>
<li><p><strong>Calculate MLE:</strong> We calculate the maximum likelihood estimate (MLE) for <code>theta</code>, which is the sample mean <code>theta_hat</code>.</p></li>
<li><p><strong>Define Log-Likelihood Function:</strong> We define the log-likelihood function for the exponential distribution:</p>
<p><span class="math display">\[
l(\theta | X_{1}, \dots, X_{n}) = -n \log \theta - \frac{1}{\theta} \sum_{i = 1}^{n} X_{i}
\]</span></p></li>
<li><p><strong>Calculate Observed Log-Likelihood:</strong> We calculate the value of the log-likelihood function at the MLE <code>theta_hat</code>.</p></li>
<li><p><strong>Define Critical Value Function:</strong> We define a function <code>find_critical_value</code> that computes the difference between twice the log-likelihood ratio and the critical value from the chi-squared distribution with 1 degree of freedom:</p>
<p><span class="math display">\[
-2 \left[ l(\theta | X_{1}, \dots, X_{n}) - l(\hat{\theta} | X_{1}, \dots, X_{n}) \right] - \chi^{2}_{\alpha}(1)
\]</span></p></li>
<li><p><strong>Find Confidence Interval Bounds:</strong> We use the <code>uniroot()</code> function to find the values of <code>theta</code> that make the <code>find_critical_value</code> function equal to zero. These values are the lower and upper bounds of the confidence interval.</p></li>
<li><p><strong>Visualize:</strong> We create a plot of the log-likelihood function using <code>ggplot2</code> and overlay vertical lines for the confidence interval bounds (dotted blue lines) and a horizontal line for the critical log-likelihood value (dashed red line).</p></li>
</ol>
<p><strong>Relationship to Text:</strong></p>
<p>This script illustrates the <strong>likelihood ratio method</strong> for constructing confidence intervals, as discussed in <strong>Section 13.2</strong> and demonstrated in <strong>Example 13.8</strong>. The script shows how to find the confidence interval by inverting the likelihood ratio test and visualizes the log-likelihood function along with the interval.</p>
</section>
<section class="level3" id="r-script-5-simulating-the-coverage-probability-of-confidence-intervals">
<h3 class="anchored" data-anchor-id="r-script-5-simulating-the-coverage-probability-of-confidence-intervals">R Script 5: Simulating the coverage probability of confidence intervals</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a aria-hidden="true" href="#cb13-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb13-2"><a aria-hidden="true" href="#cb13-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb13-3"><a aria-hidden="true" href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a aria-hidden="true" href="#cb13-4" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb13-5"><a aria-hidden="true" href="#cb13-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb13-6"><a aria-hidden="true" href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a aria-hidden="true" href="#cb13-7" tabindex="-1"></a><span class="co"># Define parameters</span></span>
<span id="cb13-8"><a aria-hidden="true" href="#cb13-8" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb13-9"><a aria-hidden="true" href="#cb13-9" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb13-10"><a aria-hidden="true" href="#cb13-10" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb13-11"><a aria-hidden="true" href="#cb13-11" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb13-12"><a aria-hidden="true" href="#cb13-12" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb13-13"><a aria-hidden="true" href="#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a aria-hidden="true" href="#cb13-14" tabindex="-1"></a><span class="co"># Function to generate a confidence interval and check if it contains the true mean</span></span>
<span id="cb13-15"><a aria-hidden="true" href="#cb13-15" tabindex="-1"></a>generate_ci <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, sigma, n, alpha) {</span>
<span id="cb13-16"><a aria-hidden="true" href="#cb13-16" tabindex="-1"></a>  sample_data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma)</span>
<span id="cb13-17"><a aria-hidden="true" href="#cb13-17" tabindex="-1"></a>  sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_data)</span>
<span id="cb13-18"><a aria-hidden="true" href="#cb13-18" tabindex="-1"></a>  z_critical <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb13-19"><a aria-hidden="true" href="#cb13-19" tabindex="-1"></a>  margin_of_error <span class="ot">&lt;-</span> z_critical <span class="sc">*</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb13-20"><a aria-hidden="true" href="#cb13-20" tabindex="-1"></a>  lower_bound <span class="ot">&lt;-</span> sample_mean <span class="sc">-</span> margin_of_error</span>
<span id="cb13-21"><a aria-hidden="true" href="#cb13-21" tabindex="-1"></a>  upper_bound <span class="ot">&lt;-</span> sample_mean <span class="sc">+</span> margin_of_error</span>
<span id="cb13-22"><a aria-hidden="true" href="#cb13-22" tabindex="-1"></a>  contains_mu <span class="ot">&lt;-</span> (mu <span class="sc">&gt;=</span> lower_bound) <span class="sc">&amp;</span> (mu <span class="sc">&lt;=</span> upper_bound)</span>
<span id="cb13-23"><a aria-hidden="true" href="#cb13-23" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">data.frame</span>(lower_bound, upper_bound, contains_mu))</span>
<span id="cb13-24"><a aria-hidden="true" href="#cb13-24" tabindex="-1"></a>}</span>
<span id="cb13-25"><a aria-hidden="true" href="#cb13-25" tabindex="-1"></a></span>
<span id="cb13-26"><a aria-hidden="true" href="#cb13-26" tabindex="-1"></a><span class="co"># Run simulations</span></span>
<span id="cb13-27"><a aria-hidden="true" href="#cb13-27" tabindex="-1"></a>ci_results <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(<span class="dv">1</span><span class="sc">:</span>num_simulations, <span class="sc">~</span><span class="fu">generate_ci</span>(mu, sigma, n, alpha))</span>
<span id="cb13-28"><a aria-hidden="true" href="#cb13-28" tabindex="-1"></a></span>
<span id="cb13-29"><a aria-hidden="true" href="#cb13-29" tabindex="-1"></a><span class="co"># Calculate the coverage probability</span></span>
<span id="cb13-30"><a aria-hidden="true" href="#cb13-30" tabindex="-1"></a>coverage_probability <span class="ot">&lt;-</span> <span class="fu">mean</span>(ci_results<span class="sc">$</span>contains_mu)</span>
<span id="cb13-31"><a aria-hidden="true" href="#cb13-31" tabindex="-1"></a></span>
<span id="cb13-32"><a aria-hidden="true" href="#cb13-32" tabindex="-1"></a><span class="co"># Print the coverage probability</span></span>
<span id="cb13-33"><a aria-hidden="true" href="#cb13-33" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Coverage Probability:"</span>, coverage_probability))</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Coverage Probability: 0.955"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a aria-hidden="true" href="#cb15-1" tabindex="-1"></a><span class="co"># Visualize the confidence intervals</span></span>
<span id="cb15-2"><a aria-hidden="true" href="#cb15-2" tabindex="-1"></a><span class="fu">ggplot</span>(ci_results, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>num_simulations, <span class="at">ymin =</span> lower_bound, <span class="at">ymax =</span> upper_bound, <span class="at">color =</span> contains_mu)) <span class="sc">+</span></span>
<span id="cb15-3"><a aria-hidden="true" href="#cb15-3" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="at">width =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb15-4"><a aria-hidden="true" href="#cb15-4" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> mu, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb15-5"><a aria-hidden="true" href="#cb15-5" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb15-6"><a aria-hidden="true" href="#cb15-6" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb15-7"><a aria-hidden="true" href="#cb15-7" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Simulated Confidence Intervals"</span>,</span>
<span id="cb15-8"><a aria-hidden="true" href="#cb15-8" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Simulation Number"</span>,</span>
<span id="cb15-9"><a aria-hidden="true" href="#cb15-9" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Confidence Interval"</span>,</span>
<span id="cb15-10"><a aria-hidden="true" href="#cb15-10" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Contains True Mean"</span></span>
<span id="cb15-11"><a aria-hidden="true" href="#cb15-11" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-12"><a aria-hidden="true" href="#cb15-12" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb15-13"><a aria-hidden="true" href="#cb15-13" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap13_files/figure-html/unnamed-chunk-5-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Intuitive Explanation:</strong></p>
<ol type="1">
<li><strong>Load Libraries and Set Parameters:</strong> We load the <code>tidyverse</code> library. We set the seed and define the true mean (<code>mu</code>), true standard deviation (<code>sigma</code>), sample size (<code>n</code>), significance level (<code>alpha</code>), and the number of simulations (<code>num_simulations</code>).</li>
<li><strong>Define Confidence Interval Function:</strong> We define a function <code>generate_ci</code> that generates a random sample from a normal distribution, calculates the confidence interval using the formula from <strong>Example 13.2</strong>, and checks if the true mean <code>mu</code> falls within the interval.</li>
<li><strong>Run Simulations:</strong> We use <code>map_dfr</code> to run the simulation <code>num_simulations</code> times, each time generating a new confidence interval and storing the lower bound, upper bound, and whether it contains the true mean.</li>
<li><strong>Calculate Coverage Probability:</strong> We calculate the proportion of confidence intervals that contain the true mean, which is the estimated coverage probability.</li>
<li><strong>Visualize:</strong> We create a plot showing the confidence intervals from each simulation using <code>ggplot2</code>. Intervals that contain the true mean are colored blue, and those that do not are colored red. A horizontal dashed line represents the true mean.</li>
</ol>
<p><strong>Relationship to Text:</strong></p>
<p>This script demonstrates the concept of <strong>coverage probability</strong>, which is defined in <strong>Section 13.1</strong> of the text. The simulation shows that the actual coverage probability of the confidence intervals is close to the nominal level (1 - <code>alpha</code>). The visualization helps to understand how confidence intervals vary from sample to sample and how often they contain the true parameter value.</p>
</section>
</section>
<section class="level2" id="youtube-videos">
<h2 class="anchored" data-anchor-id="youtube-videos">YouTube Videos</h2>
<p>Here are some suggested YouTube videos that explain the concepts mentioned in the attached text, along with explanations of how they relate to the text:</p>
<section class="level3" id="confidence-intervals-basics-and-intuition">
<h3 class="anchored" data-anchor-id="confidence-intervals-basics-and-intuition">Confidence Intervals: Basics and Intuition</h3>
<section class="level4" id="video-1-confidence-intervals---introduction-jbstatistics">
<h4 class="anchored" data-anchor-id="video-1-confidence-intervals---introduction-jbstatistics">Video 1: Confidence Intervals - Introduction | jbstatistics</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=yDEvXB6ApWc">https://www.youtube.com/watch?v=yDEvXB6ApWc</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video provides a solid introduction to the concept of <strong>confidence intervals</strong>. It explains what they are, why they are useful, and how to interpret them. The video starts with a motivating example and gradually introduces the formal definition. It does a good job at explaining the difference between a <strong>point estimate</strong> and an <strong>interval estimate</strong>.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video is directly related to <strong>Section 13.1</strong> of the text, which introduces the definition of confidence sets. It covers the basic idea of a confidence set as a way to quantify the uncertainty associated with an estimator, which is exactly what this video is explaining. The video also aligns with the text’s emphasis on the fact that a confidence interval is a <strong>random set</strong> that varies from sample to sample, and it explains the concept of <strong>coverage probability</strong> in an intuitive way.</p>
</section>
<section class="level4" id="video-2-confidence-intervals---an-introduction-to-the-interpretation-of-confidence-intervals-dr-nics-maths-and-stats">
<h4 class="anchored" data-anchor-id="video-2-confidence-intervals---an-introduction-to-the-interpretation-of-confidence-intervals-dr-nics-maths-and-stats">Video 2: Confidence Intervals - (An introduction to the interpretation of confidence intervals) | Dr Nic’s Maths and Stats</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=8oVwIJXhOk4">https://www.youtube.com/watch?v=8oVwIJXhOk4</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video focuses on the interpretation of confidence intervals. It emphasizes that a 95% confidence interval does not mean there is a 95% probability that the true parameter lies within the interval. Instead, it explains that if we were to repeat the sampling process many times, 95% of the constructed intervals would contain the true parameter.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video addresses the common misconception about the interpretation of confidence intervals, which is also touched upon in <strong>Section 13.1</strong>. The text states that <span class="math inline">\(C_{\alpha}(X^{n})\)</span> is a random set designed to vary from sample to sample to achieve the stated coverage, and this video reinforces this concept by illustrating how different samples lead to different confidence intervals and how the coverage probability relates to the long-run frequency of intervals containing the true parameter.</p>
</section>
</section>
<section class="level3" id="confidence-intervals-for-specific-distributions">
<h3 class="anchored" data-anchor-id="confidence-intervals-for-specific-distributions">Confidence Intervals for Specific Distributions</h3>
<section class="level4" id="video-3-confidence-interval-for-the-mean-known-population-standard-deviation-jbstatistics">
<h4 class="anchored" data-anchor-id="video-3-confidence-interval-for-the-mean-known-population-standard-deviation-jbstatistics">Video 3: Confidence Interval for the Mean (known population standard deviation) | jbstatistics</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=kgDDeSVjD70">https://www.youtube.com/watch?v=kgDDeSVjD70</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video provides a step-by-step guide on how to construct a confidence interval for the mean of a normal distribution when the population standard deviation is known. It explains the formula and demonstrates how to calculate the interval using a practical example.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video is directly related to <strong>Example 13.2</strong> in the text, which discusses the construction of a confidence interval for <span class="math inline">\(\mu\)</span> when <span class="math inline">\(X \sim N(\mu, \sigma^{2})\)</span> with <span class="math inline">\(\sigma^{2}\)</span> known. The video explains the same formula used in the example:</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left[ \bar{X} - \frac{\sigma z_{\alpha/2}}{\sqrt{n}}, \bar{X} + \frac{\sigma z_{\alpha/2}}{\sqrt{n}} \right] = \bar{X} \pm \frac{\sigma z_{\alpha/2}}{\sqrt{n}}.
\]</span></p>
<p>The video also provides a clear explanation of how to find the critical value <span class="math inline">\(z_{\alpha/2}\)</span> and how to apply the formula to a real-world example.</p>
</section>
<section class="level4" id="video-4-confidence-interval-for-the-population-mean-sigma-unknown-dane-mcguckian">
<h4 class="anchored" data-anchor-id="video-4-confidence-interval-for-the-population-mean-sigma-unknown-dane-mcguckian">Video 4: Confidence interval for the population mean (sigma unknown) | Dane McGuckian</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=s_dTXR3qi5Q">https://www.youtube.com/watch?v=s_dTXR3qi5Q</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video explains how to construct a confidence interval for the mean when the population standard deviation is unknown. It introduces the <span class="math inline">\(t\)</span>-distribution and explains how to use it to construct the interval.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video corresponds to <strong>Example 13.3</strong> in the text, where a confidence interval for <span class="math inline">\(\mu\)</span> is constructed when <span class="math inline">\(X \sim N(\mu, \sigma^{2})\)</span> with <span class="math inline">\(\sigma^{2}\)</span> unknown. The video explains the use of the <span class="math inline">\(t\)</span>-distribution and the formula:</p>
<p><span class="math display">\[
C_{\alpha}(X^{n}) = \left[ \bar{X} - \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}}, \bar{X} + \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}} \right] = \bar{X} \pm \frac{s_{*} t_{\alpha/2}(n - 1)}{\sqrt{n}},
\]</span></p>
<p>which is the same as the one presented in the text. The video provides a clear explanation of how to find the critical value <span class="math inline">\(t_{\alpha/2}(n - 1)\)</span> and how to apply the formula.</p>
</section>
<section class="level4" id="video-5-confidence-interval-for-a-proportion---using-the-central-limit-theorem-jbstatistics">
<h4 class="anchored" data-anchor-id="video-5-confidence-interval-for-a-proportion---using-the-central-limit-theorem-jbstatistics">Video 5: Confidence Interval for a proportion - using the Central Limit Theorem | jbstatistics</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=8GSuBka5TWg">https://www.youtube.com/watch?v=8GSuBka5TWg</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video explains how to construct a confidence interval for a population proportion using the Central Limit Theorem (CLT). It explains the conditions under which the CLT can be applied and demonstrates how to calculate the interval.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video relates to <strong>Example 13.11</strong> in the text, which discusses the construction of a large sample confidence interval for a proportion <span class="math inline">\(p\)</span>. The video explains the use of the normal approximation to the binomial distribution and the formula:</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2} \frac{\sqrt{\hat{p}(1 - \hat{p})}}{\sqrt{n}},
\]</span></p>
<p>which is consistent with the formula presented in the text.</p>
</section>
</section>
<section class="level3" id="likelihood-ratio-confidence-intervals">
<h3 class="anchored" data-anchor-id="likelihood-ratio-confidence-intervals">Likelihood Ratio Confidence Intervals</h3>
<section class="level4" id="video-6-confidence-intervals-mle-method-ritvikmath">
<h4 class="anchored" data-anchor-id="video-6-confidence-intervals-mle-method-ritvikmath">Video 6: Confidence Intervals: MLE method | ritvikmath</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=5NMkGABS4kY">https://www.youtube.com/watch?v=5NMkGABS4kY</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video provides an introduction to the concept of constructing confidence intervals using the maximum likelihood estimation (MLE) method. While it doesn’t explicitly focus on likelihood ratio tests, it lays the foundation by explaining how MLEs can be used for interval estimation.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video provides background information relevant to <strong>Section 13.2</strong>, which discusses <strong>likelihood ratio confidence intervals</strong>. The video explains how MLEs are obtained and how they can be used to construct confidence intervals, which is a key concept underlying the likelihood ratio method. Although the video does not derive the likelihood ratio statistic, it provides a good starting point for understanding the role of MLEs in interval estimation.</p>
</section>
<section class="level4" id="video-7-introduction-to-likelihood-ratio-tests-365-data-science">
<h4 class="anchored" data-anchor-id="video-7-introduction-to-likelihood-ratio-tests-365-data-science">Video 7: Introduction to Likelihood Ratio Tests | 365 Data Science</h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=60z7cC5rQ4c">https://www.youtube.com/watch?v=60z7cC5rQ4c</a></li>
</ul>
<p><strong>Explanation:</strong></p>
<p>This video gives a general introduction to <strong>likelihood ratio tests</strong>. While it doesn’t explicitly cover confidence intervals, it explains the concept of the likelihood ratio statistic and how it’s used for hypothesis testing.</p>
<p><strong>Relationship to Text:</strong></p>
<p>This video is relevant to <strong>Section 13.2</strong>, which introduces the likelihood ratio statistic:</p>
<p><span class="math display">\[
\lambda(X^{n}; \theta_{0}) = \frac{\max_{\theta \in \Theta} L(\theta | X^{n})}{L(\theta_{0} | X^{n})}.
\]</span></p>
<p>The video explains how this statistic is constructed and how it can be used to compare the likelihood of the data under different hypotheses. Understanding likelihood ratio tests is crucial for understanding how likelihood ratio confidence intervals are constructed.</p>
<p>These videos provide a good starting point for understanding the concepts of confidence intervals discussed in the attached text. They cover various aspects, including basic definitions, construction methods for different distributions, and the likelihood ratio approach.</p>
</section>
</section>
</section>
<section class="level2" id="multiple-choice-exercises">
<h2 class="anchored" data-anchor-id="multiple-choice-exercises">Multiple Choice Exercises</h2>
<section class="level3" id="sec-ch13mcexercise1">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise1">MC Exercise 1</h3>
<p><a href="#sec-ch13mcsolution1">MC Solution 1</a></p>
<p>A 95% confidence interval for the mean <span class="math inline">\(\mu\)</span> of a normal population with known variance is given by (5, 8). What is the sample mean <span class="math inline">\(\bar{X}\)</span>?</p>
<ol type="a">
<li>5.5<br/>
</li>
<li>6.0<br/>
</li>
<li>6.5<br/>
</li>
<li>7.0</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise2">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise2">MC Exercise 2</h3>
<p><a href="#sec-ch13mcsolution2">MC Solution 2</a></p>
<p>Which of the following statements is <strong>TRUE</strong> about a confidence interval?</p>
<ol type="a">
<li>The probability that the true parameter lies within the confidence interval is equal to the confidence level.<br/>
</li>
<li>A 99% confidence interval is always wider than a 95% confidence interval for the same parameter and data.<br/>
</li>
<li>The confidence interval is a fixed interval that contains the true parameter with a certain probability.<br/>
</li>
<li>Increasing the sample size will always result in a wider confidence interval.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise3">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise3">MC Exercise 3</h3>
<p><a href="#sec-ch13mcsolution3">MC Solution 3</a></p>
<p>A random sample of size <span class="math inline">\(n = 100\)</span> is taken from a population with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2 = 25\)</span>. The sample mean is <span class="math inline">\(\bar{X} = 20\)</span>. What is the approximate 95% confidence interval for <span class="math inline">\(\mu\)</span>?</p>
<ol type="a">
<li>(19.02, 20.98)<br/>
</li>
<li>(19.51, 20.49)<br/>
</li>
<li>(19.68, 20.32)<br/>
</li>
<li>(19.36, 20.64)</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise4">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise4">MC Exercise 4</h3>
<p><a href="#sec-ch13mcsolution4">MC Solution 4</a></p>
<p>A random sample of size <span class="math inline">\(n = 16\)</span> is taken from a normal population with unknown mean <span class="math inline">\(\mu\)</span> and unknown variance <span class="math inline">\(\sigma^2\)</span>. The sample variance is <span class="math inline">\(s^2 = 9\)</span>. What is the critical value <span class="math inline">\(t_{\alpha/2}\)</span> used to construct a 99% confidence interval for <span class="math inline">\(\mu\)</span>?</p>
<ol type="a">
<li>2.947<br/>
</li>
<li>2.602<br/>
</li>
<li>2.921<br/>
</li>
<li>2.583</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise5">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise5">MC Exercise 5</h3>
<p><a href="#sec-ch13mcsolution5">MC Solution 5</a></p>
<p>In the context of confidence intervals, what does the term “<strong>coverage probability</strong>” refer to?</p>
<ol type="a">
<li>The probability that the sample mean falls within the confidence interval.<br/>
</li>
<li>The probability that the true parameter falls within a specific realized confidence interval.<br/>
</li>
<li>The long-run proportion of confidence intervals that contain the true parameter.<br/>
</li>
<li>The probability that the null hypothesis is rejected when it is true.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise6">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise6">MC Exercise 6</h3>
<p><a href="#sec-ch13mcsolution6">MC Solution 6</a></p>
<p>A 90% confidence interval for a population proportion <span class="math inline">\(p\)</span> is calculated to be (0.55, 0.65). What is the margin of error?</p>
<ol type="a">
<li>0.025<br/>
</li>
<li>0.05<br/>
</li>
<li>0.10<br/>
</li>
<li>0.55</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise7">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise7">MC Exercise 7</h3>
<p><a href="#sec-ch13mcsolution7">MC Solution 7</a></p>
<p>Which of the following is <strong>NOT</strong> an assumption required for constructing a confidence interval for the mean of a normal population with known variance?</p>
<ol type="a">
<li>The population is normally distributed.<br/>
</li>
<li>The sample is randomly selected.<br/>
</li>
<li>The population variance is known.<br/>
</li>
<li>The sample size is greater than 30.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise8">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise8">MC Exercise 8</h3>
<p><a href="#sec-ch13mcsolution8">MC Solution 8</a></p>
<p>The <strong>likelihood ratio statistic</strong> for testing a simple null hypothesis <span class="math inline">\(H_0: \theta = \theta_0\)</span> is given by <span class="math inline">\(\lambda(X^n; \theta_0)\)</span>. What is the general form of a <strong>likelihood ratio confidence interval</strong>?</p>
<ol type="a">
<li><span class="math inline">\(\{\theta_0: \lambda(X^n; \theta_0) \geq c_\alpha\}\)</span><br/>
</li>
<li><span class="math inline">\(\{\theta_0: \lambda(X^n; \theta_0) \leq c_\alpha\}\)</span><br/>
</li>
<li><span class="math inline">\(\{\theta_0: \lambda(X^n; \theta_0) = c_\alpha\}\)</span><br/>
</li>
<li><span class="math inline">\(\{\theta_0: \lambda(X^n; \theta_0) &gt; c_\alpha\}\)</span></li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise9">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise9">MC Exercise 9</h3>
<p><a href="#sec-ch13mcsolution9">MC Solution 9</a></p>
<p>A random sample of size <span class="math inline">\(n = 25\)</span> is taken from a normal population with unknown mean <span class="math inline">\(\mu\)</span> and unknown variance. The sample mean is <span class="math inline">\(\bar{X} = 12\)</span> and the sample standard deviation is <span class="math inline">\(s = 4\)</span>. What is the 95% confidence interval for <span class="math inline">\(\mu\)</span>?</p>
<ol type="a">
<li>(10.344, 13.656)<br/>
</li>
<li>(10.432, 13.568)<br/>
</li>
<li>(11.208, 12.792)<br/>
</li>
<li>(10.304, 13.696)</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise10">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise10">MC Exercise 10</h3>
<p><a href="#sec-ch13mcsolution10">MC Solution 10</a></p>
<p>What is the relationship between the <strong>acceptance region</strong> of a hypothesis test and a <strong>confidence interval</strong>?</p>
<ol type="a">
<li>They are unrelated concepts.<br/>
</li>
<li>The acceptance region is the complement of the confidence interval.<br/>
</li>
<li>The confidence interval is the set of non-rejectable null hypotheses.<br/>
</li>
<li>The acceptance region is always wider than the confidence interval.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise11">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise11">MC Exercise 11</h3>
<p><a href="#sec-ch13mcsolution11">MC Solution 11</a></p>
<p>A sample of 49 observations is taken from a population with a known standard deviation of 14. The sample mean is 60. What is the length of a 99% confidence interval for the population mean?</p>
<ol type="a">
<li>2.576<br/>
</li>
<li>5.152<br/>
</li>
<li>7.000<br/>
</li>
<li>10.304</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise12">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise12">MC Exercise 12</h3>
<p><a href="#sec-ch13mcsolution12">MC Solution 12</a></p>
<p>For a normally distributed population with unknown variance, which distribution is used to construct a confidence interval for the population mean?</p>
<ol type="a">
<li>Normal distribution<br/>
</li>
<li>t-distribution<br/>
</li>
<li>Chi-squared distribution<br/>
</li>
<li>F-distribution</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise13">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise13">MC Exercise 13</h3>
<p><a href="#sec-ch13mcsolution13">MC Solution 13</a></p>
<p>Which of the following statements is true regarding the <strong>expected length</strong> of a confidence interval?</p>
<ol type="a">
<li>It is always equal to the actual length of the confidence interval.<br/>
</li>
<li>It is a measure of the precision of the confidence interval.<br/>
</li>
<li>It is minimized when the confidence level is increased.<br/>
</li>
<li>It is independent of the sample size.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise14">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise14">MC Exercise 14</h3>
<p><a href="#sec-ch13mcsolution14">MC Solution 14</a></p>
<p>A 95% confidence interval for the population mean is calculated to be (10, 15). If the confidence level is changed to 90%, what will happen to the width of the confidence interval?</p>
<ol type="a">
<li>It will increase.<br/>
</li>
<li>It will decrease.<br/>
</li>
<li>It will remain the same.<br/>
</li>
<li>The change cannot be determined without more information.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise15">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise15">MC Exercise 15</h3>
<p><a href="#sec-ch13mcsolution15">MC Solution 15</a></p>
<p>What is the <strong>pivotal quantity</strong> used to construct a confidence interval for the variance <span class="math inline">\(\sigma^2\)</span> of a normal population?</p>
<ol type="a">
<li><span class="math inline">\(\frac{(n-1)s^2}{\sigma^2}\)</span><br/>
</li>
<li><span class="math inline">\(\frac{\bar{X} - \mu}{s/\sqrt{n}}\)</span><br/>
</li>
<li><span class="math inline">\(\frac{\hat{p}(1-\hat{p})}{n}\)</span><br/>
</li>
<li><span class="math inline">\(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\)</span></li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise16">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise16">MC Exercise 16</h3>
<p><a href="#sec-ch13mcsolution16">MC Solution 16</a></p>
<p>A <strong>uniformly most accurate</strong> (UMA) confidence interval minimizes which of the following?</p>
<ol type="a">
<li>The expected length of the interval<br/>
</li>
<li>The probability of <strong>false coverage</strong><br/>
</li>
<li>The width of the interval<br/>
</li>
<li>The variance of the estimator</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise17">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise17">MC Exercise 17</h3>
<p><a href="#sec-ch13mcsolution17">MC Solution 17</a></p>
<p>Which of the following is an advantage of using the <strong>likelihood ratio method</strong> for constructing confidence intervals?</p>
<ol type="a">
<li>It always produces the shortest possible confidence interval.<br/>
</li>
<li>It is applicable even when the distribution of the data is unknown.<br/>
</li>
<li>It is based on the asymptotic distribution of the likelihood ratio statistic.<br/>
</li>
<li>It does not require the calculation of maximum likelihood estimates.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise18">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise18">MC Exercise 18</h3>
<p><a href="#sec-ch13mcsolution18">MC Solution 18</a></p>
<p>A sample proportion <span class="math inline">\(\hat{p} = 0.7\)</span> is obtained from a sample of size <span class="math inline">\(n = 100\)</span>. What is the approximate standard error of <span class="math inline">\(\hat{p}\)</span>?</p>
<ol type="a">
<li>0.0458<br/>
</li>
<li>0.0021<br/>
</li>
<li>0.2100<br/>
</li>
<li>0.0004</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise19">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise19">MC Exercise 19</h3>
<p><a href="#sec-ch13mcsolution19">MC Solution 19</a></p>
<p>What is the effect of increasing the sample size on the width of a confidence interval, assuming all other factors remain constant?</p>
<ol type="a">
<li>The width increases.<br/>
</li>
<li>The width decreases.<br/>
</li>
<li>The width remains the same.<br/>
</li>
<li>The effect cannot be determined without more information.</li>
</ol>
</section>
<section class="level3" id="sec-ch13mcexercise20">
<h3 class="anchored" data-anchor-id="sec-ch13mcexercise20">MC Exercise 20</h3>
<p><a href="#sec-ch13mcsolution20">MC Solution 20</a></p>
<p>A 95% confidence interval for a population mean is reported as (12, 18). If the sample size was <span class="math inline">\(n=25\)</span> and the population standard deviation was known, what is the value of the population standard deviation?</p>
<ol type="a">
<li>7.5<br/>
</li>
<li>3.82<br/>
</li>
<li>5.1<br/>
</li>
<li>Cannot be determined from given information</li>
</ol>
</section>
</section>
<section class="level2" id="solutions-1">
<h2 class="anchored" data-anchor-id="solutions-1">Solutions</h2>
<section class="level3" id="sec-ch13mcsolution1">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution1">MC Solution 1</h3>
<p><a href="#sec-ch13mcexercise1">MC Exercise 1</a></p>
<p>The sample mean <span class="math inline">\(\bar{X}\)</span> is the midpoint of the confidence interval. Therefore,</p>
<p><span class="math display">\[
\bar{X} = \frac{5 + 8}{2} = 6.5.
\]</span></p>
<p>The correct answer is <strong>c) 6.5</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A confidence interval for the mean is centered around the sample mean <span class="math inline">\(\bar{X}\)</span>. The interval is constructed by adding and subtracting a margin of error from <span class="math inline">\(\bar{X}\)</span>. Therefore, <span class="math inline">\(\bar{X}\)</span> is always located exactly in the middle of the interval. This is consistent with the formulas used in <strong>Examples 13.2 and 13.3</strong>.</p>
</section>
<section class="level3" id="sec-ch13mcsolution2">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution2">MC Solution 2</h3>
<p><a href="#sec-ch13mcexercise2">MC Exercise 2</a></p>
<ol type="a">
<li>Incorrect. The confidence level refers to the long-run proportion of intervals that contain the true parameter, not the probability that the true parameter lies within a specific interval.<br/>
</li>
<li>Correct. A 99% confidence interval is wider than a 95% confidence interval because it requires a larger margin of error to achieve a higher level of confidence.<br/>
</li>
<li>Incorrect. The confidence interval is random, as it depends on the sample data. The true parameter is a fixed value.<br/>
</li>
<li>Incorrect. Increasing the sample size will generally result in a narrower confidence interval.</li>
</ol>
<p>The correct answer is <strong>b) A 99% confidence interval is always wider than a 95% confidence interval for the same parameter and data.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A higher confidence level requires a wider interval to be more certain that the interval contains the true parameter. The confidence level (e.g., 95%, 99%) is related to the long-run <strong>coverage probability</strong> of the intervals, as discussed in <strong>Section 13.1</strong>. A larger sample size provides more information about the population, leading to a smaller margin of error and a narrower interval.</p>
</section>
<section class="level3" id="sec-ch13mcsolution3">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution3">MC Solution 3</h3>
<p><a href="#sec-ch13mcexercise3">MC Exercise 3</a></p>
<p>The formula for an approximate 95% confidence interval for <span class="math inline">\(\mu\)</span> when <span class="math inline">\(\sigma\)</span> is known is</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}}.
\]</span></p>
<p>With <span class="math inline">\(n = 100\)</span>, <span class="math inline">\(\sigma^2 = 25\)</span> (so <span class="math inline">\(\sigma = 5\)</span>), <span class="math inline">\(\bar{X} = 20\)</span>, and <span class="math inline">\(z_{\alpha/2} = z_{0.025} = 1.96\)</span>, the confidence interval is</p>
<p><span class="math display">\[
20 \pm 1.96 \frac{5}{\sqrt{100}} = 20 \pm 0.98.
\]</span></p>
<p>The interval is (19.02, 20.98).</p>
<p>The correct answer is <strong>a) (19.02, 20.98)</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>This problem applies the formula for a confidence interval for the mean when the population variance is known, as discussed in <strong>Example 13.2</strong>. We plug in the given values for the sample size, sample mean, population standard deviation, and the critical value from the standard normal distribution to calculate the interval.</p>
</section>
<section class="level3" id="sec-ch13mcsolution4">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution4">MC Solution 4</h3>
<p><a href="#sec-ch13mcexercise4">MC Exercise 4</a></p>
<p>For a 99% confidence interval with <span class="math inline">\(n = 16\)</span>, the degrees of freedom are <span class="math inline">\(n - 1 = 15\)</span>. We need to find <span class="math inline">\(t_{\alpha/2}\)</span> where <span class="math inline">\(\alpha = 0.01\)</span>, so we look for <span class="math inline">\(t_{0.005}(15)\)</span>. Using a <span class="math inline">\(t\)</span>-table or calculator, we find that <span class="math inline">\(t_{0.005}(15) = 2.947\)</span>.</p>
<p>The correct answer is <strong>a) 2.947</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>When the population variance is unknown, we use the <span class="math inline">\(t\)</span>-distribution to construct the confidence interval, as discussed in <strong>Example 13.3</strong>. The degrees of freedom are <span class="math inline">\(n - 1\)</span>, and we need to find the critical value from the <span class="math inline">\(t\)</span>-distribution that corresponds to the desired confidence level and degrees of freedom.</p>
</section>
<section class="level3" id="sec-ch13mcsolution5">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution5">MC Solution 5</h3>
<p><a href="#sec-ch13mcexercise5">MC Exercise 5</a></p>
<ol type="a">
<li>Incorrect. This describes the sampling distribution of the sample mean.<br/>
</li>
<li>Incorrect. Once an interval is calculated, the true parameter either lies within it or not; there is no probability involved.<br/>
</li>
<li>Correct. The coverage probability is the long-run proportion of confidence intervals that contain the true parameter value.<br/>
</li>
<li>Incorrect. This describes the significance level of a hypothesis test.</li>
</ol>
<p>The correct answer is <strong>c) The long-run proportion of confidence intervals that contain the true parameter.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Coverage probability</strong> is a key concept in the definition of confidence intervals, as explained in <strong>Section 13.1</strong>. It refers to the performance of the confidence interval procedure over many repeated samples. If we construct many confidence intervals using the same method, the coverage probability tells us the proportion of those intervals that will contain the true parameter value.</p>
</section>
<section class="level3" id="sec-ch13mcsolution6">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution6">MC Solution 6</h3>
<p><a href="#sec-ch13mcexercise6">MC Exercise 6</a></p>
<p>The margin of error is half the width of the confidence interval. The width is <span class="math inline">\(0.65 - 0.55 = 0.10\)</span>, so the margin of error is <span class="math inline">\(0.10 / 2 = 0.05\)</span>.</p>
<p>The correct answer is <strong>b) 0.05</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The confidence interval for a proportion is constructed by taking the sample proportion <span class="math inline">\(\hat{p}\)</span> and adding and subtracting the margin of error. The margin of error is the product of the critical value and the standard error of the sample proportion, as discussed in <strong>Example 13.11</strong>.</p>
</section>
<section class="level3" id="sec-ch13mcsolution7">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution7">MC Solution 7</h3>
<p><a href="#sec-ch13mcexercise7">MC Exercise 7</a></p>
<ol type="a">
<li>Correct. The assumption of normality is required for the sampling distribution of the sample mean to be normal.<br/>
</li>
<li>Correct. Random sampling ensures that the sample is representative of the population.<br/>
</li>
<li>Correct. This is a key assumption for this specific type of confidence interval.<br/>
</li>
<li>Incorrect. While a large sample size allows for the use of the Central Limit Theorem, it is not a strict requirement when the population variance is known, and the population is normally distributed.</li>
</ol>
<p>The correct answer is <strong>d) The sample size is greater than 30.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The construction of a confidence interval for the mean with known variance relies on the assumption that the sampling distribution of the sample mean is normal. This is guaranteed when the population is normally distributed, regardless of the sample size. The Central Limit Theorem is invoked when the population distribution is unknown, and the sample size is large.</p>
</section>
<section class="level3" id="sec-ch13mcsolution8">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution8">MC Solution 8</h3>
<p><a href="#sec-ch13mcexercise8">MC Exercise 8</a></p>
<p>The likelihood ratio confidence interval is the set of all <span class="math inline">\(\theta_0\)</span> values that are not rejected by the likelihood ratio test. This corresponds to the set of <span class="math inline">\(\theta_0\)</span> values for which the likelihood ratio statistic is greater than or equal to a critical value.</p>
<p>The correct answer is <strong>a) <span class="math inline">\(\{\theta_0: \lambda(X^n; \theta_0) \geq c_\alpha\}\)</span></strong> The text in section 13.2 has a typo, and it should be “<span class="math inline">\(\geq\)</span>” instead of “<span class="math inline">\(\leq\)</span>”.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Section 13.2</strong> defines the likelihood ratio confidence interval as the set of non-rejectable null hypotheses. In other words, it’s the set of parameter values <span class="math inline">\(\theta_0\)</span> for which the likelihood ratio test does not reject the null hypothesis <span class="math inline">\(H_0: \theta = \theta_0\)</span>. This corresponds to the values of <span class="math inline">\(\theta_0\)</span> where the likelihood ratio statistic is sufficiently large, indicating that the observed data are reasonably likely under the null hypothesis.</p>
</section>
<section class="level3" id="sec-ch13mcsolution9">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution9">MC Solution 9</h3>
<p><a href="#sec-ch13mcexercise9">MC Exercise 9</a></p>
<p>The formula for a 95% confidence interval for <span class="math inline">\(\mu\)</span> when <span class="math inline">\(\sigma\)</span> is unknown is</p>
<p><span class="math display">\[
\bar{X} \pm t_{\alpha/2} \frac{s}{\sqrt{n}}.
\]</span></p>
<p>With <span class="math inline">\(n = 25\)</span>, <span class="math inline">\(\bar{X} = 12\)</span>, <span class="math inline">\(s = 4\)</span>, and <span class="math inline">\(t_{\alpha/2} = t_{0.025}(24) = 2.064\)</span>, the confidence interval is</p>
<p><span class="math display">\[
12 \pm 2.064 \frac{4}{\sqrt{25}} = 12 \pm 1.6512.
\]</span></p>
<p>The interval is (10.3488, 13.6512). The closest value is (10.344, 13.656).</p>
<p>The correct answer is <strong>a) (10.344, 13.656)</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>This problem applies the formula for a confidence interval for the mean when the population variance is unknown, as discussed in <strong>Example 13.3</strong>. We plug in the given values for the sample size, sample mean, sample standard deviation, and the critical value from the <span class="math inline">\(t\)</span>-distribution to calculate the interval.</p>
</section>
<section class="level3" id="sec-ch13mcsolution10">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution10">MC Solution 10</h3>
<p><a href="#sec-ch13mcexercise10">MC Exercise 10</a></p>
<ol type="a">
<li>Incorrect. They are closely related concepts in statistical inference.<br/>
</li>
<li>Incorrect. The complement of the acceptance region is the rejection region.<br/>
</li>
<li>Correct. The confidence interval can be interpreted as the set of all parameter values that would not be rejected by a hypothesis test at the corresponding significance level.<br/>
</li>
<li>Incorrect. There is no fixed relationship between the width of the acceptance region and the confidence interval.</li>
</ol>
<p>The correct answer is <strong>c) The confidence interval is the set of non-rejectable null hypotheses.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Section 13.1</strong> states that “The confidence interval is basically the set of non-rejectable null hypotheses about <span class="math inline">\(\theta\)</span>.” This means that if we were to perform a hypothesis test for each possible value of the parameter, the confidence interval would contain all the values for which we would fail to reject the null hypothesis.</p>
</section>
<section class="level3" id="sec-ch13mcsolution11">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution11">MC Solution 11</h3>
<p><a href="#sec-ch13mcexercise11">MC Exercise 11</a></p>
<p>The length of a 99% confidence interval for the population mean with known standard deviation is given by:</p>
<p><span class="math display">\[
2 * z_{\alpha/2} * \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>Here, <span class="math inline">\(z_{\alpha/2} = z_{0.005} = 2.576\)</span>, <span class="math inline">\(\sigma = 14\)</span>, and <span class="math inline">\(n = 49\)</span>. Therefore, the length is:</p>
<p><span class="math display">\[
2 * 2.576 * \frac{14}{\sqrt{49}} = 2 * 2.576 * 2 = 10.304
\]</span></p>
<p>The correct answer is <strong>d) 10.304</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The length of a confidence interval is twice the margin of error. In this case, we use the formula for the margin of error when the population standard deviation is known, which involves the critical value from the standard normal distribution, the population standard deviation, and the sample size. This is consistent with the formula in <strong>Example 13.2</strong>.</p>
</section>
<section class="level3" id="sec-ch13mcsolution12">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution12">MC Solution 12</h3>
<p><a href="#sec-ch13mcexercise12">MC Exercise 12</a></p>
<ol type="a">
<li>Incorrect. The normal distribution is used when the population variance is known.<br/>
</li>
<li>Correct. The t-distribution is used when the population variance is unknown and estimated by the sample variance.<br/>
</li>
<li>Incorrect. The chi-squared distribution is used for constructing confidence intervals for the variance.<br/>
</li>
<li>Incorrect. The F-distribution is used for comparing variances of two populations.</li>
</ol>
<p>The correct answer is <strong>b) t-distribution</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>As explained in <strong>Example 13.3</strong>, when the population variance is unknown, we use the <span class="math inline">\(t\)</span>-distribution to construct the confidence interval for the mean. The <span class="math inline">\(t\)</span>-distribution accounts for the extra uncertainty introduced by estimating the population variance from the sample.</p>
</section>
<section class="level3" id="sec-ch13mcsolution13">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution13">MC Solution 13</h3>
<p><a href="#sec-ch13mcexercise13">MC Exercise 13</a></p>
<ol type="a">
<li>Incorrect. The expected length is a theoretical value, while the actual length varies from sample to sample.<br/>
</li>
<li>Correct. The expected length is a measure of the average width of the confidence intervals, which reflects the precision of the estimation.<br/>
</li>
<li>Incorrect. Increasing the confidence level increases the expected length.<br/>
</li>
<li>Incorrect. The expected length decreases as the sample size increases.</li>
</ol>
<p>The correct answer is <strong>b) It is a measure of the precision of the confidence interval.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Section 13.3</strong> discusses the concept of expected length as a way to evaluate the performance of a confidence interval. A smaller expected length indicates a more precise interval, meaning that the interval is, on average, narrower and provides a more specific estimate of the true parameter value.</p>
</section>
<section class="level3" id="sec-ch13mcsolution14">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution14">MC Solution 14</h3>
<p><a href="#sec-ch13mcexercise14">MC Exercise 14</a></p>
<ol type="a">
<li>Incorrect. Decreasing the confidence level requires a smaller critical value.<br/>
</li>
<li>Correct. A 90% confidence interval will be narrower than a 95% confidence interval because a smaller critical value is used.<br/>
</li>
<li>Incorrect. The confidence level directly affects the width of the interval.<br/>
</li>
<li>Incorrect. The change can be determined based on the relationship between confidence level and interval width.</li>
</ol>
<p>The correct answer is <strong>b) It will decrease.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A lower confidence level means we are willing to accept a lower probability that the interval contains the true parameter. This allows us to use a smaller critical value, which results in a smaller margin of error and a narrower confidence interval.</p>
</section>
<section class="level3" id="sec-ch13mcsolution15">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution15">MC Solution 15</h3>
<p><a href="#sec-ch13mcexercise15">MC Exercise 15</a></p>
<ol type="a">
<li>Correct. This is the pivotal quantity used for constructing confidence intervals for the variance, and it follows a chi-squared distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.<br/>
</li>
<li>Incorrect. This is the pivotal quantity used for constructing confidence intervals for the mean when the variance is unknown.<br/>
</li>
<li>Incorrect. This is related to the standard error of the sample proportion.<br/>
</li>
<li>Incorrect. This is the pivotal quantity used for constructing confidence intervals for the mean when the variance is known.</li>
</ol>
<p>The correct answer is <strong>a) <span class="math inline">\(\frac{(n-1)s^2}{\sigma^2}\)</span></strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Example 13.5</strong> shows that the quantity <span class="math inline">\(\frac{(n-1)s^2}{\sigma^2}\)</span> follows a chi-squared distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. This quantity is pivotal because its distribution does not depend on any unknown parameters. We can use this fact to construct a confidence interval for <span class="math inline">\(\sigma^2\)</span>.</p>
</section>
<section class="level3" id="sec-ch13mcsolution16">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution16">MC Solution 16</h3>
<p><a href="#sec-ch13mcexercise16">MC Exercise 16</a></p>
<ol type="a">
<li>Incorrect. While minimizing the expected length is a desirable property, it is not the defining characteristic of a UMA interval.<br/>
</li>
<li>Correct. A UMA confidence interval minimizes the probability of including false parameter values, uniformly over all possible false values.<br/>
</li>
<li>Incorrect. The width of the interval is related to the expected length but is not the primary focus of UMA intervals.<br/>
</li>
<li>Incorrect. The variance of the estimator is a separate concept related to the efficiency of the estimator.</li>
</ol>
<p>The correct answer is <strong>b) The probability of false coverage.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Section 13.3</strong> defines a <strong>Uniformly Most Accurate</strong> (UMA) confidence interval as one that minimizes the probability of <strong>false coverage</strong>, which is the probability that the interval contains a false parameter value. This means that a UMA interval is designed to be as narrow as possible while still maintaining the desired coverage probability.</p>
</section>
<section class="level3" id="sec-ch13mcsolution17">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution17">MC Solution 17</h3>
<p><a href="#sec-ch13mcexercise17">MC Exercise 17</a></p>
<ol type="a">
<li>Incorrect. The likelihood ratio method does not guarantee the shortest possible interval in all cases.<br/>
</li>
<li>Incorrect. The likelihood ratio method typically requires knowledge of the data distribution to construct the likelihood function.<br/>
</li>
<li>Correct. The likelihood ratio method often relies on the asymptotic chi-squared distribution of the likelihood ratio statistic under the null hypothesis.<br/>
</li>
<li>Incorrect. The likelihood ratio method involves comparing the likelihood at the MLE to the likelihood at other parameter values.</li>
</ol>
<p>The correct answer is <strong>c) It is based on the asymptotic distribution of the likelihood ratio statistic.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Section 13.2</strong> explains that the likelihood ratio method for constructing confidence intervals is based on the likelihood ratio test. The method often utilizes the fact that, under certain regularity conditions, the likelihood ratio statistic has an asymptotic chi-squared distribution. This allows for the construction of approximate confidence intervals based on the quantiles of the chi-squared distribution.</p>
</section>
<section class="level3" id="sec-ch13mcsolution18">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution18">MC Solution 18</h3>
<p><a href="#sec-ch13mcexercise18">MC Exercise 18</a></p>
<p>The standard error of the sample proportion <span class="math inline">\(\hat{p}\)</span> is given by:</p>
<p><span class="math display">\[
\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\]</span></p>
<p>Plugging in <span class="math inline">\(\hat{p} = 0.7\)</span> and <span class="math inline">\(n = 100\)</span>, we get:</p>
<p><span class="math display">\[
\sqrt{\frac{0.7(1-0.7)}{100}} = \sqrt{\frac{0.21}{100}} = \sqrt{0.0021} \approx 0.0458
\]</span></p>
<p>The correct answer is <strong>a) 0.0458</strong>.</p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The standard error of the sample proportion is a measure of the variability of the sample proportion as an estimator of the true proportion. It is used in the construction of confidence intervals for proportions, as discussed in <strong>Example 13.11</strong>.</p>
</section>
<section class="level3" id="sec-ch13mcsolution19">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution19">MC Solution 19</h3>
<p><a href="#sec-ch13mcexercise19">MC Exercise 19</a></p>
<ol type="a">
<li>Incorrect. Increasing the sample size provides more information about the population.<br/>
</li>
<li>Correct. A larger sample size leads to a smaller standard error and thus a narrower confidence interval.<br/>
</li>
<li>Incorrect. The sample size directly affects the width of the interval.<br/>
</li>
<li>Incorrect. The effect can be determined based on the relationship between sample size and standard error.</li>
</ol>
<p>The correct answer is <strong>b) The width decreases.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>As the sample size increases, the standard error of the estimator decreases. Since the margin of error is proportional to the standard error, a smaller standard error leads to a smaller margin of error and a narrower confidence interval. This is consistent with the general principle discussed in <strong>Section 13.1</strong> that a good confidence interval shrinks with sample size.</p>
</section>
<section class="level3" id="sec-ch13mcsolution20">
<h3 class="anchored" data-anchor-id="sec-ch13mcsolution20">MC Solution 20</h3>
<p><a href="#sec-ch13mcexercise20">MC Exercise 20</a></p>
<p>A 95% confidence interval for a population mean with known population standard deviation is given by: <span class="math display">\[
\bar{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}}
\]</span> We are given that the interval is (12, 18), so the sample mean is <span class="math inline">\(\bar{X} = \frac{12+18}{2} = 15\)</span>. The margin of error is <span class="math inline">\(\frac{18-12}{2} = 3\)</span>. We are also given that <span class="math inline">\(n=25\)</span> and we know that for a 95% confidence interval, <span class="math inline">\(z_{\alpha/2} = 1.96\)</span>. We can set up the equation: <span class="math display">\[
3 = 1.96 \frac{\sigma}{\sqrt{25}}
\]</span> Solving for <span class="math inline">\(\sigma\)</span>, we get: <span class="math display">\[
\sigma = \frac{3 * \sqrt{25}}{1.96} = \frac{15}{1.96} \approx 7.65
\]</span> The closest value is 7.5.</p>
<p>The correct answer is <strong>a) 7.5</strong>.</p>
<p><strong>Intuitive Explanation:</strong> We use the formula for the confidence interval of a population mean with known standard deviation. The margin of error is half the width of the confidence interval. We can use this information, along with the sample size and the critical value, to solve for the population standard deviation.</p>
</section>
</section>
</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>

</div> <!-- /content -->
<footer class="footer">
<div class="nav-footer">
<div class="nav-footer-left">
<p>Author: Peter Fuleky</p>
</div>
<div class="nav-footer-center">
       
    </div>
<div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a></p>
</div>
</div>
</footer>
</body></html>