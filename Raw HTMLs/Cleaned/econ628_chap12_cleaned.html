<!DOCTYPE html>

<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
<meta charset="utf-8"/>
<meta content="quarto-1.5.57" name="generator"/>
<meta content="width=device-width, initial-scale=1.0, user-scalable=yes" name="viewport"/>
<meta content="Peter Fuleky" name="author"/>
<title>Chapter 12: Hypothesis Testing – Study notes for Econometrics I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>
<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta content="../" name="quarto:offset"/>
<link href="../chapters/chap13.html" rel="next"/>
<link href="../chapters/chap11.html" rel="prev"/>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet"/>
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" id="quarto-text-highlighting-styles" rel="stylesheet"/>
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet"/>
<link data-mode="light" href="../site_libs/bootstrap/bootstrap.min.css" id="quarto-bootstrap" rel="stylesheet"/>
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<link href="../style.css" rel="stylesheet"/>
</head>
<body class="nav-sidebar floating">
<div id="quarto-search-results"></div>
<header class="headroom fixed-top" id="quarto-header">

</header>
<!-- content -->
<div class="quarto-container page-columns page-rows-contents page-layout-article" id="quarto-content">
<!-- sidebar -->

<div class="quarto-sidebar-collapse-item" data-bs-target=".quarto-sidebar-collapse-item" data-bs-toggle="collapse" id="quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
<div class="sidebar margin-sidebar" id="quarto-margin-sidebar">

</div>
<!-- main -->
<main class="content" id="quarto-document-content">
<header class="quarto-title-block default" id="title-block-header">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 12: Hypothesis Testing</span></h1>
</div>
<div class="quarto-title-meta">
</div>
</header>
<section class="level2" id="hypotheses">
<h2 class="anchored" data-anchor-id="hypotheses">12.1 HYPOTHESES</h2>
<p>In addition to point estimation, we often want to know how good our estimator is and whether it is compatible with certain preconceived “hypotheses” about the data. Suppose that we observe certain data, and there is a true data distribution denoted by <span class="math inline">\(f\)</span>, which is known to lie in a family of models <span class="math inline">\(\mathcal{F}\)</span>. The purpose is to evaluate whether the data are compatible with certain preconceived hypotheses. The context is a parametric model <span class="math inline">\(\{P_{\theta}, \theta \in \Theta \}\)</span>, where <span class="math inline">\(\Theta\)</span> contains all the possible values of <span class="math inline">\(\theta\)</span>.</p>
<section class="level3" id="definition-12.1">
<h3 class="anchored" data-anchor-id="definition-12.1">Definition 12.1</h3>
<p>We suppose there is a further reduction of <span class="math inline">\(\Theta\)</span> called a <strong>Null hypothesis</strong> <span class="math inline">\(H_0\)</span> (<span class="math inline">\(\Theta_0 \subseteq \Theta\)</span>). The <strong>Alternative hypothesis</strong> <span class="math inline">\(H_1\)</span> (<span class="math inline">\(\Theta_1 \subseteq \Theta\)</span>) is the complement of the null hypothesis in <span class="math inline">\(\Theta\)</span>, i.e.,</p>
<p><span class="math display">\[
\Theta_0 \cap \Theta_1 = \phi \text{ and } \Theta_0 \cup \Theta_1 = \Theta.
\]</span></p>
<p>For example, <span class="math inline">\(H_0\)</span> could be:</p>
<ol type="1">
<li>The prediction of a scientific theory. For example, the interest elasticity of demand for money is zero; the gravitational constant is 9.</li>
<li>The absence of some structure, e.g., independence of an error term over time, homoskedasticity etc.</li>
<li>A simplification of an otherwise complicated model</li>
</ol>
</section>
<section class="level3" id="example-12.1">
<h3 class="anchored" data-anchor-id="example-12.1">Example 12.1</h3>
<p>A female colleague of the famous statistician R.A. Fisher claimed to be able to tell whether the tea or the milk was added first to a cup. Fisher proposed to give her eight cups, four of each variety, in random order. One could then ask what the probability was for her getting the number she got correct, but just by chance. The null hypothesis was that the Lady had no such ability. The test statistic was a simple count of the number of successes in selecting the 4 cups. The critical region was the single case of 4 successes of 4 possible based on a conventional probability criterion (<span class="math inline">\(&lt;5\%\)</span>); 1 of 70 <span class="math inline">\(\sim 1.4\%\)</span>). The lady correctly identified every cup, which would be considered a statistically significant result.</p>
<p>Our purpose here is to provide a method for interpreting what the data say about the hypothesis. We distinguish between a <strong>Simple hypothesis</strong> (under <span class="math inline">\(H_0\)</span>, the data distribution is completely specified) and a <strong>Composite hypothesis</strong> (in which case, <span class="math inline">\(H_0\)</span> does not completely determine the distribution, i.e., there are ‘nuisance’ parameters not specified by <span class="math inline">\(H_0\)</span>). We also distinguish between <strong>Single</strong> and <strong>Multiple</strong> hypotheses (one or more restriction on parameters of <span class="math inline">\(f\)</span>). We shall also distinguish between <strong>one-sided</strong> and <strong>two-sided</strong> alternatives; when we have a single real-valued parameter, this is an easy notion to comprehend.</p>
</section>
<section class="level3" id="example-12.2">
<h3 class="anchored" data-anchor-id="example-12.2">Example 12.2</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span>. <span class="math inline">\(H_0 : \mu = \mu_0\)</span> simple single null hypothesis. <span class="math inline">\(H_A : \mu \neq \mu_0\)</span> composite alternative (two-sided). One sided alternative <span class="math inline">\(H_A : \mu &gt; \mu_0\)</span> composite alternative (one-sided).</p>
</section>
<section class="level3" id="example-12.3">
<h3 class="anchored" data-anchor-id="example-12.3">Example 12.3</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>. <span class="math inline">\(H_0 : \mu = \mu_0\)</span> composite null because <span class="math inline">\(\sigma^2\)</span> is not restricted. <span class="math inline">\(H_A : \mu \neq \mu_0\)</span> composite alternative (two-sided); <span class="math inline">\(H_A : \mu &gt; \mu_0\)</span> composite alternative (one-sided)</p>
</section>
<section class="level3" id="example-12.4">
<h3 class="anchored" data-anchor-id="example-12.4">Example 12.4</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>. <span class="math inline">\(H_0 : \mu = \mu_0, \sigma^2 = \sigma_0^2\)</span> simple null, multiple hypotheses</p>
<p>One may observe that apparently for the one-sided alternative hypothesis, <span class="math inline">\(\Theta_0 \cup \Theta_1 \neq \Theta\)</span>. We may understand this in two ways. First, write the null hypothesis as <span class="math inline">\(H_0 : \mu \leq \mu_0\)</span> in which case <span class="math inline">\(\Theta_0 \cup \Theta_1 = \Theta = R\)</span>; in this case, <span class="math inline">\(\mu_0\)</span> is called the <strong>least favourable case</strong> (of the null hypothesis). Second, we may redefine <span class="math inline">\(\Theta = R_+ = \{ \theta : \theta \geq 0 \}\)</span> so that <span class="math inline">\(\Theta_0 \cup \Theta_1 = \Theta\)</span>.</p>
</section>
</section>
<section class="level2" id="test-procedure">
<h2 class="anchored" data-anchor-id="test-procedure">12.2 TEST PROCEDURE</h2>
<p>A hypothesis test is a procedure that allows one to carry out the simple decision rule:</p>
<p><span class="math display">\[
\varphi: X^n \rightarrow \{1, 0\}.
\]</span></p>
<p>It is like a criminal trial, which also has two outcomes (in most places): Guilty or not Guilty.</p>
<p>Essentially, we need to partition the data into two regions. There are many ways to do this. A common intermediate step is to calculate a scalar <strong>Test statistic</strong> <span class="math inline">\(T(X^n, \theta) \in R\)</span> that can measure the consistency of the data with <span class="math inline">\(H_0\)</span>. The logic of the test is to design this such that large values of <span class="math inline">\(T\)</span> are incompatible with the null hypothesis but small values of <span class="math inline">\(T\)</span> are compatible with null.</p>
<p>So how big should <span class="math inline">\(T\)</span> be before I reject? Define the following quantities: <strong>Significance level</strong> <span class="math inline">\(\alpha \in (0, 1)\)</span>, <strong>Critical region</strong> <span class="math inline">\(R_{\alpha}\)</span>, and <strong>Acceptance region</strong> <span class="math inline">\(C_{\alpha} = R^c_{\alpha}\)</span>. Usually, <span class="math inline">\(C_{\alpha}\)</span> is an interval such as <span class="math inline">\([c_{\alpha}, C_{\alpha}]\)</span> with the limits being called <strong>critical values</strong>.</p>
<p>The test is carried out such that: if <span class="math inline">\(T \in C_{\alpha}\)</span>, then accept the null hypothesis; if <span class="math inline">\(T \in R_{\alpha}\)</span>, then reject the null hypothesis. The usual approach is to choose the partition such that</p>
<p><span class="math display">\[
\text{Exact} \qquad \text{Pr}(T \in R_{\alpha} | H_0 \text{ is true}) = \alpha
\]</span></p>
<p><span class="math display">\[
\text{Approximate} \qquad \lim_{n \rightarrow \infty} \text{Pr}(T \in R_{\alpha} | H_0 \text{ is true}) = \alpha.
\]</span></p>
<p>When the null hypothesis is true, the rule yields reject decision <span class="math inline">\(\alpha\)</span> proportion of times (or approximately <span class="math inline">\(\alpha\)</span> proportion of times) so that were this test applied to many such data sets generated by <span class="math inline">\(H_0\)</span>, you would indeed reject <span class="math inline">\(\alpha\)</span> proportion of times. Note that accepting the null hypothesis does not mean we can conclude that it is true, only that there is insufficient evidence from this test that it is false. This is an example of a <strong>transposed conditional</strong>.</p>
<p>How to choose <span class="math inline">\(\alpha\)</span>? This is about measuring the standard of evidence against the null hypothesis that leads you to reject it. Lawyers use “beyond reasonable doubt” as the standard of evidence in criminal trials, and “the balance of probabilities” in civil trials. In statistics, these are quantitatively expressed through <span class="math inline">\(\alpha\)</span>. Values such as <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(\alpha = 0.01\)</span> are common standards in social sciences and medical research.</p>
<p>The main issue is how to choose <span class="math inline">\(T\)</span> and <span class="math inline">\(R_{\alpha}\)</span>. This involves calculating <span class="math inline">\(\text{Pr}(T \in R_{\alpha} | H_0)\)</span> or finding an approximation to it. In some special cases (normality) we can find a <span class="math inline">\(T\)</span> whose distribution under <span class="math inline">\(H_0\)</span> whose distribution is known exactly or approximately in large samples. This is called the <strong>pivotal case</strong>. In other cases, the distribution of <span class="math inline">\(T\)</span> under <span class="math inline">\(H_0\)</span> may depend (even in large samples) on unknown quantities that have to be estimated.</p>
<section class="level3" id="example-12.5">
<h3 class="anchored" data-anchor-id="example-12.5">Example 12.5</h3>
<p>Suppose that <span class="math inline">\(X_1, \dots, X_n\)</span> are i.i.d. <span class="math inline">\(N(\mu, \sigma^2)\)</span>, where <span class="math inline">\(\sigma^2\)</span> is known. Suppose that <span class="math inline">\(H_0 : \mu = \mu_0\)</span>. Then</p>
<p><span class="math display">\[
T = \dfrac{(X - \mu_0)}{\sigma / \sqrt{n}} \sim N(0, 1) \text{ under } H_0.
\]</span></p>
<p>Let <span class="math inline">\(R_{\alpha} = \{ x : |x| \geq z_{\alpha/2} \}\)</span>. The rule is to reject if <span class="math inline">\(|T| \geq z_{\alpha/2}\)</span>, where <span class="math inline">\(\Phi(z_{\alpha}) = 1 - \alpha\)</span>. Critical values <span class="math inline">\(\pm z_{\alpha/2}\)</span>. If the alternative is one-sided, then reject if <span class="math inline">\(T &gt; z_{\alpha}\)</span>, i.e., critical value is <span class="math inline">\(z_{\alpha}\)</span>. Suppose now that <span class="math inline">\(\sigma^2\)</span> is unknown, in which case the null is composite with the value of <span class="math inline">\(\sigma^2\)</span> unrestricted. In this case, we use the celebrated <strong>t-test</strong></p>
<p><span class="math display">\[
T = \dfrac{X - \mu_0}{s_* / \sqrt{n}} \sim t(n-1) \text{ under } H_0.
\]</span></p>
<p>Reject if <span class="math inline">\(|T| &gt; t_{\alpha/2}(n-1)\)</span> or <span class="math inline">\(T &gt; t_{\alpha}(n-1)\)</span>.</p>
<p>Typical critical values are shown in the table below:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(\alpha\)</span></th>
<th style="text-align: left;">0.05</th>
<th style="text-align: left;">0.025</th>
<th style="text-align: left;">0.005</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(z_{\alpha}\)</span></td>
<td style="text-align: left;">1.645</td>
<td style="text-align: left;">1.96</td>
<td style="text-align: left;">2.81</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(t_{\alpha}(9)\)</span></td>
<td style="text-align: left;">1.83</td>
<td style="text-align: left;">2.26</td>
<td style="text-align: left;">3.25</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(t_{\alpha}(4)\)</span></td>
<td style="text-align: left;">2.13</td>
<td style="text-align: left;">2.78</td>
<td style="text-align: left;">4.60</td>
</tr>
</tbody>
</table>
<p>In some fields of science it is more common to talk about a 5 sigma standard, that is <span class="math inline">\(c_{\alpha} = 5\)</span>. This corresponds to a significance level <span class="math inline">\(\alpha\)</span> of <span class="math inline">\(2.9 \times 10^{-7}\)</span> under the normal distribution. Note that as <span class="math inline">\(n \rightarrow \infty\)</span>,</p>
<p><span class="math display">\[
t_{\alpha}(n) \rightarrow z_{\alpha}
\]</span></p>
<p>for all <span class="math inline">\(\alpha\)</span>. In practice when <span class="math inline">\(n &gt; 30\)</span> the two critical values are the same to two decimal places.</p>
<p>In the previous example, when the nuisance parameter <span class="math inline">\(\sigma^2\)</span> was unknown and we had a composite null hypothesis, we still obtained (12.1). That is, for all <span class="math inline">\(\sigma^2 \in R_+\)</span>, we have</p>
<p><span class="math display">\[
\text{Pr}(T \in R_{\alpha} | \mu = \mu_0, \sigma^2) = \alpha.
\]</span></p>
<p>However, in other composite cases, this may not be exactly true.</p>
</section>
<section class="level3" id="example-12.6">
<h3 class="anchored" data-anchor-id="example-12.6">Example 12.6</h3>
<p>Suppose that <span class="math inline">\(X_1, \dots, X_n\)</span> are i.i.d. <span class="math inline">\(N(\mu, \sigma^2)\)</span>, where <span class="math inline">\(\sigma^2\)</span> is known. Suppose that <span class="math inline">\(H_0 : \mu \leq \mu_0\)</span>. Then</p>
<p><span class="math display">\[
T = \dfrac{(X - \mu_0)}{\sigma / \sqrt{n}} \sim N(\mu - \mu_0, 1) \text{ under } H_0.
\]</span></p>
<p>Let <span class="math inline">\(R_{\alpha} = \{ x : x \geq z_{\alpha} \}\)</span>. The rule is to reject if <span class="math inline">\(T \geq z_{\alpha}\)</span>. In this case, we have for all <span class="math inline">\(\mu \leq \mu_0\)</span></p>
<p><span class="math display">\[
\text{Pr}(T \in R_{\alpha} | \mu) \leq \alpha
\]</span></p>
<p>with equality only when <span class="math inline">\(\mu = \mu_0\)</span>. In general, we only may obtain</p>
<p><span class="math display">\[
\text{Exact} \qquad \sup_{\theta \in \Theta_0} \text{Pr}(T \in R_{\alpha} | \theta) \leq \alpha
\]</span></p>
<p><span class="math display">\[
\text{Approximate} \qquad \lim_{n \rightarrow \infty} \sup_{\theta \in \Theta_0} \text{Pr}(T \in R_{\alpha} | \theta) \leq \alpha,
\]</span></p>
<p>and in such cases where the inequality may be strict over some subset of the null hypothesis we say that the test is <strong>conservative</strong>. If there is a value <span class="math inline">\(\theta_0 \in \Theta_0\)</span> such that <span class="math inline">\(\text{Pr}(T \in R_{\alpha} | \theta_0) = \alpha\)</span> or <span class="math inline">\(\lim_{n \rightarrow \infty} \text{Pr}(T \in R_{\alpha} | \theta_0) = \alpha\)</span>, this value is called the <strong>least favourable case</strong>. By themselves the objectives (12.3) and (12.4) are not hard to achieve: one can always just use a random number generator to achieve the right rejection probability. However, as we will see below, it may not be possible to achieve these objectives in some cases if one simultaneously wants to reject false hypotheses frequently.</p>
<p>Sachs (1999) used rather complete data records from Switzerland to analyze the relationships between the signs of the Zodiac and (1) who purchases literature on astrology, (2) marriages, (3) divorces, (4) who lives single, (5) choice of university major, (6) profession, (7) cause of death, (8) suicide, (9) criminal convictions, (10) driving record, and (11) who plays football. For example, for his analyses of who marries whom, Sachs used the records of weddings in Switzerland from 1987 through 1994. In all 11 behaviour domains, Sachs found numerous significant associations between the signs of the Zodiac and behaviour.</p>
</section>
<section class="level3" id="example-12.7">
<h3 class="anchored" data-anchor-id="example-12.7">Example 12.7</h3>
<p>We want to test whether Zodiac sign has any influence on success measured by income at age 40. We have a sample of individuals from each Zodiac sign and assume that their (log of) income <span class="math inline">\(X_j \sim N(\mu_j, \sigma_0^2)\)</span>, <span class="math inline">\(j = 1, 2, \dots, 12\)</span>, where <span class="math inline">\(\sigma_0^2\)</span> is known but <span class="math inline">\(\mu_j\)</span> are not. In this case the null hypothesis is that <span class="math inline">\(H_0 : \mu_1 = \mu_2 = \dots = \mu_{12} = \mu_0\)</span>, where <span class="math inline">\(\mu_0\)</span> is a known number, versus the alternative that the <span class="math inline">\(\mu_j\)</span> are not all the same. These are multiple restrictions, which may better be described as</p>
<p><span class="math display">\[
\mu_1 = \mu_0, \dots, \mu_{12} = \mu_0.
\]</span></p>
<p>Suppose we have independent samples of size <span class="math inline">\(n_j\)</span>, <span class="math inline">\(j = 1, \dots, 12\)</span> from each Zodiac sign. A simple test statistic</p>
<p><span class="math display">\[
\begin{aligned}
\tau &amp;= \sum_{j=1}^{12} \left( \dfrac{X_j - \mu_0}{\sigma_0 / \sqrt{n_j}} \right)^2 \\
&amp;= \sum_{j=1}^{12} n_j \left( \dfrac{X_j - \mu_0}{\sigma_0} \right)^2 \sim \chi^2(12).
\end{aligned}
\]</span></p>
<p>We reject the null hypothesis when <span class="math inline">\(\tau &gt; \chi^2_{\alpha}(12)\)</span>. See Figure 12.1.</p>
<p>For large sample tests, the logic is based on LLN, CLT, and Slutsky theorems.</p>
</section>
<section class="level3" id="example-12.8">
<h3 class="anchored" data-anchor-id="example-12.8">Example 12.8</h3>
<p>Suppose that <span class="math inline">\(X\)</span> is i.i.d. with <span class="math inline">\(E(X) = \mu\)</span> and <span class="math inline">\(\text{var}(X) = \sigma^2\)</span>, where <span class="math inline">\(\sigma^2\)</span> is unknown. We test the hypothesis that <span class="math inline">\(\mu = \mu_0\)</span>. In this case, under the null hypothesis</p>
<p><span class="math display">\[
T = \dfrac{\sqrt{n}(X - \mu_0)}{s} \xrightarrow{d} N(0, 1).
\]</span></p>
<p>Reject the null if <span class="math inline">\(|T| &gt; z_{\alpha/2}\)</span> or <span class="math inline">\(T &gt; z_{\alpha}\)</span>. The test is asymptotically valid.</p>
</section>
<section class="level3" id="example-12.9">
<h3 class="anchored" data-anchor-id="example-12.9">Example 12.9</h3>
<p>In the Zodiac example, suppose that we just assume that their (log of) income is i.i.d. with mean <span class="math inline">\(\mu_j\)</span>, <span class="math inline">\(j = 1, 2, \dots, 12\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>. Then asymptotically</p>
<p><span class="math display">\[
\tau = \sum_{j=1}^{12} \left( \dfrac{X_j - \mu_0}{\sigma_0 / \sqrt{n_j}} \right)^2 \xrightarrow{d} \chi^2(12)
\]</span></p>
<p>We reject the null hypothesis when <span class="math inline">\(\tau &gt; \chi^2_{\alpha}(12)\)</span>. The test is asymptotically valid.</p>
<p>We next consider the <strong>multiple testing issue</strong>, which is currently a major field of research in statistics. Consider the Zodiac example and compute for <span class="math inline">\(j = 1, \dots, 12\)</span></p>
<p><span class="math display">\[
\tau_j = \dfrac{X_j - \mu_0}{\sigma_0 / \sqrt{n_j}} \sim N(0, 1); \qquad C_j = \{ X^n : |\tau_j| \leq z_{\alpha/2} \}.
\]</span></p>
<p>Why not just carry out 12 tests using <span class="math inline">\(\tau_j\)</span>, i.e., reject if any one of them rejects? This is called the <strong>finite induced test</strong>. We calculate the rejection probability under the null:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}[C_1 \cap \dots \cap C_{12}] &amp;= \text{Pr}[|\tau_1| \leq z_{\alpha/2}, \dots, |\tau_{12}| \leq z_{\alpha/2}] \\
&amp;= \text{Pr}[|\tau_1| \leq z_{\alpha/2}] \times \dots \times \text{Pr}[|\tau_{12}| \leq z_{\alpha/2}] \\
&amp;= (1 - \alpha)^{12} &lt; 1 - \alpha.
\end{aligned}
\]</span></p>
<p>This says that if we use the critical value <span class="math inline">\(z_{\alpha/2}\)</span> we will over reject the null hypothesis (<strong>liberal test</strong>). Instead, if we use the critical value <span class="math inline">\(z_{\gamma/2}\)</span> with <span class="math inline">\(\gamma\)</span> such that <span class="math inline">\((1 - \gamma)^{12} = 1 - \alpha\)</span>, then the resulting test of the multiple null will have significance level <span class="math inline">\(\alpha\)</span>. So it is a perfectly valid test after this adjustment. The critical region of this test is a cuboid rather than a spheroid. These two different tests have overlapping critical regions, i.e., one may reject both tests, reject neither test, or reject one but not the other test. The calculation above requires heavily on the independence of <span class="math inline">\(\tau_j\)</span> otherwise the exact critical value for this procedure is harder to obtain.</p>
</section>
<section class="level3" id="example-12.10">
<h3 class="anchored" data-anchor-id="example-12.10">Example 12.10</h3>
<p>Suppose we want to predict future stock returns <span class="math inline">\(Y\)</span> and I have a database of quadrillions of different predictors, <span class="math inline">\(X_j\)</span>. The semistrong Efficient Markets Hypothesis, or EMH, (with constant risk premium) says that <span class="math inline">\(\rho_j = \text{cov}(X_j, Y) = 0\)</span>. Suppose that everything has mean zero and variance one and is mutually independent, and I observe a sample of size <span class="math inline">\(n\)</span> on all variables. For each predictor I compute</p>
<p><span class="math display">\[
\hat{\rho}_j = \dfrac{1}{n} \sum_{i=1}^{n} X_{ji} Y_i
\]</span></p>
<p>Under EMH, the CLT says that</p>
<p><span class="math display">\[
\sqrt{n} \hat{\rho}_j \xrightarrow{d} N(0, 1).
\]</span></p>
<p>Reject if <span class="math inline">\(|\sqrt{n} \hat{\rho}_j| \geq z_{\alpha/2}\)</span>. Bright idea: Suppose I just did all the possible tests and take the predictor with the maximum test statistic? This can be thought of as an application of the <strong>Infinite monkey theorem</strong>. The significance level of this procedure is <span class="math inline">\(1 - (1 - \alpha)^{\text{quadrillions}} \sim 1\)</span>.</p>
</section>
</section>
<section class="level2" id="likelihood-tests">
<h2 class="anchored" data-anchor-id="likelihood-tests">12.3 LIKELIHOOD TESTS</h2>
<p>Suppose we have the null <span class="math inline">\(\theta \in \Theta_0\)</span> and the alternative <span class="math inline">\(\theta \in \Theta_1 = \Theta_0^c\)</span>. The <strong>likelihood ratio statistic</strong> is</p>
<p><span class="math display">\[
\lambda(X^n) = \dfrac{\max_{\theta \in \Theta} L(\theta | X^n)}{\max_{\theta \in \Theta_0} L(\theta | X^n)} = \dfrac{L(\hat{\theta}_{MLE} | X^n)}{L(\hat{\theta}_{RMLE} | X^n)},
\]</span></p>
<p>where <span class="math inline">\(\hat{\theta}_{MLE}\)</span> is MLE (max over <span class="math inline">\(\Theta\)</span>) and the <span class="math inline">\(\hat{\theta}_{RMLE}\)</span> is the “restricted MLE” over <span class="math inline">\(\Theta_0\)</span>. Note that some authors define the likelihood ratio as <span class="math inline">\(1 / \lambda\)</span>, and in some cases it is defined as <span class="math inline">\(\max_{\theta \in \Theta_1} L(\theta | X^n) / \max_{\theta \in \Theta_0} L(\theta | X^n)\)</span>. There are two other well known tests that are related to the LR test, the <strong>Wald test</strong> and the <strong>Score test</strong> (or <strong>LM test</strong>). Suppose that we can express the restrictions imposed by the null hypothesis in the form <span class="math inline">\(g(\theta_0) = 0\)</span> for some differentiable function <span class="math inline">\(g\)</span> such that <span class="math inline">\(G(\theta_0) = g'(\theta_0) \neq 0\)</span>. That is, the null is simple. The Wald statistic and Score test for this case are</p>
<p><span class="math display">\[
W = \dfrac{n g(\hat{\theta})^2}{G(\hat{\theta})^2 I(\hat{\theta})} ; \qquad LM = \dfrac{n s(\hat{\theta}_{RMLE})^2}{I(\hat{\theta}_{RMLE})}
\]</span></p>
<p><strong>Logic</strong>: Note that <span class="math inline">\(\lambda(X^n) \geq 1\)</span> and small values of <span class="math inline">\(\lambda\)</span> would point to the veracity of the null hypothesis, while large values would go against it. The logic of the Wald test is that under the null hypothesis <span class="math inline">\(g(\hat{\theta})\)</span> should be close to zero. The logic of the score test is that under the null hypothesis <span class="math inline">\(s(\hat{\theta}_{RMLE})\)</span> should be close to zero, while under the alternative hypothesis it will not be.</p>
<p>We continue this discussion for the LRT. A LRT is any test that rejects when <span class="math inline">\(\lambda(X^n) \geq c\)</span> for some <span class="math inline">\(c \geq 1\)</span>, i.e., we have a rejection region</p>
<p><span class="math display">\[
R_{\alpha}(\lambda) = \{ \lambda : \lambda \geq c \}.
\]</span></p>
<p>The key issue is to find <span class="math inline">\(c\)</span> to control the significance level.</p>
<section class="level3" id="example-12.11">
<h3 class="anchored" data-anchor-id="example-12.11">Example 12.11</h3>
<p><span class="math inline">\(X \sim N(\mu, 1)\)</span>. <span class="math inline">\(H_0 : \mu = \mu_0\)</span> vs. <span class="math inline">\(H_A : \mu \neq \mu_0\)</span>. In this case the denominator is</p>
<p><span class="math display">\[
L(\mu_0 | X^n) = \dfrac{1}{(2 \pi)^{n/2}} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \mu_0)^2 \right).
\]</span></p>
<p>The MLE is <span class="math inline">\(\hat{\mu}_{MLE} = X\)</span>, so</p>
<p><span class="math display">\[
\begin{aligned}
\lambda(X^n) &amp;= \dfrac{(2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - X)^2 \right)}{(2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \mu_0)^2 \right)} \\
&amp;= \exp \left( \dfrac{n}{2} (X - \mu_0)^2 \right)
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\log \lambda(X^n) = \dfrac{n}{2} (X - \mu_0)^2.
\]</span></p>
<p>So that in this case the LRT rejects if</p>
<p><span class="math display">\[
\lambda(X^n) \geq c \Leftrightarrow \sqrt{n} |X - \mu_0| \geq \sqrt{-2 \log c}
\]</span></p>
<p>for any <span class="math inline">\(c\)</span>. Therefore, we take <span class="math inline">\(c\)</span> that solves <span class="math inline">\(z_{\alpha/2} = \sqrt{2 \log c}\)</span>, which says that <span class="math inline">\(c = \exp \left( \dfrac{z_{\alpha/2}^2}{2} \right)\)</span> works.</p>
</section>
<section class="level3" id="example-12.12">
<h3 class="anchored" data-anchor-id="example-12.12">Example 12.12</h3>
<p>Zodiac. In this case we may show</p>
<p><span class="math display">\[
\begin{aligned}
\log \lambda(X^n) &amp;= \dfrac{1}{2 \sigma_0^2} \sum_{j=1}^{12} \sum_{i=1}^{n_j} (X_{ji} - \mu_0)^2 + \dfrac{1}{2 \sigma_0^2} \sum_{j=1}^{12} \sum_{i=1}^{n_j} (X_{ji} - X_j)^2 \\
&amp;= \dfrac{1}{2 \sigma_0^2} \sum_{j=1}^{12} \sum_{i=1}^{n_j} \{ (X_{ji} - \mu_0)^2 - (X_{ji} - X_j)^2 \} \\
&amp;= \dfrac{1}{2} \sum_{j=1}^{12} n_j \left( \dfrac{X_j - \mu_0}{\sigma_0} \right)^2
\end{aligned}
\]</span></p>
<p>The test we used earlier is equivalent to LRT.</p>
</section>
<section class="level3" id="example-12.13">
<h3 class="anchored" data-anchor-id="example-12.13">Example 12.13</h3>
<p>The Binomial case where <span class="math inline">\(X_i = 1\)</span> with probability <span class="math inline">\(p\)</span> and <span class="math inline">\(X_i = 0\)</span> with probability <span class="math inline">\(1 - p\)</span> and we observe <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i = 1, \dots, n\)</span>. Suppose the null hypothesis is that <span class="math inline">\(p \leq p_0\)</span> versus <span class="math inline">\(p &gt; p_0\)</span>. The likelihood ratio is</p>
<p><span class="math display">\[
\lambda(X^n) = \dfrac{\hat{p}^k (1 - \hat{p})^{n-k}}{p_0^k (1 - p_0)^{n-k}} = \left( \dfrac{\hat{p}}{p_0} \right)^k \left( \dfrac{1 - \hat{p}}{1 - p_0} \right)^{n-k} = \left( \dfrac{k}{n p_0} \right)^k \left( \dfrac{l}{n q_0} \right)^l
\]</span></p>
<p>where <span class="math inline">\(q_0 = 1 - p_0\)</span> and <span class="math inline">\(l = n - k\)</span>. This is a discrete random variable since <span class="math inline">\(k\)</span> takes the values <span class="math inline">\(0, 1, \dots, n\)</span>. Can see that any rejection region <span class="math inline">\(R_{\alpha}(\lambda) = \{ \lambda : \lambda \geq c \}\)</span> is equivalent to a rejection region <span class="math inline">\(\{ k : k \geq c' \}\)</span> for some <span class="math inline">\(c' \in \{ 0, 1, \dots, n \}\)</span>. We can calculate exactly the probability</p>
<p><span class="math display">\[
\text{Pr}(k \geq c') = \sum_{j \geq c'} \binom{n}{j} p_0^j (1 - p_0)^{n-j}
\]</span></p>
<p>for any <span class="math inline">\(c'\)</span>, but we may not be able to find <span class="math inline">\(c' \in \{ 0, 1, \dots, n \}\)</span> such that <span class="math inline">\(\text{Pr}(k \geq c') = \alpha\)</span>, because of the discreteness issue. Typically therefore we will have a conservative test with <span class="math inline">\(\text{Pr}(T \in R_{\alpha} | \theta) &lt; \alpha\)</span>.</p>
<p>We can define the LRT for any setting where we have a likelihood and clearly defined null and alternative hypothesis. However, it is often hard to get exact tests. Instead we may work with approximate tests based on large samples.</p>
</section>
<section class="level3" id="theorem-12.1">
<h3 class="anchored" data-anchor-id="theorem-12.1">Theorem 12.1</h3>
<p>Under some regularity conditions, under <span class="math inline">\(H_0\)</span></p>
<p><span class="math display">\[
2 \log \lambda(X^n), W, LM \xrightarrow{d} \chi^2(1).
\]</span></p>
<p>We will discuss the theory more in detail later.</p>
</section>
<section class="level3" id="example-12.14">
<h3 class="anchored" data-anchor-id="example-12.14">Example 12.14</h3>
<p>The Binomial case. In this case the log likelihood ratio is</p>
<p><span class="math display">\[
LR = n \left( \hat{p} \log \left( \dfrac{\hat{p}}{p_0} \right) + (1 - \hat{p}) \log \left( \dfrac{1 - \hat{p}}{1 - p_0} \right) \right) = n \phi(\hat{p}).
\]</span></p>
<p>We have under the null hypothesis <span class="math inline">\(\sqrt{n} (\hat{p} - p_0) \xrightarrow{d} N(0, p_0 (1 - p_0))\)</span>. The function <span class="math inline">\(\phi\)</span> is twice differentiable with</p>
<p><span class="math display">\[
\phi'(p) = \log \left( \dfrac{p}{1 - p} \right) - \log \left( \dfrac{p_0}{1 - p_0} \right)
\]</span></p>
<p><span class="math display">\[
\phi''(p) = \dfrac{1}{p(1-p)}
\]</span></p>
<p>and <span class="math inline">\(\phi'(p_0) = 0\)</span> but <span class="math inline">\(\phi''(p_0) \neq 0\)</span>. Applying the delta method corollary we obtain (12.7). The Wald statistic and Score test are</p>
<p><span class="math display">\[
W = \dfrac{n (\hat{p} - p_0)^2}{\hat{p} (1 - \hat{p})} ; \qquad LM = \dfrac{n (\hat{p} - p_0)^2}{p_0 (1 - p_0)}.
\]</span></p>
<p>By even simpler arguments we also obtain the chi-squared limiting distribution for <span class="math inline">\(W, LM\)</span> under the null hypothesis.</p>
</section>
</section>
<section class="level2" id="power-of-tests">
<h2 class="anchored" data-anchor-id="power-of-tests">12.4 POWER OF TESTS</h2>
<p>We next define the power of a test. Hypothesis testing, like criminal trials, makes two types of errors.</p>
<section class="level3" id="definition-12.2">
<h3 class="anchored" data-anchor-id="definition-12.2">Definition 12.2</h3>
<p><strong>Type I error</strong>: Reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true; <strong>Type II error</strong>: accept <span class="math inline">\(H_0\)</span> when it is false. Let</p>
<p><span class="math display">\[
\alpha = \text{Pr}(\text{Type I error}) = \text{Pr}(\text{Reject } H_0 | H_0 \text{ is true})
\]</span></p>
<p><span class="math display">\[
\beta = \text{Pr}(\text{Type II error}) = \text{Pr}(\text{Accept } H_0 | H_A \text{ is true}).
\]</span></p>
<p>If the hypotheses are composite then <span class="math inline">\(\alpha, \beta\)</span> may depend on the particular value of <span class="math inline">\(\theta\)</span>. There is generally a trade-off between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. <span class="math inline">\(\alpha\)</span> is called the <strong>size</strong> of the test or the <strong>significance level</strong>, while <span class="math inline">\(\pi = 1 - \beta\)</span> is called the <strong>power</strong> of the test. We want a test with high power or low error rate of type II. Power will depend on the particular alternative value and on the sample size.</p>
</section>
<section class="level3" id="example-12.15">
<h3 class="anchored" data-anchor-id="example-12.15">Example 12.15</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span> and <span class="math inline">\(H_0 : \mu = \mu_0\)</span> versus <span class="math inline">\(H_A : \mu &gt; \mu_0\)</span>. We have for all <span class="math inline">\(\mu \in R\)</span>,</p>
<p><span class="math display">\[
T = \sqrt{n} (X - \mu_0) = \sqrt{n} (X - \mu) + \sqrt{n} (\mu - \mu_0) \sim N(\sqrt{n} (\mu - \mu_0), 1).
\]</span></p>
<p>Suppose that we reject the null hypothesis if <span class="math inline">\(T &gt; z_{\alpha}\)</span>. It follows that</p>
<p><span class="math display">\[
\pi_n(\mu) = \text{Pr}(T \geq z_{\alpha} | \mu) = \text{Pr}(N(0, 1) + \delta_n(\mu) \geq z_{\alpha}) = 1 - \Phi(z_{\alpha} - \delta_n(\mu)).
\]</span></p>
<p>When <span class="math inline">\(\mu &gt; \mu_0\)</span>, <span class="math inline">\(\delta_n(\mu) &gt; 0\)</span>, and <span class="math inline">\(\pi_n(\mu) &gt; \alpha\)</span>. The larger is <span class="math inline">\(\delta_n(\mu)\)</span>, the larger is the power. As <span class="math inline">\(\mu \rightarrow \infty\)</span>, we find <span class="math inline">\(\pi_n(\mu) \rightarrow 1\)</span>. On the other hand, as <span class="math inline">\(\mu \rightarrow \mu_0\)</span> we have <span class="math inline">\(\pi_n(\mu) \rightarrow \alpha\)</span>, that is, the type II error converges to <span class="math inline">\(1 - \alpha\)</span>. See Figures 12.2 and 12.3.</p>
<p>This shows that the power of the test is larger as: the alternative is further from the null hypothesis and as the sample size is larger. Likewise, the power of the test decreases as the alternative gets closer to the null. In general, we find that <span class="math inline">\(\inf_{\theta \in \Theta_1} \pi_n(\theta) \leq \alpha\)</span>. A test for which <span class="math inline">\(\inf_{\theta \in \Theta_1} \pi_n(\theta) = \alpha\)</span> is said to be <strong>unbiased</strong>, meaning the rejection frequency is at least as big under the alternative as under the null. This would seem like a pretty reasonable requirement; it is easy to establish in simple cases like we show here but harder to show in more complicated cases. Indeed, one often finds that in complicated multiple testing environments there are alternatives against which a test has zero power.</p>
</section>
<section class="level3" id="example-12.16">
<h3 class="anchored" data-anchor-id="example-12.16">Example 12.16</h3>
<p>Zodiac. Suppose that we consider the test statistic</p>
<p><span class="math display">\[
T = \dfrac{1}{\sqrt{12}} \sum_{j=1}^{12} \dfrac{(X_j - \mu_0)}{\sigma_0 / \sqrt{n_j}} \sim N(0, 1) \text{ under } H_0.
\]</span></p>
<p>Large values of <span class="math inline">\(T\)</span> are generally incompatible with null hypothesis and makes a valid test. However, we have zero power against some alternatives. Suppose that <span class="math inline">\(n_j = n/12\)</span>. If <span class="math inline">\((\mu_1, \dots, \mu_{12})\)</span> is such that</p>
<p><span class="math display">\[
\dfrac{1}{12} \sum_{j=1}^{12} \mu_j = \mu_0
\]</span></p>
<p>we have <span class="math inline">\(\delta_n(\mu) = 0\)</span> and <span class="math inline">\(T \sim N(0, 1)\)</span> under these members of <span class="math inline">\(H_A\)</span>, that is, the test has zero power against these alternatives. In some sense, made precise below, the set <span class="math inline">\(\{ (\mu_1, \dots, \mu_{12}) : \dfrac{1}{12} \sum_{j=1}^{12} \mu_j = \mu_0 \}\)</span> is much larger than the set <span class="math inline">\(\{ (\mu_1, \dots, \mu_{12}) : \dfrac{1}{12} \sum_{j=1}^{12} \mu_j \neq \mu_0 \}\)</span>.</p>
</section>
<section class="level3" id="neyman-pearson-optimal-testing">
<h3 class="anchored" data-anchor-id="neyman-pearson-optimal-testing">12.4.1 Neyman Pearson Optimal Testing</h3>
<p>We would like to simultaneously minimize <span class="math inline">\(\alpha\)</span> and maximize <span class="math inline">\(\pi\)</span>, i.e., to set type I and type II errors to zero, but these objectives are generally in conflict. We instead first specify and control <span class="math inline">\(\alpha\)</span>, and then find a test with the best <span class="math inline">\(\pi\)</span> for the given <span class="math inline">\(\alpha\)</span>.</p>
<p>We now consider the class of all tests with size <span class="math inline">\(\alpha\)</span> for <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>. Want to find the test for which <span class="math inline">\(\pi(\theta)\)</span> is uniformly maximized over <span class="math inline">\(\Theta_1\)</span>. If such a test exists, it is said to be <strong>Uniformly Most Powerful</strong> (UMP). Not possible in general.</p>
<p>We now give the Neyman-Pearson lemma which applies to the special case of a simple null and a simple alternative, that is,</p>
<p><span class="math display">\[
\Theta_0 = \{ \theta_0 \}, \Theta_1 = \{ \theta_1 \}
\]</span></p>
<p>i.e., <span class="math inline">\(H_0 : \theta = \theta_0\)</span> and <span class="math inline">\(H_A : \theta = \theta_1\)</span>. In this case, with <span class="math inline">\(n=1\)</span>, we define the likelihood ratio as</p>
<p><span class="math display">\[
\lambda(x) = \dfrac{f(x | \theta_0)}{f(x | \theta_1)} = \dfrac{f_0(x)}{f_1(x)}
\]</span></p>
</section>
<section class="level3" id="theorem-12.2">
<h3 class="anchored" data-anchor-id="theorem-12.2">Theorem 12.2</h3>
<p>(Neyman-Pearson) Let <span class="math inline">\(R\)</span> be any critical region with</p>
<p><span class="math display">\[
\text{Pr}(X \in R | \theta_0) \leq \alpha
\]</span></p>
<p>Suppose there exists a critical region <span class="math inline">\(R_{\lambda}\)</span> of the form</p>
<p><span class="math display">\[
R_{\lambda} = \left\{ x : \dfrac{f(x | \theta_1)}{f(x | \theta_0)} \geq k \right\} \text{ such that } \text{Pr}(X \in R_{\lambda} | \theta_0) = \alpha.
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\text{Pr}(X \in R_{\lambda} | \theta_1) \geq \text{Pr}(X \in R | \theta_1),
\]</span></p>
<p>i.e., a test based on the likelihood ratio has better power.</p>
<p><strong>Proof</strong>. We show the proof for continuous data only. Writing <span class="math inline">\(R_{\lambda} = (R_{\lambda} \cap R) \cup (R_{\lambda} \cap R^c)\)</span> and <span class="math inline">\(R = (R_{\lambda} \cap R) \cup (R_{\lambda}^c \cap R)\)</span> we obtain that</p>
<p><span class="math display">\[
\text{Pr}(X \in R_{\lambda} | \theta_1) - \text{Pr}(X \in R | \theta_1) = \int_{R_{\lambda} \cap R^c} f_1(x) dx - \int_{R_{\lambda}^c \cap R} f_1(x) dx.
\]</span></p>
<p>On <span class="math inline">\(R \cap R^c \subseteq R_{\lambda}\)</span>, we have</p>
<p><span class="math display">\[
f_1(x) \geq k f_0(x),
\]</span></p>
<p>so that</p>
<p><span class="math display">\[
\int_{R_{\lambda} \cap R^c} f_1(x) dx \geq k \int_{R_{\lambda} \cap R^c} f_0(x) dx.
\]</span></p>
<p>On <span class="math inline">\(R_{\lambda}^c \cap R \subseteq R_{\lambda}^c\)</span>, we have</p>
<p><span class="math display">\[
\int_{R_{\lambda}^c \cap R} f_1(x) dx &lt; k \int_{R_{\lambda}^c \cap R} f_0(x) dx.
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(X \in R_{\lambda} | \theta_1) - \text{Pr}(X \in R | \theta_1) &amp;\geq k \left[ \int_{R_{\lambda} \cap R^c} f_0(x) dx - \int_{R_{\lambda}^c \cap R} f_0(x) dx \right] \\
&amp;= k \left[ \int_{R_{\lambda}} f_0(x) dx - \int_{R} f_0(x) dx \right] \\
&amp;= k \left[ \text{Pr}(X \in R_{\lambda} | \theta_0) - \text{Pr}(X \in R | \theta_0) \right] \\
&amp;\geq 0,
\end{aligned}
\]</span></p>
<p>since <span class="math inline">\(k \geq 0\)</span> and <span class="math inline">\(\text{Pr}(X \in R_{\lambda} | \theta_0) = \alpha\)</span> and <span class="math inline">\(\text{Pr}(X \in R | \theta_0) \leq \alpha\)</span>.</p>
<p><strong>Remarks</strong>.</p>
<ol type="1">
<li>When <span class="math inline">\(X\)</span> is discrete it may not be possible to find <span class="math inline">\(R_{\lambda}\)</span> for all such <span class="math inline">\(\alpha\)</span>. For example, suppose that <span class="math inline">\(X\)</span> is the number of successes in three independent trials and that <span class="math inline">\(\theta_0 = 1/4\)</span> or <span class="math inline">\(\theta_1 = 3/4\)</span>. We have to find <span class="math inline">\(k\)</span> such that</li>
</ol>
<p><span class="math display">\[
\text{Pr} \left[ X : \dfrac{f_1(X)}{f_0(X)} \geq k \right] = 0.05,
\]</span></p>
<p>which is equivalent to finding <span class="math inline">\(k'\)</span> such that</p>
<p><span class="math display">\[
\text{Pr}[X \geq k'] = 0.05.
\]</span></p>
<p>Since <span class="math inline">\(X\)</span> can only be <span class="math inline">\(0, 1, 2, 3\)</span> this can not be done exactly. One way out of this is just to work with those specific <span class="math inline">\(\alpha\)</span> for which an exact likelihood ratio critical region can be found. An alternative is to use randomization.</p>
<ol start="2" type="1">
<li>The extension to one-sided composite hypotheses</li>
</ol>
<p><span class="math display">\[
H_0 : \theta \leq \theta_0, H_A : \theta &gt; \theta_0.
\]</span></p>
<p>The <strong>Karlin-Rubin theorem</strong> says that the LR test is UMP provided there is a sufficient statistic <span class="math inline">\(T(X)\)</span> that has the <strong>monotone likelihood ratio (MLR)</strong> property: for all <span class="math inline">\(\theta_1 &gt; \theta_0\)</span>, <span class="math inline">\(\dfrac{f(x | \theta_1)}{f(x | \theta_0)}\)</span> is a nondecreasing function of <span class="math inline">\(x\)</span> on (joint support) <span class="math inline">\(\{ x : f(x | \theta_1) &gt; 0 \text{ and } f(x | \theta_0) &gt; 0 \}\)</span>. Reason is that every pair of parameter values <span class="math inline">\(\theta_1, \theta_2\)</span> with <span class="math inline">\(\theta_1 &lt; \theta_2\)</span> establishes the same preference ordering over the sample points. Examples: One parameter exponential families, e.g., Normal, Poisson, and Binomial.</p>
<ol start="3" type="1">
<li>In general, testing against two-sided alternatives, UMP’s do not exist. For example, suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span>; <span class="math inline">\(H_0 : \mu = 0\)</span> vs. <span class="math inline">\(\mu &gt; 0\)</span>. In this case, the best critical region is <span class="math inline">\(\{ X^n : X \geq z_{\alpha} / \sqrt{n} \}\)</span>. For any <span class="math inline">\(\mu &gt; 0\)</span>, this test is most powerful for testing the hypothesis <span class="math inline">\(\mu = 0\)</span> against the point alternative <span class="math inline">\(\mu\)</span>. The critical region is independent of <span class="math inline">\(\mu\)</span>. In the two-sided test, the test with rejection region</li>
</ol>
<p><span class="math display">\[
\left\{ X^n : |X| \geq \dfrac{z_{\alpha/2}}{\sqrt{n}} \right\}
\]</span></p>
<p>is less powerful than the test with rejection region</p>
<p><span class="math display">\[
\left\{ X^n : X \geq \dfrac{z_{\alpha}}{\sqrt{n}} \right\}
\]</span></p>
<p>when <span class="math inline">\(\mu &gt; 0\)</span>, and less powerful than the test with rejection region</p>
<p><span class="math display">\[
\left\{ X^n : X &lt; \dfrac{z_{\alpha}}{\sqrt{n}} \right\}
\]</span></p>
<p>when <span class="math inline">\(\mu &lt; 0\)</span>.</p>
<ol start="4" type="1">
<li>So in many cases optimal tests do not exist. In this case we turn to restricted classes to obtain optimality results, for example, Unbiased and Invariant Tests. An unbiased test satisfies</li>
</ol>
<p><span class="math display">\[
\pi(\theta) \geq \alpha \text{ for all } \theta \in \Theta_1.
\]</span></p>
<p>The one-sided test is biased (against all alternatives) because when <span class="math inline">\(\mu &lt; 0\)</span> the power is zero. The above two-sided normal test is UMP unbiased. Alternatively, one can eliminate some tests by requiring invariance under a group of transformations.</p>
<ol start="5" type="1">
<li>Although we may only be able to obtain optimal tests in limited circumstances using the Neyman-Pearson theory, we can use the theory to define the <strong>power envelope</strong>, that is, compute the optimal power that could be achieved against a specific point alternative, and then change the alternative value and again compute the optimal power under Neyman-Pearson rules. The curve that traces out the optimal power as a function of the alternative values is the power envelope. This gives a benchmark against which to compare tests that are designed against the composite alternative.</li>
</ol>
</section>
<section class="level3" id="consistency-of-tests-and-local-power">
<h3 class="anchored" data-anchor-id="consistency-of-tests-and-local-power">12.4.2 Consistency of Tests and Local Power</h3>
<p>In many cases it is hard if not impossible to derive the exact distribution of a test statistic under the null hypothesis, instead we may work with large sample approximation. In this case, we try to achieve <strong>asymptotic size control</strong> by working with a limiting distribution. We next consider how a test performs under the alternative hypothesis when the sample size is large.</p>
</section>
<section class="level3" id="definition-12.3">
<h3 class="anchored" data-anchor-id="definition-12.3">Definition 12.3</h3>
<p>A test with power function <span class="math inline">\(\pi_n(\theta)\)</span> is <strong>consistent</strong> if <span class="math inline">\(\lim_{n \rightarrow \infty} \pi_n(\theta) = 1\)</span> for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
<p>This is a desirable property. Many tests that we have considered are consistent under some conditions, including the general class of Likelihood Ratio tests.</p>
</section>
<section class="level3" id="example-12.17">
<h3 class="anchored" data-anchor-id="example-12.17">Example 12.17</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span> and <span class="math inline">\(H_0 : \mu = \mu_0\)</span> versus <span class="math inline">\(H_1 : \mu &gt; \mu_0\)</span>. We have for all <span class="math inline">\(\mu &gt; \mu_0\)</span> that <span class="math inline">\(\sqrt{n} (\mu - \mu_0) \rightarrow \infty\)</span> and so for <span class="math inline">\(T = \sqrt{n} (X - \mu_0)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\pi_n(\mu) &amp;= \text{Pr}(T \geq z_{\alpha} | \mu) \\
&amp;= 1 - \Phi(z_{\alpha} - \sqrt{n} (\mu - \mu_0)) \\
&amp;\rightarrow 1.
\end{aligned}
\]</span></p>
<p>This test is consistent against all alternatives <span class="math inline">\(\mu &gt; \mu_0\)</span>.</p>
<p>Consistency says that for fixed alternatives, the power goes to one (the Type II error probability goes to zero). This property can be established for many tests based on consistent estimators, so it is a minimal requirement for a good testing procedure. How do we discriminate between tests that are consistent?</p>
<p>The approach we consider here is to consider alternatives that are close to the null hypothesis. Suppose that the true parameter <span class="math inline">\(\theta\)</span> is actually a function of sample size so that</p>
<p><span class="math display">\[
\theta_n = \theta_0 + \delta_n(c),
\]</span></p>
<p>where <span class="math inline">\(\delta_n(c) \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> and <span class="math inline">\(c \in C\)</span>. If <span class="math inline">\(\delta_n(c) = c / \sqrt{n}\)</span> for <span class="math inline">\(c \in R_+\)</span>, we have the so-called <strong>Pitman alternatives</strong>, and we typically obtain</p>
<p><span class="math display">\[
\pi_n(\theta_n) \rightarrow \pi_L(c; \alpha) \in [\alpha, 1].
\]</span></p>
<p>That is, we may show (for a large class of testing problems) that under a sequence of local alternatives, the power function converges to a function bounded between the size and one, so that the test has some power against these alternatives. We hope that <span class="math inline">\(\pi_L(c; \alpha) &gt; \alpha\)</span> for all <span class="math inline">\(c \neq 0\)</span> because otherwise the test is not able to detect departures from the null hypothesis at this scale. The function <span class="math inline">\(\pi_L(c; \alpha)\)</span> is called the <strong>local power function</strong>. There is an elaborate theory of optimal large sample testing that compares tests according to their power against Pitman alternatives.</p>
</section>
<section class="level3" id="definition-12.4">
<h3 class="anchored" data-anchor-id="definition-12.4">Definition 12.4</h3>
<p>Suppose that test statistic <span class="math inline">\(T\)</span> has local power function <span class="math inline">\(\pi_L(c; \alpha)\)</span> and test statistic <span class="math inline">\(T^*\)</span> has local power function <span class="math inline">\(\pi_L^*(c; \alpha)\)</span>. The test <span class="math inline">\(T\)</span> is more powerful than <span class="math inline">\(T^*\)</span> if</p>
<p><span class="math display">\[
\pi_L(c; \alpha) \geq \pi_L^*(c; \alpha)
\]</span></p>
<p>for all <span class="math inline">\(c\)</span> in the (local) alternative set <span class="math inline">\(C\)</span>.</p>
<p>It turns out that in many cases Likelihood Ratio tests cannot be beaten over all local alternatives according to this criterion, i.e., they are essentially asymptotically optimal. Generally speaking, efficient estimators produce efficient tests.</p>
</section>
<section class="level3" id="example-12.18">
<h3 class="anchored" data-anchor-id="example-12.18">Example 12.18</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span> and <span class="math inline">\(H_0 : \mu = \mu_0\)</span> versus <span class="math inline">\(H_1 : \mu &gt; \mu_0\)</span>. We compare the two statistics</p>
<p><span class="math display">\[
T = \sqrt{n} (\hat{\mu} - \mu_0), \quad \hat{\mu} = \dfrac{1}{n} \sum_{i=1}^{n} X_i
\]</span></p>
<p><span class="math display">\[
T_E = \sqrt{n} (\hat{\mu}_E - \mu_0), \quad \hat{\mu}_E = \dfrac{\sqrt{2}}{n} \sum_{i=1}^{n/2} X_{2i}.
\]</span></p>
<p>Both <span class="math inline">\(T\)</span> and <span class="math inline">\(T_E\)</span> are consistent against all fixed alternatives. The local power function of <span class="math inline">\(T\)</span> and <span class="math inline">\(T_E\)</span> are respectively</p>
<p><span class="math display">\[
\pi_L(c; \alpha) = 1 - \Phi(z_{\alpha} - c) ; \quad \pi_L^E(c; \alpha) = 1 - \Phi \left( z_{\alpha} - \dfrac{c}{\sqrt{2}} \right),
\]</span></p>
<p>and clearly <span class="math inline">\(\pi_L(c; \alpha) \geq \pi_L^E(c; \alpha)\)</span> for all <span class="math inline">\(c, \alpha &gt; 0\)</span>.</p>
</section>
<section class="level3" id="example-12.19">
<h3 class="anchored" data-anchor-id="example-12.19">Example 12.19</h3>
<p>The Binomial case. Suppose that</p>
<p><span class="math display">\[
p_n = p_0 + \dfrac{c}{\sqrt{n}}
\]</span></p>
<p>Then writing <span class="math inline">\(\hat{p} - p_0 = \hat{p} - p_n + p_n - p_0\)</span> we obtain (by the triangular array CLT)</p>
<p><span class="math display">\[
\sqrt{n} (\hat{p} - p_0) \xrightarrow{d} N(c, p_0 (1 - p_0)),
\]</span></p>
<p>from which it follows that the Likelihood tests all converge in distribution to the same random variable <span class="math inline">\(Z(\delta)^2\)</span>, where <span class="math inline">\(Z(\delta) \sim N(\delta, 1)\)</span> and <span class="math inline">\(\delta = c / \sqrt{p_0 (1 - p_0)}\)</span>. This is called a non-central chi-squared distribution.</p>
</section>
<section class="level3" id="example-12.20">
<h3 class="anchored" data-anchor-id="example-12.20">Example 12.20</h3>
<p>Zodiac. Suppose that for <span class="math inline">\(j = 1, 2, \dots, 12\)</span></p>
<p><span class="math display">\[
\mu_{nj} = \mu_0 + \dfrac{c_j}{\sqrt{n}}
\]</span></p>
<p>Then writing <span class="math inline">\(X_j - \mu_0 = X_j - \mu_{nj} + \mu_{nj} - \mu_0\)</span> we obtain that</p>
<p><span class="math display">\[
\sqrt{n_j} \left( \dfrac{X_j - \mu_{nj}}{\sigma_0} \right) \xrightarrow{d} Z_j(c_j / \sigma_0) \sim N(c_j, 1),
\]</span></p>
<p>from which it follows that</p>
<p><span class="math display">\[
\sum_{j=1}^{12} n_j \left( \dfrac{X_j - \mu_0}{\sigma_0} \right)^2 \xrightarrow{d} \sum_{j=1}^{12} Z_j(c_j / \sigma_0)^2.
\]</span></p>
<p>Note that the mean of the limiting distribution is <span class="math inline">\(12 + \sum_{j=1}^{12} c_j^2 / \sigma_0^2\)</span> and provided <span class="math inline">\(\sum_{j=1}^{12} c_j^2 \neq 0\)</span> the local power will be greater than the size, that is, it suffices that only one of the <span class="math inline">\(c_j \neq 0\)</span>.</p>
<p>If the alternatives are even further from the null hypothesis, i.e., <span class="math inline">\(\sqrt{n} \delta_n(c) \rightarrow \infty\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> (or equivalently <span class="math inline">\(c = c_n \rightarrow \infty\)</span>), then many tests can achieve power approaching one, as for the case with a fixed alternative. On the other hand, if the alternatives are too close to the null hypothesis then as we have seen the power tends in the best case to <span class="math inline">\(\alpha\)</span>, that is,</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \inf_{\theta \in \Theta_1} \pi_n(\theta) = \alpha.
\]</span></p>
</section>
<section class="level3" id="example-12.21">
<h3 class="anchored" data-anchor-id="example-12.21">Example 12.21</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span> and <span class="math inline">\(H_0 : \mu = \mu_0\)</span> versus <span class="math inline">\(H_1 : \mu &gt; \mu_0\)</span>. If we take the sequence <span class="math inline">\(\mu_n = \mu_0 + n^{-1} \in H_1\)</span>, then</p>
<p><span class="math display">\[
\pi(\mu_n) = 1 - \Phi(z_{\alpha} - (1 / \sqrt{n})) \rightarrow 1 - \Phi(z_{\alpha}) = \alpha.
\]</span></p>
<p>We can’t generally make tests that are uniformly consistent except when the alternative is separated from the null as in the simple case of Neyman-Pearson. Another way of expressing this is to consider a sequence <span class="math inline">\(\theta_m \rightarrow \theta_0\)</span> as <span class="math inline">\(m \rightarrow \infty\)</span>, we have</p>
<p><span class="math display">\[
\alpha = \lim_{n \rightarrow \infty} \lim_{m \rightarrow \infty} \pi_n(\theta_m) \neq \lim_{m \rightarrow \infty} \lim_{n \rightarrow \infty} \pi_n(\theta_m) = 1.
\]</span></p>
<p>We have predicated our arguments so far on the case where <span class="math inline">\(\alpha\)</span> is fixed, i.e., the Type I error stays bounded away from zero, and have shown that the Type II error goes to zero with large sample size. We next show that actually one can make both Type I and Type II error go to zero simultaneously. That is, we construct a test for which <span class="math inline">\(\alpha_n(\theta) \rightarrow 0\)</span> for all <span class="math inline">\(\theta \in \Theta_0\)</span> and <span class="math inline">\(\beta_n(\theta) \rightarrow 0\)</span> for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
</section>
<section class="level3" id="example-12.22">
<h3 class="anchored" data-anchor-id="example-12.22">Example 12.22</h3>
<p>Suppose that <span class="math inline">\(X \sim N(\mu, 1)\)</span> and null hypothesis is <span class="math inline">\(\mu = 0\)</span> versus <span class="math inline">\(\mu &gt; 0\)</span>. Usually, we reject if <span class="math inline">\(\sqrt{n} X \geq z_{\alpha}\)</span> for some fixed <span class="math inline">\(\alpha\)</span>, but now we allow <span class="math inline">\(z_{\alpha} \rightarrow \infty\)</span>. We have rejection probability of <span class="math inline">\(\text{Pr}(Z \geq z_{\alpha} - \sqrt{n} \mu) \rightarrow 1\)</span> if and only if <span class="math inline">\(z_{\alpha} - \sqrt{n} \mu \rightarrow -\infty\)</span>, where <span class="math inline">\(Z \sim N(0, 1)\)</span>. Therefore, provided <span class="math inline">\(z_{\alpha} \rightarrow \infty\)</span> such that <span class="math inline">\(z_{\alpha} / \sqrt{n} \rightarrow 0\)</span>, the test will have zero Type I and Type II errors for fixed <span class="math inline">\(\mu\)</span>, asymptotically. There are many such values of <span class="math inline">\(z_{\alpha}\)</span> (and corresponding <span class="math inline">\(\alpha\)</span>) that satisfy this.</p>
</section>
<section class="level3" id="nonparametric-testing">
<h3 class="anchored" data-anchor-id="nonparametric-testing">12.4.3 Nonparametric Testing</h3>
<p>So far we have mostly focussed on the parametric case where a correctly specified model has been assumed. We now consider the nonparametric case where we do not specify the null or the alternative to be parametric.</p>
</section>
<section class="level3" id="example-12.23">
<h3 class="anchored" data-anchor-id="example-12.23">Example 12.23</h3>
<p>Suppose that <span class="math inline">\(X_i\)</span> are i.i.d. with distribution <span class="math inline">\(F\)</span> such that <span class="math inline">\(E(X^2) &lt; \infty\)</span>. We wish to test the hypothesis that <span class="math inline">\(\mu(F) = E(X) = 0\)</span> versus the alternative that <span class="math inline">\(\mu(F) &gt; 0\)</span>. The test statistic we consider is</p>
<p><span class="math display">\[
T = \dfrac{\sqrt{n} X}{s},
\]</span></p>
<p>which converges to a standard normal under the null hypothesis. Therefore, we can obtain</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \text{Pr}(T \geq z_{\alpha} | H_0) = \alpha.
\]</span></p>
<p>Furthermore, can show that</p>
<p><span class="math display">\[
\text{Pr}(T \geq z_{\alpha}) \rightarrow 1
\]</span></p>
<p>for any <span class="math inline">\(F\)</span> such that <span class="math inline">\(\mu(F) &gt; 0\)</span> and we may also derive the local power function for the test. Let <span class="math inline">\(\mu_n = \mu + c n^{-1/2}\)</span>, then the local power function is</p>
<p><span class="math display">\[
\pi_L(c; \alpha) = 1 - \Phi(z_{\alpha} - c / \sigma),
\]</span></p>
<p>where <span class="math inline">\(\sigma^2(F) = \text{var}(X)\)</span>.</p>
<p>We next consider an example of a <strong>specification test</strong>, where the null hypothesis is well defined but the alternative hypothesis is very general.</p>
</section>
<section class="level3" id="example-12.24">
<h3 class="anchored" data-anchor-id="example-12.24">Example 12.24</h3>
<p>Suppose that <span class="math inline">\(X_i\)</span> are i.i.d. discrete random variables with some discrete distribution <span class="math inline">\(F_X\)</span> such that <span class="math inline">\(E X^4 &lt; \infty\)</span> with <span class="math inline">\(\mu = E(X)\)</span>, <span class="math inline">\(\sigma^2 = \text{var}(X)\)</span>. We wish to test whether <span class="math inline">\(X\)</span> is Poisson distributed for some parameter <span class="math inline">\(\lambda \in R_+\)</span>. The alternative is that is not Poisson distributed. This is outside of the Likelihood framework because the alternative hypothesis here is any distribution excluding the Poisson. Both the null and the alternative are highly composite. A simple test can be based on comparison of the mean with the variance. Let</p>
<p><span class="math display">\[
T = \dfrac{\sqrt{n} (X - s^2)}{\hat{v}}
\]</span></p>
<p>where <span class="math inline">\(\hat{v}\)</span> is an estimate of the (asymptotic) variance <span class="math inline">\(v\)</span> of <span class="math inline">\(\sqrt{n} (X - s^2)\)</span>. In fact</p>
<p><span class="math display">\[
\begin{aligned}
\text{var} \left[ \sqrt{n} (X - s^2) \right] &amp;= \text{var} \left[ \dfrac{1}{\sqrt{n}} \sum_{i=1}^{n} \left( X_i - (X_i - X)^2 \right) \right] \\
&amp;= n \text{var}(X) + n \text{var}(s^2) - 2n \text{cov}(X, s^2) \\
&amp;= \sigma^2 + \sigma^4 (\kappa_4 + 2) - 2 \kappa_3 \sigma^3,
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\kappa_3\)</span> and <span class="math inline">\(\kappa_4\)</span> are the skewness and kurtosis of <span class="math inline">\(X\)</span>. The last line is an asymptotic approximation. If <span class="math inline">\(X\)</span> were Poisson <span class="math inline">\(\lambda\)</span>, then <span class="math inline">\(\mu = \sigma^2 = \lambda\)</span>, <span class="math inline">\(\kappa_3 = \lambda^{-1/2}\)</span>, and <span class="math inline">\(\kappa_4 = \lambda^{-1}\)</span>, so that <span class="math inline">\(v = \lambda + \lambda^2 (2 + \lambda^{-1}) - 2 \lambda^{3/2} \lambda^{-1/2} = 2 \lambda^2\)</span>. We may consider several candidates for <span class="math inline">\(\hat{v}\)</span></p>
<p><span class="math display">\[
\hat{v}_1 = 2 X^2; \quad \hat{v}_2 = 2 s^4; \quad \hat{v}_3 = \dfrac{1}{n} \sum_{i=1}^{n} (X_i - X)^4,
\]</span></p>
<p>where the first two exploit knowledge of the null distribution whereas the last just exploits the i.i.d. property. For any value <span class="math inline">\(\lambda\)</span> of the null hypothesis we have that <span class="math inline">\(T \xrightarrow{d} N(0, 1)\)</span>. This follows from some arguments we already gave for the sample mean and variance, namely</p>
<p><span class="math display">\[
\dfrac{1}{\sqrt{n}} \sum_{i=1}^{n} (X_i - X)^2 = \dfrac{1}{\sqrt{n}} \sum_{i=1}^{n} \{ X_i - (X_i - \mu)^2 \} - \sqrt{n} (X - \mu)^2,
\]</span></p>
<p>and applying the CLT to the standardized sum of <span class="math inline">\(Z_i = X_i - (X_i - \mu)^2\)</span>. The power of this test only depends to first order on the difference between the mean and the variance of <span class="math inline">\(X\)</span>. The test will have zero power against distributions that are not Poisson but for which <span class="math inline">\(\mu = \sigma^2\)</span>, so it is not a consistent test if we do not restrict the class of alternatives further. We consider local power. Suppose that we have a sequence of distributions such that <span class="math inline">\(E X^4 \leq C\)</span> and</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \sqrt{n} (\mu - \sigma^2) = c.
\]</span></p>
<p>Then for the test defined in (12.13), we have</p>
<p><span class="math display">\[
T \xrightarrow{d} N(m, w)
\]</span></p>
<p><span class="math display">\[
m = \dfrac{c}{\sqrt{v_{\infty}}}; \quad w = \dfrac{v}{v_{\infty}}
\]</span></p>
<p>where <span class="math inline">\(v_{\infty} = p \lim_{n \rightarrow \infty} \hat{v}\)</span>. The derivation is left as an exercise. Note that</p>
<p><span class="math display">\[
\begin{aligned}
p \lim_{n \rightarrow \infty} \hat{v}_1 &amp;= 2 \mu^2 = p \lim_{n \rightarrow \infty} \hat{v}_2 = 2 \sigma^4 \\
p \lim_{n \rightarrow \infty} \hat{v}_3 &amp;= \sigma^2 + \sigma^4 (\kappa_4 + 2) - 2 \kappa_3 \sigma^3.
\end{aligned}
\]</span></p>
<p>In the case where <span class="math inline">\(\kappa_3 = \kappa_4 = 0\)</span>, we have <span class="math inline">\(p \lim_{n \rightarrow \infty} \hat{v}_3 = \sigma^2 + 2 \sigma^4\)</span>, and in that case the local power function of <span class="math inline">\(\hat{v}_1, \hat{v}_2\)</span> dominates that of <span class="math inline">\(\hat{v}_3\)</span>. Note that if we consider a sequence of local alternatives where all moments converge to the corresponding Poisson ones, then the three normalizations yield the same local power function.</p>
<p>So far so good. The bad news is that in 1956, Bahadur and Savage proved that, in a nonparametric setting, it is impossible to construct a test about the value of the mean of a distribution that has size <span class="math inline">\(\alpha\)</span> and has power greater than <span class="math inline">\(\alpha\)</span> for even one distribution. Consider the example above where we test <span class="math inline">\(\mu(F) = 0\)</span> versus <span class="math inline">\(\mu(F) &gt; 0\)</span>. Let <span class="math inline">\(\mathcal{F}_0 = \{ F : \mu(F) = 0 \text{ and } \sigma^2(F) &lt; \infty \}\)</span> denote the set of distributions consistent with the null hypothesis. Correct size control here requires that we satisfy</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \sup_{F \in \mathcal{F}_0} \text{Pr}(T \geq z_{\alpha}) \leq \alpha.
\]</span></p>
<p>This is easy to accomplish if one doesn’t care about power - just use a random number generator for your test. However, if one wants to simultaneously achieve power <span class="math inline">\(&gt; \alpha\)</span> and even (12.12) for the test, then, as Bahadur and Savage (1956) show, this is not possible. The issue is that <span class="math inline">\(\mathcal{F}_0 = \{ F : \mu(F) = 0 \text{ and } \sigma^2(F) &lt; \infty \}\)</span> is a very big set that contains many distributions for which the CLT provides a poor approximation; indeed, one can find sequences <span class="math inline">\(\{ F_m \}_{m=1}^{\infty} \subset \mathcal{F}_0\)</span> such that the CLT breaks down either because <span class="math inline">\(\sigma^2(F_m)\)</span> gets too big or too small. Romano (2004) shows that the t-test achieves (12.14) and (12.12) when a restricted subset of <span class="math inline">\(\mathcal{F}_0\)</span> is considered. For example</p>
<p><span class="math display">\[
\mathcal{F}_{C, \delta} = \left\{ F : \mu(F) = 0, \sigma^2(F) &lt; \infty, \text{ and } E \left( \left| \dfrac{X - \mu(F)}{\sigma(F)} \right|^{2 + \delta} \right) \leq C \right\}
\]</span></p>
<p>for <span class="math inline">\(\delta &gt; 0\)</span> and <span class="math inline">\(C &lt; \infty\)</span> is such a class. Uniform size control requires us to be very pessimistic about the type of distributions we might face, as if nature is playing against us. Even the class of distributions <span class="math inline">\(\mathcal{F}_{C, \delta}\)</span> is very big and contains distributions that we don’t think are reasonable distributions for the data we have.</p>
</section>
</section>
<section class="level2" id="criticisms-of-the-standard-hypothesis-testing-approach">
<h2 class="anchored" data-anchor-id="criticisms-of-the-standard-hypothesis-testing-approach">12.5 CRITICISMS OF THE STANDARD HYPOTHESIS TESTING APPROACH</h2>
<p>We have taken the standard approach to hypothesis testing as given, but it is fair to say that it is one of the most controversial parts of the statistical canon.</p>
<ol type="1">
<li><p>It is very primitive decision-making. The outcome is only one of two things and doesn’t take account of the potentially different losses associated with the outcomes.</p></li>
<li><p>There is an asymmetric way in which the null hypothesis is treated versus the alternative. In some cases, such as testing the Efficient Markets Hypothesis we may feel comfortable with not specifying clearly what the alternative is and paying special attention to the null hypothesis, whereas in other contexts such as comparing the efficacy of alternative policies we may find this straightjacket uncomfortable.</p></li>
<li><p>Failure to reject the null hypothesis does not mean that it is true or even close to true. It may be that the test does not have power against the particular true hypothesis.</p></li>
<li><p>The significance level <span class="math inline">\(\alpha\)</span> is arbitrary. Some argue that <span class="math inline">\(\alpha\)</span> should be made a function of sample size, because in practice as <span class="math inline">\(n\)</span> gets large almost any hypothesis is rejected. In reality hypotheses are neighbourhoods not points. One can extend the usual theory to allow <span class="math inline">\(\Theta_0\)</span> to be an interval around some point <span class="math inline">\(\theta_0\)</span>, although it may be hard apriori to specify which interval.</p></li>
<li><p>A related criticism is that in many contexts we care about the economic significance of the departure from the null hypothesis. If the income difference between two groups is £10 per year, even if it is statistically significant based on large samples, then it is not so important. On the other hand if the difference were £100000 per year, even if the difference were not statistically significant, we would be paying attention to it.</p></li>
<li><p>In practice asymptotic approximations are often used and it may not be possible to control the size of the test.</p></li>
</ol>
<p>An approach that gives more information than the straight yes/no of a formal hypothesis test is to report the <strong>p-value</strong>. This scans through all the <span class="math inline">\(\alpha\)</span> and finds the marginal level for rejection.</p>
<section class="level3" id="definition-12.5">
<h3 class="anchored" data-anchor-id="definition-12.5">Definition 12.5</h3>
<p>Suppose that <span class="math inline">\(T\)</span> is a given test statistic. Then define the (one-sided) p-value</p>
<p><span class="math display">\[
p_{obs} = \text{Pr}(T \geq T_{obs} | H_0).
\]</span></p>
<p>In the two-sided case, we use the same definition with <span class="math inline">\(T \leftrightarrow |T|\)</span> and <span class="math inline">\(T_{obs} \leftrightarrow |T_{obs}|\)</span>.</p>
<p>Low <span class="math inline">\(p_{obs}\)</span> is evidence against the null hypothesis. More information is conveyed by this approach - the reader can decide on his or her own <span class="math inline">\(\alpha\)</span> and carry out the test. This just gives more information, but does not solve the conceptual issues around hypothesis testing. Apparently, p-values are widely abused and misused, Trafimow and Marks (2015). The American Statistical Association (2016) recently felt compelled to issue an edict on the matter in which they list six principles to guide empirical researchers:</p>
<ol type="1">
<li><p>P-values can indicate how incompatible the data are with a specified statistical model.</p></li>
<li><p>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.</p></li>
<li><p>Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.</p></li>
<li><p>Proper inference requires full reporting and transparency</p></li>
<li><p>A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.</p></li>
<li><p>By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.</p></li>
</ol>
<p>This seems like a good place to stop.</p>
</section>
</section>
<section class="level2" id="exercises">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<section class="level3" id="sec-ch12exercise1">
<h3 class="anchored" data-anchor-id="sec-ch12exercise1">Exercise 1</h3>
<p><a href="#sec-ch12solution1">Solution 1</a></p>
<p>Suppose you are testing the hypothesis that the average return of a particular stock is zero against the alternative that it is positive. You have a sample of 100 daily returns, and you assume that the returns are normally distributed with known variance <span class="math inline">\(\sigma^2 = 4\)</span>. Your null hypothesis is <span class="math inline">\(H_0: \mu = 0\)</span> and your alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; 0\)</span>. You decide to use a significance level of <span class="math inline">\(\alpha = 0.05\)</span>. Calculate the critical value for the test statistic <span class="math inline">\(T = \dfrac{\bar{X}}{\sigma / \sqrt{n}}\)</span>, where <span class="math inline">\(\bar{X}\)</span> is the sample mean of the returns.</p>
</section>
<section class="level3" id="sec-ch12exercise2">
<h3 class="anchored" data-anchor-id="sec-ch12exercise2">Exercise 2</h3>
<p><a href="#sec-ch12solution2">Solution 2</a></p>
<p>Consider a scenario where you are testing the effectiveness of a new drug. The null hypothesis <span class="math inline">\(H_0\)</span> is that the drug has no effect (<span class="math inline">\(\mu = 0\)</span>), and the alternative hypothesis <span class="math inline">\(H_1\)</span> is that the drug has a positive effect (<span class="math inline">\(\mu &gt; 0\)</span>). You have collected data from two groups: a control group (no drug) and a treatment group (with drug). Assuming the data are normally distributed with known variance <span class="math inline">\(\sigma^2 = 9\)</span> and the sample size for each group is 36, calculate the power of the test when the true mean effect of the drug is <span class="math inline">\(\mu = 1.5\)</span> and the significance level is <span class="math inline">\(\alpha = 0.01\)</span>.</p>
</section>
<section class="level3" id="sec-ch12exercise3">
<h3 class="anchored" data-anchor-id="sec-ch12exercise3">Exercise 3</h3>
<p><a href="#sec-ch12solution3">Solution 3</a></p>
<p>A researcher is investigating whether the average IQ of students in a particular university is different from the general population average of 100. The researcher collects a sample of 50 students and finds that the sample mean IQ is 105. Assume that the IQ scores are normally distributed with a known standard deviation of 15. The null hypothesis is <span class="math inline">\(H_0: \mu = 100\)</span>, and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq 100\)</span>. Calculate the p-value for this two-sided test.</p>
</section>
<section class="level3" id="sec-ch12exercise4">
<h3 class="anchored" data-anchor-id="sec-ch12exercise4">Exercise 4</h3>
<p><a href="#sec-ch12solution4">Solution 4</a></p>
<p>Suppose you are testing the null hypothesis <span class="math inline">\(H_0: \theta = \theta_0\)</span> against the alternative <span class="math inline">\(H_1: \theta \neq \theta_0\)</span> using the likelihood ratio test. Derive the general form of the likelihood ratio test statistic <span class="math inline">\(\lambda(X^n)\)</span> for a sample <span class="math inline">\(X^n = (X_1, X_2, \dots, X_n)\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2 = 1\)</span>.</p>
</section>
<section class="level3" id="sec-ch12exercise5">
<h3 class="anchored" data-anchor-id="sec-ch12exercise5">Exercise 5</h3>
<p><a href="#sec-ch12solution5">Solution 5</a></p>
<p>Consider a multiple testing scenario where you are testing 10 different null hypotheses simultaneously. Each test is conducted at a significance level of <span class="math inline">\(\alpha = 0.05\)</span>. Assuming the tests are independent, calculate the probability of making at least one Type I error (rejecting at least one true null hypothesis).</p>
</section>
<section class="level3" id="sec-ch12exercise6">
<h3 class="anchored" data-anchor-id="sec-ch12exercise6">Exercise 6</h3>
<p><a href="#sec-ch12solution6">Solution 6</a></p>
<p>You are given a sample of <span class="math inline">\(n\)</span> observations from a Bernoulli distribution with unknown parameter <span class="math inline">\(p\)</span>. The null hypothesis is <span class="math inline">\(H_0: p = 0.5\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: p \neq 0.5\)</span>. Derive the Wald test statistic for this hypothesis test.</p>
</section>
<section class="level3" id="sec-ch12exercise7">
<h3 class="anchored" data-anchor-id="sec-ch12exercise7">Exercise 7</h3>
<p><a href="#sec-ch12solution7">Solution 7</a></p>
<p>Explain the concept of a <strong>conservative test</strong> in the context of hypothesis testing. Provide an example where a test might be conservative.</p>
</section>
<section class="level3" id="sec-ch12exercise8">
<h3 class="anchored" data-anchor-id="sec-ch12exercise8">Exercise 8</h3>
<p><a href="#sec-ch12solution8">Solution 8</a></p>
<p>Suppose you have a sample of <span class="math inline">\(n\)</span> observations from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>. The null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>. Derive the expression for the power of the test, <span class="math inline">\(\pi_n(\mu)\)</span>, in terms of the standard normal cumulative distribution function <span class="math inline">\(\Phi\)</span>.</p>
</section>
<section class="level3" id="sec-ch12exercise9">
<h3 class="anchored" data-anchor-id="sec-ch12exercise9">Exercise 9</h3>
<p><a href="#sec-ch12solution9">Solution 9</a></p>
<p>Discuss the relationship between the <strong>significance level</strong> <span class="math inline">\(\alpha\)</span> of a test and the probability of making a Type I error. How does the choice of <span class="math inline">\(\alpha\)</span> affect the power of the test?</p>
</section>
<section class="level3" id="sec-ch12exercise10">
<h3 class="anchored" data-anchor-id="sec-ch12exercise10">Exercise 10</h3>
<p><a href="#sec-ch12solution10">Solution 10</a></p>
<p>Explain the concept of the <strong>least favorable case</strong> in the context of a composite null hypothesis. Provide an example to illustrate this concept.</p>
</section>
<section class="level3" id="sec-ch12exercise11">
<h3 class="anchored" data-anchor-id="sec-ch12exercise11">Exercise 11</h3>
<p><a href="#sec-ch12solution11">Solution 11</a></p>
<p>Suppose you are conducting a hypothesis test with a known null distribution. Explain how you would determine the <strong>critical region</strong> for a given significance level <span class="math inline">\(\alpha\)</span>. Provide an example using the standard normal distribution.</p>
</section>
<section class="level3" id="sec-ch12exercise12">
<h3 class="anchored" data-anchor-id="sec-ch12exercise12">Exercise 12</h3>
<p><a href="#sec-ch12solution12">Solution 12</a></p>
<p>In the context of the Neyman-Pearson lemma, explain the concept of a <strong>uniformly most powerful (UMP) test</strong>. Why is it not always possible to find a UMP test?</p>
</section>
<section class="level3" id="sec-ch12exercise13">
<h3 class="anchored" data-anchor-id="sec-ch12exercise13">Exercise 13</h3>
<p><a href="#sec-ch12solution13">Solution 13</a></p>
<p>Consider a hypothesis test where the null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>. Explain the concept of <strong>consistency</strong> of a test. What does it mean for a test to be consistent against a specific alternative?</p>
</section>
<section class="level3" id="sec-ch12exercise14">
<h3 class="anchored" data-anchor-id="sec-ch12exercise14">Exercise 14</h3>
<p><a href="#sec-ch12solution14">Solution 14</a></p>
<p>Explain the concept of <strong>Pitman alternatives</strong> in the context of hypothesis testing. How is the <strong>local power function</strong> related to Pitman alternatives?</p>
</section>
<section class="level3" id="sec-ch12exercise15">
<h3 class="anchored" data-anchor-id="sec-ch12exercise15">Exercise 15</h3>
<p><a href="#sec-ch12solution15">Solution 15</a></p>
<p>Discuss the criticisms of the standard hypothesis testing approach mentioned in the text. Provide an example where the standard approach might be inadequate or misleading.</p>
</section>
<section class="level3" id="sec-ch12exercise16">
<h3 class="anchored" data-anchor-id="sec-ch12exercise16">Exercise 16</h3>
<p><a href="#sec-ch12solution16">Solution 16</a></p>
<p>Suppose you are testing the null hypothesis that the average height of students in a university is 170 cm against the alternative that it is different from 170 cm. You collect a sample of 64 students and find the sample mean height to be 172 cm. Assume the heights are normally distributed with a known standard deviation of 8 cm. Calculate the test statistic <span class="math inline">\(T\)</span> and determine whether to reject the null hypothesis at a significance level of <span class="math inline">\(\alpha = 0.05\)</span>.</p>
</section>
<section class="level3" id="sec-ch12exercise17">
<h3 class="anchored" data-anchor-id="sec-ch12exercise17">Exercise 17</h3>
<p><a href="#sec-ch12solution17">Solution 17</a></p>
<p>Explain the difference between a <strong>simple hypothesis</strong> and a <strong>composite hypothesis</strong>. Provide an example of each.</p>
</section>
<section class="level3" id="sec-ch12exercise18">
<h3 class="anchored" data-anchor-id="sec-ch12exercise18">Exercise 18</h3>
<p><a href="#sec-ch12solution18">Solution 18</a></p>
<p>Consider a hypothesis test for the mean of a normal distribution with known variance. Explain how the power of the test is affected by the sample size <span class="math inline">\(n\)</span>.</p>
</section>
<section class="level3" id="sec-ch12exercise19">
<h3 class="anchored" data-anchor-id="sec-ch12exercise19">Exercise 19</h3>
<p><a href="#sec-ch12solution19">Solution 19</a></p>
<p>Suppose you are testing the null hypothesis <span class="math inline">\(H_0: p = p_0\)</span> against the alternative <span class="math inline">\(H_1: p &gt; p_0\)</span> for a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>. Derive the expression for the likelihood ratio test statistic.</p>
</section>
<section class="level3" id="sec-ch12exercise20">
<h3 class="anchored" data-anchor-id="sec-ch12exercise20">Exercise 20</h3>
<p><a href="#sec-ch12solution20">Solution 20</a></p>
<p>Describe the concept of a <strong>nonparametric test</strong>. Provide an example of a situation where a nonparametric test might be used.</p>
</section>
</section>
<section class="level2" id="solutions">
<h2 class="anchored" data-anchor-id="solutions">Solutions</h2>
<section class="level3" id="sec-ch12solution1">
<h3 class="anchored" data-anchor-id="sec-ch12solution1">Solution 1</h3>
<p><a href="#sec-ch12exercise1">Exercise 1</a></p>
<p>Given the null hypothesis <span class="math inline">\(H_0: \mu = 0\)</span> and the alternative hypothesis <span class="math inline">\(H_1: \mu &gt; 0\)</span>, we are conducting a one-sided hypothesis test. The test statistic is given by <span class="math inline">\(T = \dfrac{\bar{X}}{\sigma / \sqrt{n}}\)</span>. We are given that the returns are normally distributed with known variance <span class="math inline">\(\sigma^2 = 4\)</span>, so <span class="math inline">\(\sigma = 2\)</span>. The sample size is <span class="math inline">\(n = 100\)</span>, and the significance level is <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<p>Since the variance is known and the data are assumed to be normally distributed, we can use the standard normal distribution to find the critical value. For a one-sided test with <span class="math inline">\(\alpha = 0.05\)</span>, we need to find the value <span class="math inline">\(z_{\alpha}\)</span> such that <span class="math inline">\(\text{Pr}(Z &gt; z_{\alpha}) = 0.05\)</span>, where <span class="math inline">\(Z\)</span> is a standard normal random variable.</p>
<p>From the standard normal table or using a calculator, we find that <span class="math inline">\(z_{\alpha} = z_{0.05} \approx 1.645\)</span>. This is because the area to the right of 1.645 under the standard normal curve is approximately 0.05.</p>
<p>The critical value for the test statistic <span class="math inline">\(T\)</span> is given by <span class="math inline">\(z_{0.05} = 1.645\)</span>. We reject the null hypothesis if <span class="math inline">\(T &gt; 1.645\)</span>.</p>
<p>Intuitively, we are looking for a sample mean that is sufficiently larger than the hypothesized mean (0 in this case) to reject the null hypothesis. The critical value 1.645 represents the threshold beyond which we consider the sample mean to be significantly different from the hypothesized mean at the 0.05 significance level. The concepts used in this solution are the <strong>test statistic</strong>, <strong>significance level</strong>, <strong>critical value</strong>, and the <strong>standard normal distribution</strong> which are discussed in Section 12.2.</p>
</section>
<section class="level3" id="sec-ch12solution2">
<h3 class="anchored" data-anchor-id="sec-ch12solution2">Solution 2</h3>
<p><a href="#sec-ch12exercise2">Exercise 2</a></p>
<p>We are given the null hypothesis <span class="math inline">\(H_0: \mu = 0\)</span> and the alternative hypothesis <span class="math inline">\(H_1: \mu &gt; 0\)</span>. The data are assumed to be normally distributed with known variance <span class="math inline">\(\sigma^2 = 9\)</span>, so <span class="math inline">\(\sigma = 3\)</span>. The sample size for each group is <span class="math inline">\(n = 36\)</span>, and the significance level is <span class="math inline">\(\alpha = 0.01\)</span>. The true mean effect of the drug is <span class="math inline">\(\mu = 1.5\)</span>.</p>
<p>The test statistic is given by <span class="math inline">\(T = \dfrac{\bar{X}}{\sigma / \sqrt{n}}\)</span>, where <span class="math inline">\(\bar{X}\)</span> is the sample mean difference between the treatment and control groups. Under the null hypothesis, <span class="math inline">\(T \sim N(0, 1)\)</span>.</p>
<p>For a one-sided test with <span class="math inline">\(\alpha = 0.01\)</span>, we find the critical value <span class="math inline">\(z_{\alpha}\)</span> such that <span class="math inline">\(\text{Pr}(Z &gt; z_{\alpha}) = 0.01\)</span>. From the standard normal table or using a calculator, we find that <span class="math inline">\(z_{0.01} \approx 2.33\)</span>.</p>
<p>The power of the test is the probability of rejecting the null hypothesis when the alternative hypothesis is true. In this case, under the alternative hypothesis with <span class="math inline">\(\mu = 1.5\)</span>, the test statistic follows a normal distribution with mean <span class="math inline">\(\dfrac{1.5}{3 / \sqrt{36}} = \dfrac{1.5}{0.5} = 3\)</span> and variance 1. Thus, <span class="math inline">\(T \sim N(3, 1)\)</span> under <span class="math inline">\(H_1\)</span>.</p>
<p>The power of the test is given by:</p>
<p><span class="math display">\[
\begin{aligned}
\pi_n(\mu) &amp;= \text{Pr}(T &gt; z_{\alpha} | H_1) \\
&amp;= \text{Pr} \left( \dfrac{\bar{X} - \mu}{\sigma / \sqrt{n}} &gt; z_{\alpha} - \dfrac{\mu}{\sigma / \sqrt{n}} \bigg| H_1 \right) \\
&amp;= \text{Pr} \left( Z &gt; 2.33 - \dfrac{1.5}{3 / \sqrt{36}} \right) \\
&amp;= \text{Pr}(Z &gt; 2.33 - 3) \\
&amp;= \text{Pr}(Z &gt; -0.67) \\
&amp;= 1 - \text{Pr}(Z \leq -0.67) \\
&amp;\approx 1 - 0.2514 \\
&amp;\approx 0.7486
\end{aligned}
\]</span></p>
<p>Thus, the power of the test is approximately 0.7486.</p>
<p>Intuitively, the power of the test represents the probability that we correctly reject the null hypothesis when the true mean effect is 1.5. In this case, there is a 74.86<span class="math inline">\(\%\)</span> chance that we will detect the positive effect of the drug. The concepts used in this solution are the <strong>power of the test</strong>, <strong>test statistic</strong>, <strong>significance level</strong>, and <strong>critical value</strong>, as discussed in Sections 12.2 and 12.4.</p>
</section>
<section class="level3" id="sec-ch12solution3">
<h3 class="anchored" data-anchor-id="sec-ch12solution3">Solution 3</h3>
<p><a href="#sec-ch12exercise3">Exercise 3</a></p>
<p>The null hypothesis is <span class="math inline">\(H_0: \mu = 100\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq 100\)</span>. We have a sample of <span class="math inline">\(n = 50\)</span> students with a sample mean IQ of <span class="math inline">\(\bar{X} = 105\)</span>. The IQ scores are normally distributed with a known standard deviation <span class="math inline">\(\sigma = 15\)</span>.</p>
<p>The test statistic is given by <span class="math inline">\(T = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} = \dfrac{105 - 100}{15 / \sqrt{50}} \approx 2.357\)</span>.</p>
<p>Since this is a two-sided test, the p-value is the probability of observing a test statistic as extreme as or more extreme than the one calculated, in either direction, under the null hypothesis. In other words, the p-value is given by:</p>
<p><span class="math display">\[
\begin{aligned}
p\text{-value} &amp;= \text{Pr}(|T| &gt; 2.357) \\
&amp;= \text{Pr}(T &gt; 2.357) + \text{Pr}(T &lt; -2.357) \\
&amp;= 2 \times \text{Pr}(T &gt; 2.357)
\end{aligned}
\]</span></p>
<p>Using the standard normal distribution table or a calculator, we find that <span class="math inline">\(\text{Pr}(T &gt; 2.357) \approx 0.0092\)</span>. Therefore, the p-value is <span class="math inline">\(2 \times 0.0092 = 0.0184\)</span>.</p>
<p>Intuitively, the p-value represents the probability of observing a sample mean IQ as far from 100 as 105 (in either direction) if the true average IQ were 100. In this case, the p-value of 0.0184 suggests that there is a 1.84<span class="math inline">\(\%\)</span> chance of observing such a sample mean under the null hypothesis. The concepts used in this solution are the <strong>p-value</strong>, <strong>test statistic</strong>, and <strong>two-sided test</strong>, as discussed in Sections 12.2 and 12.5.</p>
</section>
<section class="level3" id="sec-ch12solution4">
<h3 class="anchored" data-anchor-id="sec-ch12solution4">Solution 4</h3>
<p><a href="#sec-ch12exercise4">Exercise 4</a></p>
<p>We are given a sample <span class="math inline">\(X^n = (X_1, X_2, \dots, X_n)\)</span> from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2 = 1\)</span>. The null hypothesis is <span class="math inline">\(H_0: \theta = \theta_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \theta \neq \theta_0\)</span>.</p>
<p>The likelihood function for a single observation <span class="math inline">\(X_i\)</span> is given by:</p>
<p><span class="math display">\[
L(\mu | X_i) = \dfrac{1}{\sqrt{2 \pi}} \exp \left( -\dfrac{(X_i - \mu)^2}{2} \right)
\]</span></p>
<p>The likelihood function for the sample <span class="math inline">\(X^n\)</span> is the product of the individual likelihoods:</p>
<p><span class="math display">\[
L(\mu | X^n) = \prod_{i=1}^{n} \dfrac{1}{\sqrt{2 \pi}} \exp \left( -\dfrac{(X_i - \mu)^2}{2} \right) = (2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \mu)^2 \right)
\]</span></p>
<p>Under the null hypothesis, <span class="math inline">\(\mu = \theta_0\)</span>, so the restricted likelihood is:</p>
<p><span class="math display">\[
L(\theta_0 | X^n) = (2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \theta_0)^2 \right)
\]</span></p>
<p>Under the alternative hypothesis, the maximum likelihood estimate of <span class="math inline">\(\mu\)</span> is the sample mean <span class="math inline">\(\bar{X} = \dfrac{1}{n} \sum_{i=1}^{n} X_i\)</span>. So the unrestricted likelihood is:</p>
<p><span class="math display">\[
L(\bar{X} | X^n) = (2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \bar{X})^2 \right)
\]</span></p>
<p>The likelihood ratio test statistic is given by:</p>
<p><span class="math display">\[
\begin{aligned}
\lambda(X^n) &amp;= \dfrac{\max_{\theta \in \Theta} L(\theta | X^n)}{\max_{\theta \in \Theta_0} L(\theta | X^n)} \\
&amp;= \dfrac{L(\bar{X} | X^n)}{L(\theta_0 | X^n)} \\
&amp;= \dfrac{(2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \bar{X})^2 \right)}{(2 \pi)^{-n/2} \exp \left( -\dfrac{1}{2} \sum_{i=1}^{n} (X_i - \theta_0)^2 \right)} \\
&amp;= \exp \left( \dfrac{1}{2} \sum_{i=1}^{n} (X_i - \theta_0)^2 - \dfrac{1}{2} \sum_{i=1}^{n} (X_i - \bar{X})^2 \right)
\end{aligned}
\]</span></p>
<p>Simplifying the exponent, we get:</p>
<p><span class="math display">\[
\lambda(X^n) = \exp \left( \dfrac{n}{2} (\bar{X} - \theta_0)^2 \right)
\]</span></p>
<p>Intuitively, the likelihood ratio test statistic compares the likelihood of the data under the null hypothesis to the likelihood of the data under the alternative hypothesis. In this case, it simplifies to a function of the squared difference between the sample mean and the hypothesized mean, scaled by the sample size. The concepts used in this solution are the <strong>likelihood function</strong>, <strong>likelihood ratio test statistic</strong>, <strong>restricted likelihood</strong>, and <strong>unrestricted likelihood</strong>, as discussed in Section 12.3.</p>
</section>
<section class="level3" id="sec-ch12solution5">
<h3 class="anchored" data-anchor-id="sec-ch12solution5">Solution 5</h3>
<p><a href="#sec-ch12exercise5">Exercise 5</a></p>
<p>We are conducting 10 different hypothesis tests simultaneously, each at a significance level of <span class="math inline">\(\alpha = 0.05\)</span>. We assume the tests are independent.</p>
<p>The probability of making a Type I error in a single test is <span class="math inline">\(\alpha = 0.05\)</span>. Therefore, the probability of not making a Type I error in a single test is <span class="math inline">\(1 - \alpha = 1 - 0.05 = 0.95\)</span>.</p>
<p>Since the tests are independent, the probability of not making a Type I error in any of the 10 tests is <span class="math inline">\((1 - \alpha)^{10} = (0.95)^{10} \approx 0.5987\)</span>.</p>
<p>The probability of making at least one Type I error is the complement of the probability of not making any Type I errors:</p>
<p><span class="math display">\[
\text{Pr(at least one Type I error)} = 1 - \text{Pr(no Type I errors)} = 1 - (1 - \alpha)^{10} = 1 - (0.95)^{10} \approx 1 - 0.5987 = 0.4013
\]</span></p>
<p>Therefore, the probability of making at least one Type I error when conducting 10 independent tests at a significance level of 0.05 is approximately 0.4013.</p>
<p>Intuitively, as the number of tests increases, the probability of making at least one Type I error also increases. This is because each test has a 0.05 probability of falsely rejecting the null hypothesis, and these probabilities accumulate over multiple tests. This is an example of the <strong>multiple testing issue</strong> discussed in Section 12.1. The concept used in this solution is <strong>Type I error</strong> which is discussed in Section 12.4.</p>
</section>
<section class="level3" id="sec-ch12solution6">
<h3 class="anchored" data-anchor-id="sec-ch12solution6">Solution 6</h3>
<p><a href="#sec-ch12exercise6">Exercise 6</a></p>
<p>We have a sample of <span class="math inline">\(n\)</span> observations from a Bernoulli distribution with unknown parameter <span class="math inline">\(p\)</span>. The null hypothesis is <span class="math inline">\(H_0: p = 0.5\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: p \neq 0.5\)</span>.</p>
<p>The Wald test statistic is based on the difference between the estimated parameter and the hypothesized value, standardized by the standard error of the estimate. For a Bernoulli distribution, the maximum likelihood estimate of <span class="math inline">\(p\)</span> is the sample proportion <span class="math inline">\(\hat{p} = \dfrac{1}{n} \sum_{i=1}^{n} X_i\)</span>, where <span class="math inline">\(X_i\)</span> is the outcome of the <span class="math inline">\(i\)</span>-th observation (0 or 1).</p>
<p>The variance of <span class="math inline">\(\hat{p}\)</span> is given by <span class="math inline">\(\dfrac{p(1-p)}{n}\)</span>. Under the null hypothesis, <span class="math inline">\(p = 0.5\)</span>, so the variance is <span class="math inline">\(\dfrac{0.5(1-0.5)}{n} = \dfrac{0.25}{n}\)</span>. The standard error of <span class="math inline">\(\hat{p}\)</span> is the square root of the variance, which is <span class="math inline">\(\sqrt{\dfrac{0.25}{n}} = \dfrac{0.5}{\sqrt{n}}\)</span>.</p>
<p>The Wald test statistic is given by:</p>
<p><span class="math display">\[
W = \dfrac{\hat{p} - p_0}{\sqrt{\dfrac{p_0(1-p_0)}{n}}}
\]</span></p>
<p>Under the null hypothesis <span class="math inline">\(H_0: p = 0.5\)</span>, the Wald test statistic is:</p>
<p><span class="math display">\[
W = \dfrac{\hat{p} - 0.5}{\sqrt{\dfrac{0.5(1-0.5)}{n}}} = \dfrac{\hat{p} - 0.5}{\dfrac{0.5}{\sqrt{n}}} = 2 \sqrt{n} (\hat{p} - 0.5)
\]</span></p>
<p>The Wald test statistic for this hypothesis test is <span class="math inline">\(W = 2 \sqrt{n} (\hat{p} - 0.5)\)</span>. Under the null hypothesis, <span class="math inline">\(W\)</span> follows approximately a standard normal distribution for large <span class="math inline">\(n\)</span>.</p>
<p>Intuitively, the Wald test statistic measures how far the estimated proportion is from the hypothesized proportion (0.5 in this case), in terms of standard errors. A large absolute value of the Wald statistic suggests that the estimated proportion is significantly different from the hypothesized value, leading to the rejection of the null hypothesis. The concept used in this solution is the <strong>Wald test</strong> which is discussed in Section 12.3.</p>
</section>
<section class="level3" id="sec-ch12solution7">
<h3 class="anchored" data-anchor-id="sec-ch12solution7">Solution 7</h3>
<p><a href="#sec-ch12exercise7">Exercise 7</a></p>
<p>A <strong>conservative test</strong> in the context of hypothesis testing is a test where the actual probability of making a Type I error is less than or equal to the stated significance level <span class="math inline">\(\alpha\)</span>. In other words, a conservative test is less likely to reject the null hypothesis than it should be, given the specified significance level.</p>
<p>Formally, a test is conservative if, for all <span class="math inline">\(\theta \in \Theta_0\)</span>,</p>
<p><span class="math display">\[
\text{Pr(reject } H_0 | \theta) \leq \alpha
\]</span></p>
<p>An example where a test might be conservative is when dealing with discrete data. Suppose we are testing the null hypothesis that the probability of success in a Bernoulli trial is <span class="math inline">\(p = p_0\)</span> against the alternative <span class="math inline">\(p &gt; p_0\)</span>. Due to the discrete nature of the data, we might not be able to find a critical value that corresponds exactly to the desired significance level <span class="math inline">\(\alpha\)</span>. In such cases, we might choose a critical value that results in a Type I error probability strictly less than <span class="math inline">\(\alpha\)</span>, making the test conservative.</p>
<p>Another example is when we have a composite null hypothesis, and the test is based on the least favorable case within the null hypothesis. This can lead to a conservative test because the actual Type I error probability for other parameter values in the null hypothesis might be lower than the significance level. This concept is discussed in Section 12.1.</p>
</section>
<section class="level3" id="sec-ch12solution8">
<h3 class="anchored" data-anchor-id="sec-ch12solution8">Solution 8</h3>
<p><a href="#sec-ch12exercise8">Exercise 8</a></p>
<p>We have a sample of <span class="math inline">\(n\)</span> observations from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>. The null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>.</p>
<p>The test statistic is given by <span class="math inline">\(T = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}\)</span>. Under the null hypothesis, <span class="math inline">\(T \sim N(0, 1)\)</span>.</p>
<p>For a given significance level <span class="math inline">\(\alpha\)</span>, we reject the null hypothesis if <span class="math inline">\(T &gt; z_{\alpha}\)</span>, where <span class="math inline">\(z_{\alpha}\)</span> is the critical value such that <span class="math inline">\(\text{Pr}(Z &gt; z_{\alpha}) = \alpha\)</span> for a standard normal random variable <span class="math inline">\(Z\)</span>.</p>
<p>The power of the test, <span class="math inline">\(\pi_n(\mu)\)</span>, is the probability of rejecting the null hypothesis when the alternative hypothesis is true, i.e., when <span class="math inline">\(\mu &gt; \mu_0\)</span>. Under the alternative hypothesis, <span class="math inline">\(T\)</span> follows a normal distribution with mean <span class="math inline">\(\dfrac{\mu - \mu_0}{\sigma / \sqrt{n}}\)</span> and variance 1.</p>
<p>The power of the test is given by:</p>
<p><span class="math display">\[
\begin{aligned}
\pi_n(\mu) &amp;= \text{Pr}(T &gt; z_{\alpha} | H_1) \\
&amp;= \text{Pr} \left( \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} &gt; z_{\alpha} \bigg| \mu &gt; \mu_0 \right) \\
&amp;= \text{Pr} \left( \dfrac{\bar{X} - \mu}{\sigma / \sqrt{n}} &gt; z_{\alpha} - \dfrac{\mu - \mu_0}{\sigma / \sqrt{n}} \bigg| \mu &gt; \mu_0 \right) \\
&amp;= \text{Pr} \left( Z &gt; z_{\alpha} - \dfrac{\sqrt{n} (\mu - \mu_0)}{\sigma} \right) \\
&amp;= 1 - \Phi \left( z_{\alpha} - \dfrac{\sqrt{n} (\mu - \mu_0)}{\sigma} \right)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\Phi\)</span> is the standard normal cumulative distribution function.</p>
<p>Thus, the expression for the power of the test is <span class="math inline">\(\pi_n(\mu) = 1 - \Phi \left( z_{\alpha} - \dfrac{\sqrt{n} (\mu - \mu_0)}{\sigma} \right)\)</span>.</p>
<p>Intuitively, the power of the test depends on the true mean <span class="math inline">\(\mu\)</span>, the sample size <span class="math inline">\(n\)</span>, the known standard deviation <span class="math inline">\(\sigma\)</span>, and the critical value <span class="math inline">\(z_{\alpha}\)</span>. As the difference between <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\mu_0\)</span> increases, or as the sample size <span class="math inline">\(n\)</span> increases, the power of the test increases. The concept used in this solution is the <strong>power of a test</strong> which is discussed in Section 12.4.</p>
</section>
<section class="level3" id="sec-ch12solution9">
<h3 class="anchored" data-anchor-id="sec-ch12solution9">Solution 9</h3>
<p><a href="#sec-ch12exercise9">Exercise 9</a></p>
<p>The <strong>significance level</strong> <span class="math inline">\(\alpha\)</span> of a test is the probability of making a Type I error, which is the probability of rejecting the null hypothesis when it is true. In other words, <span class="math inline">\(\alpha = \text{Pr(reject } H_0 | H_0 \text{ is true})\)</span>.</p>
<p>The choice of <span class="math inline">\(\alpha\)</span> directly affects the power of the test. The power of the test, denoted by <span class="math inline">\(\pi\)</span>, is the probability of rejecting the null hypothesis when it is false, i.e., <span class="math inline">\(\pi = \text{Pr(reject } H_0 | H_1 \text{ is true}) = 1 - \beta\)</span>, where <span class="math inline">\(\beta\)</span> is the probability of making a Type II error (failing to reject the null hypothesis when it is false).</p>
<p>There is a trade-off between <span class="math inline">\(\alpha\)</span> and the power of the test. Decreasing <span class="math inline">\(\alpha\)</span> (making the test more stringent) reduces the probability of making a Type I error but increases the probability of making a Type II error, thereby decreasing the power of the test. Conversely, increasing <span class="math inline">\(\alpha\)</span> increases the power of the test but also increases the probability of making a Type I error.</p>
<p>Intuitively, a smaller <span class="math inline">\(\alpha\)</span> means we require stronger evidence to reject the null hypothesis. This makes it less likely that we will reject a true null hypothesis (smaller Type I error), but it also makes it harder to reject a false null hypothesis (lower power). On the other hand, a larger <span class="math inline">\(\alpha\)</span> makes it easier to reject the null hypothesis, increasing the chance of rejecting a false null hypothesis (higher power) but also increasing the chance of rejecting a true null hypothesis (larger Type I error).</p>
<p>In practice, the choice of <span class="math inline">\(\alpha\)</span> depends on the specific context and the relative costs of making Type I and Type II errors. Common choices for <span class="math inline">\(\alpha\)</span> are 0.05 and 0.01, but other values may be appropriate depending on the situation. These concepts are discussed in Section 12.4.</p>
</section>
<section class="level3" id="sec-ch12solution10">
<h3 class="anchored" data-anchor-id="sec-ch12solution10">Solution 10</h3>
<p><a href="#sec-ch12exercise10">Exercise 10</a></p>
<p>The <strong>least favorable case</strong> in the context of a composite null hypothesis refers to the parameter value within the null hypothesis that makes it hardest to reject the null hypothesis. In other words, it is the parameter value in the null hypothesis set <span class="math inline">\(\Theta_0\)</span> that is closest to the alternative hypothesis set <span class="math inline">\(\Theta_1\)</span> in terms of the power of the test.</p>
<p>Formally, if we denote the power function of a test by <span class="math inline">\(\pi(\theta)\)</span>, the least favorable case <span class="math inline">\(\theta_{LFC}\)</span> is the value of <span class="math inline">\(\theta\)</span> in <span class="math inline">\(\Theta_0\)</span> that minimizes the power function over <span class="math inline">\(\Theta_0\)</span>:</p>
<p><span class="math display">\[
\theta_{LFC} = \arg \min_{\theta \in \Theta_0} \pi(\theta)
\]</span></p>
<p>An example to illustrate this concept is a one-sided test for the mean of a normal distribution. Suppose the null hypothesis is <span class="math inline">\(H_0: \mu \leq \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>. The power function <span class="math inline">\(\pi(\mu)\)</span> is an increasing function of <span class="math inline">\(\mu\)</span>. In this case, the least favorable case is <span class="math inline">\(\mu = \mu_0\)</span>, because this value is closest to the alternative hypothesis set (<span class="math inline">\(\mu &gt; \mu_0\)</span>) and results in the lowest power among all values in the null hypothesis set (<span class="math inline">\(\mu \leq \mu_0\)</span>).</p>
<p>Intuitively, the least favorable case represents the “boundary” between the null and alternative hypotheses. When designing a test for a composite null hypothesis, we often focus on the least favorable case because if the test has a certain size or power for the least favorable case, it will have at least that size or power for all other parameter values in the null hypothesis. This concept is discussed in Section 12.1.</p>
</section>
<section class="level3" id="sec-ch12solution11">
<h3 class="anchored" data-anchor-id="sec-ch12solution11">Solution 11</h3>
<p><a href="#sec-ch12exercise11">Exercise 11</a></p>
<p>When conducting a hypothesis test with a known null distribution, the <strong>critical region</strong> for a given significance level <span class="math inline">\(\alpha\)</span> is determined by finding the values of the test statistic that lead to the rejection of the null hypothesis. The critical region is chosen such that the probability of observing a test statistic in the critical region, when the null hypothesis is true, is equal to the significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>To determine the critical region, we first need to specify the test statistic and its distribution under the null hypothesis. Then, we find the critical values that divide the distribution into two regions: the acceptance region and the rejection region (critical region).</p>
<p>For a one-sided test with alternative hypothesis <span class="math inline">\(H_1: \theta &gt; \theta_0\)</span>, we reject the null hypothesis if the test statistic is too large. The critical value <span class="math inline">\(c\)</span> is chosen such that:</p>
<p><span class="math display">\[
\text{Pr}(T &gt; c | H_0) = \alpha
\]</span></p>
<p>where <span class="math inline">\(T\)</span> is the test statistic.</p>
<p>For a one-sided test with alternative hypothesis <span class="math inline">\(H_1: \theta &lt; \theta_0\)</span>, we reject the null hypothesis if the test statistic is too small. The critical value <span class="math inline">\(c\)</span> is chosen such that:</p>
<p><span class="math display">\[
\text{Pr}(T &lt; c | H_0) = \alpha
\]</span></p>
<p>For a two-sided test with alternative hypothesis <span class="math inline">\(H_1: \theta \neq \theta_0\)</span>, we reject the null hypothesis if the test statistic is either too large or too small. The critical values <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> are chosen such that:</p>
<p><span class="math display">\[
\text{Pr}(T &lt; c_1 | H_0) + \text{Pr}(T &gt; c_2 | H_0) = \alpha
\]</span></p>
<p>Usually, we choose <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> such that the two tail probabilities are equal, i.e., <span class="math inline">\(\text{Pr}(T &lt; c_1 | H_0) = \text{Pr}(T &gt; c_2 | H_0) = \alpha/2\)</span>.</p>
<p>As an example, consider a test for the mean of a standard normal distribution with known variance. The null hypothesis is <span class="math inline">\(H_0: \mu = 0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq 0\)</span>. The test statistic is <span class="math inline">\(T = \bar{X}\)</span>, which follows a standard normal distribution under the null hypothesis. For a significance level of <span class="math inline">\(\alpha = 0.05\)</span>, we want to find critical values <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> such that:</p>
<p><span class="math display">\[
\text{Pr}(T &lt; c_1 | H_0) = \text{Pr}(T &gt; c_2 | H_0) = 0.025
\]</span></p>
<p>Using the standard normal distribution table or a calculator, we find that <span class="math inline">\(c_1 = -1.96\)</span> and <span class="math inline">\(c_2 = 1.96\)</span>. Therefore, the critical region is <span class="math inline">\((-\infty, -1.96) \cup (1.96, \infty)\)</span>. We reject the null hypothesis if <span class="math inline">\(T &lt; -1.96\)</span> or <span class="math inline">\(T &gt; 1.96\)</span>.</p>
<p>Intuitively, the critical region represents the values of the test statistic that are considered extreme enough to reject the null hypothesis, given the chosen significance level. The concept of the <strong>critical region</strong> is discussed in Section 12.2.</p>
</section>
<section class="level3" id="sec-ch12solution12">
<h3 class="anchored" data-anchor-id="sec-ch12solution12">Solution 12</h3>
<p><a href="#sec-ch12exercise12">Exercise 12</a></p>
<p>In the context of the Neyman-Pearson lemma, a <strong>uniformly most powerful (UMP) test</strong> is a test that has the highest power among all possible tests of the same size <span class="math inline">\(\alpha\)</span> for all possible values of the parameter under the alternative hypothesis. In other words, a UMP test is a test that is simultaneously the most powerful test for every possible value in the alternative hypothesis set <span class="math inline">\(\Theta_1\)</span>.</p>
<p>Formally, a test with rejection region <span class="math inline">\(R\)</span> is a UMP test of size <span class="math inline">\(\alpha\)</span> if, for any other test with rejection region <span class="math inline">\(R'\)</span> such that <span class="math inline">\(\text{Pr(reject } H_0 | \theta) \leq \alpha\)</span> for all <span class="math inline">\(\theta \in \Theta_0\)</span>, we have:</p>
<p><span class="math display">\[
\text{Pr(reject } H_0 | \theta, \text{ using } R) \geq \text{Pr(reject } H_0 | \theta, \text{ using } R')
\]</span></p>
<p>for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
<p>It is not always possible to find a UMP test because the most powerful test for one value of the parameter in the alternative hypothesis set may not be the most powerful test for another value in the alternative hypothesis set. In other words, the form of the most powerful test may depend on the specific value of the parameter under the alternative hypothesis.</p>
<p>The Neyman-Pearson lemma provides a way to construct the most powerful test for a simple null hypothesis versus a simple alternative hypothesis. However, when the alternative hypothesis is composite, the likelihood ratio in the Neyman-Pearson lemma may depend on the specific value of the parameter under the alternative hypothesis, making it impossible to find a single rejection region that is most powerful for all possible values in the alternative hypothesis set.</p>
<p>For example, consider a two-sided test for the mean of a normal distribution with known variance. The null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>. For a specific value <span class="math inline">\(\mu_1 &gt; \mu_0\)</span>, the most powerful test is a one-sided test that rejects <span class="math inline">\(H_0\)</span> for large values of the sample mean <span class="math inline">\(\bar{X}\)</span>. However, for a specific value <span class="math inline">\(\mu_2 &lt; \mu_0\)</span>, the most powerful test is a one-sided test that rejects <span class="math inline">\(H_0\)</span> for small values of <span class="math inline">\(\bar{X}\)</span>. Thus, there is no single test that is most powerful for all possible values of <span class="math inline">\(\mu\)</span> under the alternative hypothesis, and a UMP test does not exist in this case.</p>
<p>Intuitively, a UMP test represents the best possible test in terms of power for a given significance level, regardless of the true value of the parameter under the alternative hypothesis. However, such a test often does not exist because the form of the optimal test depends on the specific value of the parameter under the alternative. These concepts are discussed in Section 12.4.1.</p>
</section>
<section class="level3" id="sec-ch12solution13">
<h3 class="anchored" data-anchor-id="sec-ch12solution13">Solution 13</h3>
<p><a href="#sec-ch12exercise13">Exercise 13</a></p>
<p><strong>Consistency</strong> of a test is a large-sample property that describes the behavior of the power of the test as the sample size <span class="math inline">\(n\)</span> approaches infinity. A test is said to be consistent if the power of the test approaches 1 as the sample size goes to infinity for all fixed alternatives in the alternative hypothesis set <span class="math inline">\(\Theta_1\)</span>. In other words, a consistent test is able to detect any fixed alternative with probability approaching 1 as the sample size increases.</p>
<p>Formally, a test with power function <span class="math inline">\(\pi_n(\theta)\)</span> is consistent if:</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \pi_n(\theta) = 1
\]</span></p>
<p>for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
<p>For a test to be consistent against a specific alternative <span class="math inline">\(\theta_1 \in \Theta_1\)</span>, it means that the power of the test against that specific alternative approaches 1 as the sample size goes to infinity:</p>
<p><span class="math display">\[
\lim_{n \rightarrow \infty} \pi_n(\theta_1) = 1
\]</span></p>
<p>Consider a hypothesis test where the null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>. A test is consistent against the alternative <span class="math inline">\(\mu_1 &gt; \mu_0\)</span> if the probability of rejecting the null hypothesis approaches 1 as the sample size increases, when the true mean is <span class="math inline">\(\mu_1\)</span>.</p>
<p>Intuitively, consistency means that as we collect more data, the test becomes increasingly able to detect any departure from the null hypothesis. A consistent test guarantees that we will eventually reject any false null hypothesis with probability 1 if we have a large enough sample size. This concept is discussed in Section 12.4.2.</p>
</section>
<section class="level3" id="sec-ch12solution14">
<h3 class="anchored" data-anchor-id="sec-ch12solution14">Solution 14</h3>
<p><a href="#sec-ch12exercise14">Exercise 14</a></p>
<p><strong>Pitman alternatives</strong> are a sequence of alternative hypotheses that approach the null hypothesis as the sample size <span class="math inline">\(n\)</span> goes to infinity. Specifically, Pitman alternatives are alternatives that are “close” to the null hypothesis, where the distance between the alternative and the null hypothesis decreases at a rate proportional to <span class="math inline">\(1/\sqrt{n}\)</span>.</p>
<p>Formally, consider a sequence of alternatives <span class="math inline">\(\theta_n\)</span> such that:</p>
<p><span class="math display">\[
\theta_n = \theta_0 + \dfrac{c}{\sqrt{n}}
\]</span></p>
<p>where <span class="math inline">\(\theta_0\)</span> is a value in the null hypothesis set <span class="math inline">\(\Theta_0\)</span> and <span class="math inline">\(c\)</span> is a constant. As <span class="math inline">\(n \rightarrow \infty\)</span>, <span class="math inline">\(\theta_n\)</span> approaches <span class="math inline">\(\theta_0\)</span>.</p>
<p>The <strong>local power function</strong> is the power of the test against Pitman alternatives. It describes the behavior of the power of the test for alternatives that are close to the null hypothesis. The local power function is often used to compare the performance of different tests in terms of their ability to detect small deviations from the null hypothesis.</p>
<p>Under certain regularity conditions, the local power function <span class="math inline">\(\pi_L(c; \alpha)\)</span> can be expressed as:</p>
<p><span class="math display">\[
\pi_L(c; \alpha) = \lim_{n \rightarrow \infty} \pi_n(\theta_n) = \lim_{n \rightarrow \infty} \pi_n \left( \theta_0 + \dfrac{c}{\sqrt{n}} \right)
\]</span></p>
<p>where <span class="math inline">\(\pi_n(\theta)\)</span> is the power function of the test.</p>
<p>The local power function depends on the constant <span class="math inline">\(c\)</span>, which represents the distance between the alternative and the null hypothesis in units of <span class="math inline">\(1/\sqrt{n}\)</span>, and the significance level <span class="math inline">\(\alpha\)</span>. It provides a way to approximate the power of the test for alternatives that are close to the null hypothesis and to compare the performance of different tests for such alternatives.</p>
<p>Intuitively, Pitman alternatives and the local power function allow us to study the behavior of the test when the true parameter value is close to the null hypothesis. This is important because it is often difficult to distinguish between the null and alternative hypotheses when the true parameter value is close to the boundary between the two hypotheses. By considering Pitman alternatives, we can analyze the power of the test in this difficult situation and compare the performance of different tests in terms of their ability to detect small deviations from the null hypothesis. These concepts are discussed in Section 12.4.2.</p>
</section>
<section class="level3" id="sec-ch12solution15">
<h3 class="anchored" data-anchor-id="sec-ch12solution15">Solution 15</h3>
<p><a href="#sec-ch12exercise15">Exercise 15</a></p>
<p>The standard hypothesis testing approach, while widely used, has several criticisms:</p>
<ol type="1">
<li><p><strong>Primitive decision-making</strong>: The outcome of a hypothesis test is binary (reject or fail to reject the null hypothesis), which does not take into account the potential losses associated with different outcomes or the magnitude of the effect.</p></li>
<li><p><strong>Asymmetric treatment of hypotheses</strong>: The null hypothesis is treated differently from the alternative hypothesis. The focus is on controlling the probability of rejecting the null hypothesis when it is true (Type I error), while the probability of failing to reject the null hypothesis when it is false (Type II error) is often not explicitly considered.</p></li>
<li><p><strong>Failure to reject does not imply the null is true</strong>: Failing to reject the null hypothesis does not mean that the null hypothesis is true or even close to true. It may simply mean that the test does not have enough power to detect the effect, especially if the sample size is small or the true effect is close to the null hypothesis.</p></li>
<li><p><strong>Arbitrary significance level</strong>: The choice of the significance level <span class="math inline">\(\alpha\)</span> is often arbitrary (e.g., 0.05 or 0.01) and may not be appropriate for all situations. Some argue that <span class="math inline">\(\alpha\)</span> should be a function of sample size, as large samples can lead to the rejection of the null hypothesis even when the effect is small and practically insignificant.</p></li>
<li><p><strong>Economic vs. statistical significance</strong>: In many contexts, we care about the economic significance of the departure from the null hypothesis, not just whether the difference is statistically significant. A statistically significant result may not be practically meaningful, while a non-statistically significant result may still be important from a practical perspective.</p></li>
<li><p><strong>Size control with approximations</strong>: In practice, asymptotic approximations are often used, and it may not be possible to control the size of the test exactly.</p></li>
</ol>
<p>An example where the standard approach might be inadequate or misleading is in testing the efficacy of a new drug. Suppose a pharmaceutical company is testing whether a new drug is more effective than an existing drug in treating a particular disease. The null hypothesis is that the new drug is equally effective as the existing drug, and the alternative hypothesis is that the new drug is more effective.</p>
<p>If the company fails to reject the null hypothesis, it does not mean that the new drug is not effective or that it is equivalent to the existing drug. It may simply mean that the sample size was too small to detect a difference or that the study was not designed to detect small but clinically meaningful differences.</p>
<p>Moreover, even if the company rejects the null hypothesis and finds a statistically significant difference in favor of the new drug, it does not necessarily mean that the new drug is clinically superior. The difference in efficacy might be very small and not practically meaningful, or the new drug might have more severe side effects that outweigh its benefits.</p>
<p>In this case, the standard hypothesis testing approach, with its focus on statistical significance and binary outcomes, may not provide enough information for decision-making. A more informative approach might involve estimating the magnitude of the difference in efficacy, along with its uncertainty, and considering the costs and benefits of the new drug compared to the existing drug. These concepts are discussed in Section 12.5.</p>
</section>
<section class="level3" id="sec-ch12solution16">
<h3 class="anchored" data-anchor-id="sec-ch12solution16">Solution 16</h3>
<p><a href="#sec-ch12exercise16">Exercise 16</a></p>
<p>The null hypothesis is <span class="math inline">\(H_0: \mu = 170\)</span> cm, and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq 170\)</span> cm. We have a sample of <span class="math inline">\(n = 64\)</span> students with a sample mean height of <span class="math inline">\(\bar{X} = 172\)</span> cm. The heights are assumed to be normally distributed with a known standard deviation of <span class="math inline">\(\sigma = 8\)</span> cm.</p>
<p>The test statistic is given by:</p>
<p><span class="math display">\[
T = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} = \dfrac{172 - 170}{8 / \sqrt{64}} = \dfrac{2}{1} = 2
\]</span></p>
<p>We are conducting a two-sided test with a significance level of <span class="math inline">\(\alpha = 0.05\)</span>. For a two-sided test, we need to find the critical values <span class="math inline">\(z_{\alpha/2}\)</span> such that <span class="math inline">\(\text{Pr}(|Z| &gt; z_{\alpha/2}) = \alpha\)</span>, where <span class="math inline">\(Z\)</span> is a standard normal random variable. In this case, <span class="math inline">\(\alpha/2 = 0.025\)</span>, and we find the critical value <span class="math inline">\(z_{0.025} \approx 1.96\)</span> from the standard normal table or using a calculator.</p>
<p>We reject the null hypothesis if <span class="math inline">\(|T| &gt; z_{\alpha/2}\)</span>, i.e., if <span class="math inline">\(|T| &gt; 1.96\)</span>. In this case, <span class="math inline">\(|T| = 2 &gt; 1.96\)</span>, so we reject the null hypothesis at the 0.05 significance level.</p>
<p>Intuitively, the sample mean height of 172 cm is sufficiently different from the hypothesized mean height of 170 cm to reject the null hypothesis at the 0.05 significance level. The test statistic of 2 indicates that the sample mean is 2 standard errors away from the hypothesized mean, which is considered statistically significant in this case. The concepts used in this solution are the <strong>test statistic</strong>, <strong>significance level</strong>, <strong>critical value</strong>, and <strong>two-sided test</strong>, as discussed in Section 12.2.</p>
</section>
<section class="level3" id="sec-ch12solution17">
<h3 class="anchored" data-anchor-id="sec-ch12solution17">Solution 17</h3>
<p><a href="#sec-ch12exercise17">Exercise 17</a></p>
<p>A <strong>simple hypothesis</strong> is a hypothesis that completely specifies the probability distribution of the data. In other words, under a simple hypothesis, there are no unknown parameters to be estimated.</p>
<p>An example of a simple hypothesis is testing whether a coin is fair. The null hypothesis is <span class="math inline">\(H_0: p = 0.5\)</span>, where <span class="math inline">\(p\)</span> is the probability of getting heads. Under this hypothesis, the distribution of the number of heads in <span class="math inline">\(n\)</span> tosses is a binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p = 0.5\)</span>, which is completely specified.</p>
<p>A <strong>composite hypothesis</strong> is a hypothesis that does not completely specify the probability distribution of the data. In other words, under a composite hypothesis, there are still unknown parameters to be estimated or a range of possible values for the parameters.</p>
<p>An example of a composite hypothesis is testing whether a coin is biased towards heads. The null hypothesis is <span class="math inline">\(H_0: p &gt; 0.5\)</span>. Under this hypothesis, the distribution of the number of heads in <span class="math inline">\(n\)</span> tosses is a binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, but the value of <span class="math inline">\(p\)</span> is not specified exactly, only that it is greater than 0.5.</p>
<p>Intuitively, a simple hypothesis is a specific statement about the data-generating process, while a composite hypothesis is a more general statement that allows for a range of possibilities. The distinction between simple and composite hypotheses is important because it affects the choice of test statistic and the calculation of the power of the test. These concepts are discussed in Section 12.1.</p>
</section>
<section class="level3" id="sec-ch12solution18">
<h3 class="anchored" data-anchor-id="sec-ch12solution18">Solution 18</h3>
<p><a href="#sec-ch12exercise18">Exercise 18</a></p>
<p>Consider a hypothesis test for the mean of a normal distribution with known variance <span class="math inline">\(\sigma^2\)</span>. The null hypothesis is <span class="math inline">\(H_0: \mu = \mu_0\)</span> and the alternative hypothesis is <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>. The test statistic is given by <span class="math inline">\(T = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}\)</span>, where <span class="math inline">\(\bar{X}\)</span> is the sample mean and <span class="math inline">\(n\)</span> is the sample size.</p>
<p>The power of the test is the probability of rejecting the null hypothesis when it is false, i.e., when <span class="math inline">\(\mu \neq \mu_0\)</span>. Under the alternative hypothesis, the test statistic <span class="math inline">\(T\)</span> follows a normal distribution with mean <span class="math inline">\(\dfrac{\mu - \mu_0}{\sigma / \sqrt{n}}\)</span> and variance 1.</p>
<p>For a two-sided test with significance level <span class="math inline">\(\alpha\)</span>, we reject the null hypothesis if <span class="math inline">\(|T| &gt; z_{\alpha/2}\)</span>, where <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution. The power of the test is given by:</p>
<p><span class="math display">\[
\pi_n(\mu) = \text{Pr} \left( \left| \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} \right| &gt; z_{\alpha/2} \bigg| \mu \neq \mu_0 \right)
\]</span></p>
<p>This can be rewritten as:</p>
<p><span class="math display">\[
\begin{aligned}
\pi_n(\mu) &amp;= 1 - \text{Pr} \left( -z_{\alpha/2} \leq \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} \leq z_{\alpha/2} \bigg| \mu \neq \mu_0 \right) \\
&amp;= 1 - \text{Pr} \left( -z_{\alpha/2} - \dfrac{\mu - \mu_0}{\sigma / \sqrt{n}} \leq \dfrac{\bar{X} - \mu}{\sigma / \sqrt{n}} \leq z_{\alpha/2} - \dfrac{\mu - \mu_0}{\sigma / \sqrt{n}} \bigg| \mu \neq \mu_0 \right) \\
&amp;= 1 - \left[ \Phi \left( z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right) - \Phi \left( -z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right) \right]
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\Phi\)</span> is the standard normal cumulative distribution function.</p>
<p>From the expression above, we can see that the power of the test is affected by the sample size <span class="math inline">\(n\)</span>. As <span class="math inline">\(n\)</span> increases, the term <span class="math inline">\(\dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma}\)</span> increases in magnitude. This causes the arguments of the <span class="math inline">\(\Phi\)</span> function to move further away from zero, either to the left or to the right, depending on the sign of <span class="math inline">\(\mu - \mu_0\)</span>.</p>
<p>If <span class="math inline">\(\mu &gt; \mu_0\)</span>, the term <span class="math inline">\(z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma}\)</span> decreases, and the term <span class="math inline">\(-z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma}\)</span> decreases. This causes <span class="math inline">\(\Phi \left( z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right)\)</span> to decrease and <span class="math inline">\(\Phi \left( -z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right)\)</span> to decrease, resulting in an increase in the power <span class="math inline">\(\pi_n(\mu)\)</span>.</p>
<p>If <span class="math inline">\(\mu &lt; \mu_0\)</span>, the term <span class="math inline">\(z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma}\)</span> increases, and the term <span class="math inline">\(-z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma}\)</span> increases. This causes <span class="math inline">\(\Phi \left( z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right)\)</span> to increase and <span class="math inline">\(\Phi \left( -z_{\alpha/2} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right)\)</span> to increase, resulting in an increase in the power <span class="math inline">\(\pi_n(\mu)\)</span>.</p>
<p>In both cases, as the sample size <span class="math inline">\(n\)</span> increases, the power of the test increases.</p>
<p>Intuitively, a larger sample size provides more information about the true value of the parameter, making it easier to detect deviations from the null hypothesis. As the sample size increases, the sampling distribution of the sample mean becomes more concentrated around the true mean, reducing the overlap between the distributions under the null and alternative hypotheses and increasing the power of the test. The concept used in this solution is the <strong>power of a test</strong> which is discussed in Section 12.4.</p>
</section>
<section class="level3" id="sec-ch12solution19">
<h3 class="anchored" data-anchor-id="sec-ch12solution19">Solution 19</h3>
<p><a href="#sec-ch12exercise19">Exercise 19</a></p>
<p>We are testing the null hypothesis <span class="math inline">\(H_0: p = p_0\)</span> against the alternative <span class="math inline">\(H_1: p &gt; p_0\)</span> for a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>. Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a sample of <span class="math inline">\(n\)</span> independent Bernoulli random variables.</p>
<p>The probability mass function for a single observation <span class="math inline">\(X_i\)</span> is given by:</p>
<p><span class="math display">\[
f(x_i | p) = p^{x_i} (1 - p)^{1 - x_i}, \quad x_i \in \{0, 1\}
\]</span></p>
<p>The likelihood function for the sample is the product of the individual probability mass functions:</p>
<p><span class="math display">\[
L(p | x_1, x_2, \dots, x_n) = \prod_{i=1}^{n} p^{x_i} (1 - p)^{1 - x_i} = p^{\sum x_i} (1 - p)^{n - \sum x_i}
\]</span></p>
<p>Under the null hypothesis, <span class="math inline">\(p = p_0\)</span>, so the restricted likelihood is:</p>
<p><span class="math display">\[
L(p_0 | x_1, x_2, \dots, x_n) = p_0^{\sum x_i} (1 - p_0)^{n - \sum x_i}
\]</span></p>
<p>Under the alternative hypothesis, the maximum likelihood estimate of <span class="math inline">\(p\)</span> is the sample proportion <span class="math inline">\(\hat{p} = \dfrac{1}{n} \sum_{i=1}^{n} x_i\)</span>. So the unrestricted likelihood is:</p>
<p><span class="math display">\[
L(\hat{p} | x_1, x_2, \dots, x_n) = \hat{p}^{\sum x_i} (1 - \hat{p})^{n - \sum x_i}
\]</span></p>
<p>The likelihood ratio test statistic is given by:</p>
<p><span class="math display">\[
\begin{aligned}
\lambda(x_1, x_2, \dots, x_n) &amp;= \dfrac{L(\hat{p} | x_1, x_2, \dots, x_n)}{L(p_0 | x_1, x_2, \dots, x_n)} \\
&amp;= \dfrac{\hat{p}^{\sum x_i} (1 - \hat{p})^{n - \sum x_i}}{p_0^{\sum x_i} (1 - p_0)^{n - \sum x_i}} \\
&amp;= \left( \dfrac{\hat{p}}{p_0} \right)^{\sum x_i} \left( \dfrac{1 - \hat{p}}{1 - p_0} \right)^{n - \sum x_i}
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(k = \sum_{i=1}^{n} x_i\)</span> be the number of successes in the sample. Then <span class="math inline">\(\hat{p} = \dfrac{k}{n}\)</span>, and the likelihood ratio test statistic can be written as:</p>
<p><span class="math display">\[
\lambda(x_1, x_2, \dots, x_n) = \left( \dfrac{k}{n p_0} \right)^k \left( \dfrac{1 - k/n}{1 - p_0} \right)^{n-k} = \left( \dfrac{k}{n p_0} \right)^k \left( \dfrac{n - k}{n (1 - p_0)} \right)^{n-k}
\]</span></p>
<p>For a one-sided test with <span class="math inline">\(H_1: p &gt; p_0\)</span>, we reject the null hypothesis for large values of <span class="math inline">\(\lambda\)</span>, which corresponds to large values of <span class="math inline">\(k\)</span>.</p>
<p>Intuitively, the likelihood ratio test statistic compares the likelihood of the observed data under the null hypothesis to the likelihood of the data under the alternative hypothesis. In this case, it is a function of the number of successes <span class="math inline">\(k\)</span> in the sample, the sample size <span class="math inline">\(n\)</span>, and the hypothesized value <span class="math inline">\(p_0\)</span>. The larger the value of <span class="math inline">\(k\)</span> relative to <span class="math inline">\(n p_0\)</span>, the stronger the evidence against the null hypothesis in favor of the alternative hypothesis <span class="math inline">\(p &gt; p_0\)</span>. This concept is discussed in Section 12.3.</p>
</section>
<section class="level3" id="sec-ch12solution20">
<h3 class="anchored" data-anchor-id="sec-ch12solution20">Solution 20</h3>
<p><a href="#sec-ch12exercise20">Exercise 20</a></p>
<p>A <strong>nonparametric test</strong> is a hypothesis test that does not make specific assumptions about the functional form of the underlying population distribution. In other words, nonparametric tests are distribution-free tests that do not rely on the assumption that the data follow a particular parametric family of distributions, such as the normal distribution.</p>
<p>Nonparametric tests are often used when the assumptions of parametric tests are not met, such as when the data are not normally distributed or when the sample size is small. They are also used when the data are measured on an ordinal scale, where the numerical values are not meaningful, but the order of the values is.</p>
<p>An example of a situation where a nonparametric test might be used is when comparing the effectiveness of two teaching methods based on students’ exam scores. Suppose we have exam scores from two groups of students, each taught using a different method. If the exam scores are not normally distributed, or if the sample sizes are small, the assumptions of a parametric test like the t-test might not be met. In this case, we could use a nonparametric test, such as the Mann-Whitney U test, to compare the two groups. The Mann-Whitney U test does not assume that the data follow a normal distribution; instead, it tests whether the probability that a randomly selected observation from one group is greater than a randomly selected observation from the other group is equal to 0.5.</p>
<p>Another example is when analyzing survey data measured on an ordinal scale. Suppose we have survey responses on a Likert scale (e.g., strongly disagree, disagree, neutral, agree, strongly agree) about customer satisfaction with a product. We want to test whether there is a difference in customer satisfaction between two different versions of the product. Since the Likert scale is ordinal, the numerical values are not meaningful, but the order is. In this case, we could use a nonparametric test, such as the Wilcoxon signed-rank test, to compare the two versions of the product. The Wilcoxon signed-rank test does not assume that the data follow a specific distribution; instead, it tests whether the median difference between paired observations is zero.</p>
<p>Intuitively, nonparametric tests are more flexible than parametric tests because they do not require specific distributional assumptions. However, they may be less powerful than parametric tests when the assumptions of the parametric tests are met. Nonparametric tests are based on ranks or signs of the data rather than the actual numerical values, which can result in some loss of information but makes the tests robust to outliers and non-normality. These concepts are discussed in Section 12.4.3.</p>
</section>
</section>
<section class="level2" id="r-script-examples">
<h2 class="anchored" data-anchor-id="r-script-examples">R Script Examples</h2>
<section class="level3" id="r-script-1-simulating-type-i-and-type-ii-errors">
<h3 class="anchored" data-anchor-id="r-script-1-simulating-type-i-and-type-ii-errors">R Script 1: Simulating Type I and Type II Errors</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a aria-hidden="true" href="#cb1-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1-2"><a aria-hidden="true" href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a aria-hidden="true" href="#cb3-1" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb3-2"><a aria-hidden="true" href="#cb3-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># Sample size</span></span>
<span id="cb3-3"><a aria-hidden="true" href="#cb3-3" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Null hypothesis mean</span></span>
<span id="cb3-4"><a aria-hidden="true" href="#cb3-4" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">15</span>  <span class="co"># Standard deviation</span></span>
<span id="cb3-5"><a aria-hidden="true" href="#cb3-5" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb3-6"><a aria-hidden="true" href="#cb3-6" tabindex="-1"></a>mu_a <span class="ot">&lt;-</span> <span class="dv">105</span>  <span class="co"># Alternative hypothesis mean (for Type II error simulation)</span></span>
<span id="cb3-7"><a aria-hidden="true" href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a aria-hidden="true" href="#cb3-8" tabindex="-1"></a><span class="co"># Calculate critical value</span></span>
<span id="cb3-9"><a aria-hidden="true" href="#cb3-9" tabindex="-1"></a>z_alpha <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb3-10"><a aria-hidden="true" href="#cb3-10" tabindex="-1"></a>critical_value <span class="ot">&lt;-</span> mu_0 <span class="sc">+</span> z_alpha <span class="sc">*</span> (sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n))</span>
<span id="cb3-11"><a aria-hidden="true" href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a aria-hidden="true" href="#cb3-12" tabindex="-1"></a><span class="co"># Number of simulations</span></span>
<span id="cb3-13"><a aria-hidden="true" href="#cb3-13" tabindex="-1"></a>num_sims <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb3-14"><a aria-hidden="true" href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a aria-hidden="true" href="#cb3-15" tabindex="-1"></a><span class="co"># Simulate Type I error</span></span>
<span id="cb3-16"><a aria-hidden="true" href="#cb3-16" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb3-17"><a aria-hidden="true" href="#cb3-17" tabindex="-1"></a>type_I_errors <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_sims, {</span>
<span id="cb3-18"><a aria-hidden="true" href="#cb3-18" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu_0, <span class="at">sd =</span> sigma)</span>
<span id="cb3-19"><a aria-hidden="true" href="#cb3-19" tabindex="-1"></a>  sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample)</span>
<span id="cb3-20"><a aria-hidden="true" href="#cb3-20" tabindex="-1"></a>  reject_null <span class="ot">&lt;-</span> sample_mean <span class="sc">&gt;</span> critical_value</span>
<span id="cb3-21"><a aria-hidden="true" href="#cb3-21" tabindex="-1"></a>  reject_null</span>
<span id="cb3-22"><a aria-hidden="true" href="#cb3-22" tabindex="-1"></a>})</span>
<span id="cb3-23"><a aria-hidden="true" href="#cb3-23" tabindex="-1"></a></span>
<span id="cb3-24"><a aria-hidden="true" href="#cb3-24" tabindex="-1"></a><span class="co"># Calculate Type I error rate</span></span>
<span id="cb3-25"><a aria-hidden="true" href="#cb3-25" tabindex="-1"></a>type_I_error_rate <span class="ot">&lt;-</span> <span class="fu">sum</span>(type_I_errors) <span class="sc">/</span> num_sims</span>
<span id="cb3-26"><a aria-hidden="true" href="#cb3-26" tabindex="-1"></a></span>
<span id="cb3-27"><a aria-hidden="true" href="#cb3-27" tabindex="-1"></a><span class="co"># Simulate Type II error</span></span>
<span id="cb3-28"><a aria-hidden="true" href="#cb3-28" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb3-29"><a aria-hidden="true" href="#cb3-29" tabindex="-1"></a>type_II_errors <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_sims, {</span>
<span id="cb3-30"><a aria-hidden="true" href="#cb3-30" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu_a, <span class="at">sd =</span> sigma)</span>
<span id="cb3-31"><a aria-hidden="true" href="#cb3-31" tabindex="-1"></a>  sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample)</span>
<span id="cb3-32"><a aria-hidden="true" href="#cb3-32" tabindex="-1"></a>  accept_null <span class="ot">&lt;-</span> sample_mean <span class="sc">&lt;=</span> critical_value</span>
<span id="cb3-33"><a aria-hidden="true" href="#cb3-33" tabindex="-1"></a>  accept_null</span>
<span id="cb3-34"><a aria-hidden="true" href="#cb3-34" tabindex="-1"></a>})</span>
<span id="cb3-35"><a aria-hidden="true" href="#cb3-35" tabindex="-1"></a></span>
<span id="cb3-36"><a aria-hidden="true" href="#cb3-36" tabindex="-1"></a><span class="co"># Calculate Type II error rate</span></span>
<span id="cb3-37"><a aria-hidden="true" href="#cb3-37" tabindex="-1"></a>type_II_error_rate <span class="ot">&lt;-</span> <span class="fu">sum</span>(type_II_errors) <span class="sc">/</span> num_sims</span>
<span id="cb3-38"><a aria-hidden="true" href="#cb3-38" tabindex="-1"></a></span>
<span id="cb3-39"><a aria-hidden="true" href="#cb3-39" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb3-40"><a aria-hidden="true" href="#cb3-40" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Type I error rate:"</span>, type_I_error_rate, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type I error rate: 0.0482 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a aria-hidden="true" href="#cb5-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Type II error rate:"</span>, type_II_error_rate, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type II error rate: 0.4254 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a aria-hidden="true" href="#cb7-1" tabindex="-1"></a><span class="co"># Visualization of Type I and Type II errors</span></span>
<span id="cb7-2"><a aria-hidden="true" href="#cb7-2" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">90</span>, <span class="dv">120</span>, <span class="at">by =</span> <span class="fl">0.1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb7-3"><a aria-hidden="true" href="#cb7-3" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb7-4"><a aria-hidden="true" href="#cb7-4" tabindex="-1"></a>    <span class="at">density_null =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu_0, <span class="at">sd =</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)),</span>
<span id="cb7-5"><a aria-hidden="true" href="#cb7-5" tabindex="-1"></a>    <span class="at">density_alt =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu_a, <span class="at">sd =</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n))</span>
<span id="cb7-6"><a aria-hidden="true" href="#cb7-6" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb7-7"><a aria-hidden="true" href="#cb7-7" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb7-8"><a aria-hidden="true" href="#cb7-8" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> density_null), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb7-9"><a aria-hidden="true" href="#cb7-9" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> density_alt), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb7-10"><a aria-hidden="true" href="#cb7-10" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> critical_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb7-11"><a aria-hidden="true" href="#cb7-11" tabindex="-1"></a>  <span class="fu">annotate</span>(</span>
<span id="cb7-12"><a aria-hidden="true" href="#cb7-12" tabindex="-1"></a>    <span class="st">"rect"</span>,</span>
<span id="cb7-13"><a aria-hidden="true" href="#cb7-13" tabindex="-1"></a>    <span class="at">xmin =</span> critical_value,</span>
<span id="cb7-14"><a aria-hidden="true" href="#cb7-14" tabindex="-1"></a>    <span class="at">xmax =</span> <span class="cn">Inf</span>,</span>
<span id="cb7-15"><a aria-hidden="true" href="#cb7-15" tabindex="-1"></a>    <span class="at">ymin =</span> <span class="dv">0</span>,</span>
<span id="cb7-16"><a aria-hidden="true" href="#cb7-16" tabindex="-1"></a>    <span class="at">ymax =</span> <span class="cn">Inf</span>,</span>
<span id="cb7-17"><a aria-hidden="true" href="#cb7-17" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.2</span>,</span>
<span id="cb7-18"><a aria-hidden="true" href="#cb7-18" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"blue"</span></span>
<span id="cb7-19"><a aria-hidden="true" href="#cb7-19" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-20"><a aria-hidden="true" href="#cb7-20" tabindex="-1"></a>  <span class="fu">annotate</span>(</span>
<span id="cb7-21"><a aria-hidden="true" href="#cb7-21" tabindex="-1"></a>    <span class="st">"rect"</span>,</span>
<span id="cb7-22"><a aria-hidden="true" href="#cb7-22" tabindex="-1"></a>    <span class="at">xmin =</span> <span class="sc">-</span><span class="cn">Inf</span>,</span>
<span id="cb7-23"><a aria-hidden="true" href="#cb7-23" tabindex="-1"></a>    <span class="at">xmax =</span> critical_value,</span>
<span id="cb7-24"><a aria-hidden="true" href="#cb7-24" tabindex="-1"></a>    <span class="at">ymin =</span> <span class="dv">0</span>,</span>
<span id="cb7-25"><a aria-hidden="true" href="#cb7-25" tabindex="-1"></a>    <span class="at">ymax =</span> <span class="cn">Inf</span>,</span>
<span id="cb7-26"><a aria-hidden="true" href="#cb7-26" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.2</span>,</span>
<span id="cb7-27"><a aria-hidden="true" href="#cb7-27" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"red"</span></span>
<span id="cb7-28"><a aria-hidden="true" href="#cb7-28" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-29"><a aria-hidden="true" href="#cb7-29" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mu_0 <span class="sc">+</span> <span class="dv">3</span>, <span class="at">y =</span> <span class="fl">0.1</span>, <span class="at">label =</span> <span class="st">"Type I error"</span>, <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb7-30"><a aria-hidden="true" href="#cb7-30" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mu_a <span class="sc">-</span> <span class="dv">3</span>, <span class="at">y =</span> <span class="fl">0.05</span>, <span class="at">label =</span> <span class="st">"Type II error"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb7-31"><a aria-hidden="true" href="#cb7-31" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-32"><a aria-hidden="true" href="#cb7-32" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Visualization of Type I and Type II Errors"</span>,</span>
<span id="cb7-33"><a aria-hidden="true" href="#cb7-33" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample Mean"</span>,</span>
<span id="cb7-34"><a aria-hidden="true" href="#cb7-34" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb7-35"><a aria-hidden="true" href="#cb7-35" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-36"><a aria-hidden="true" href="#cb7-36" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap12_files/figure-html/unnamed-chunk-1-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Explanation:</strong></p>
<p>This script simulates and visualizes <strong>Type I</strong> and <strong>Type II errors</strong> in hypothesis testing.</p>
<ol type="1">
<li><strong>Setup:</strong>
<ul>
<li>Loads the <code>tidyverse</code> library for data manipulation and visualization.</li>
<li>Sets parameters for the simulation: sample size (<code>n</code>), null hypothesis mean (<code>mu_0</code>), standard deviation (<code>sigma</code>), significance level (<code>alpha</code>), and alternative hypothesis mean (<code>mu_a</code>).</li>
<li>Calculates the critical value based on the significance level and the standard normal distribution.</li>
</ul></li>
<li><strong>Type I Error Simulation:</strong>
<ul>
<li>Repeats the simulation <code>num_sims</code> times.</li>
<li>Generates a sample of size <code>n</code> from a normal distribution with mean <code>mu_0</code> and standard deviation <code>sigma</code>.</li>
<li>Calculates the sample mean.</li>
<li>Determines whether to reject the null hypothesis based on whether the sample mean exceeds the critical value.</li>
<li>Stores the result (reject or not reject) in the <code>type_I_errors</code> vector.</li>
</ul></li>
<li><strong>Type I Error Rate Calculation:</strong>
<ul>
<li>Calculates the proportion of simulations where the null hypothesis was rejected, which is the estimated Type I error rate.</li>
</ul></li>
<li><strong>Type II Error Simulation:</strong>
<ul>
<li>Repeats the simulation <code>num_sims</code> times.</li>
<li>Generates a sample of size <code>n</code> from a normal distribution with mean <code>mu_a</code> (the alternative hypothesis mean) and standard deviation <code>sigma</code>.</li>
<li>Calculates the sample mean.</li>
<li>Determines whether to accept the null hypothesis based on whether the sample mean is less than or equal to the critical value.</li>
<li>Stores the result (accept or not accept) in the <code>type_II_errors</code> vector.</li>
</ul></li>
<li><strong>Type II Error Rate Calculation:</strong>
<ul>
<li>Calculates the proportion of simulations where the null hypothesis was accepted, which is the estimated Type II error rate.</li>
</ul></li>
<li><strong>Print Results:</strong>
<ul>
<li>Prints the estimated Type I and Type II error rates.</li>
</ul></li>
<li><strong>Visualization:</strong>
<ul>
<li>Creates a plot showing the probability density functions of the sample mean under the null and alternative hypotheses.</li>
<li>Adds a vertical line at the critical value.</li>
<li>Shades the area representing the Type I error (rejecting the null hypothesis when it is true) in blue.</li>
<li>Shades the area representing the Type II error (accepting the null hypothesis when it is false) in red.</li>
</ul></li>
</ol>
<p><strong>Concepts from the Text:</strong></p>
<p>This script illustrates several concepts from the text:</p>
<ul>
<li><strong>Type I error</strong> (Section 12.4): The probability of rejecting the null hypothesis when it is true.</li>
<li><strong>Type II error</strong> (Section 12.4): The probability of accepting the null hypothesis when it is false.</li>
<li><strong>Significance level</strong> (Sections 12.2, 12.4): The probability of making a Type I error, denoted by <span class="math inline">\(\alpha\)</span>.</li>
<li><strong>Critical value</strong> (Section 12.2): The value of the test statistic that separates the rejection region from the acceptance region.</li>
<li><strong>Power of a test</strong> (Section 12.4): The probability of rejecting the null hypothesis when it is false (1 - Type II error rate).</li>
</ul>
</section>
<section class="level3" id="r-script-2-likelihood-ratio-test-for-a-normal-mean">
<h3 class="anchored" data-anchor-id="r-script-2-likelihood-ratio-test-for-a-normal-mean">R Script 2: Likelihood Ratio Test for a Normal Mean</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a aria-hidden="true" href="#cb8-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb8-2"><a aria-hidden="true" href="#cb8-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb8-3"><a aria-hidden="true" href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a aria-hidden="true" href="#cb8-4" tabindex="-1"></a><span class="co"># Function to calculate the likelihood ratio test statistic</span></span>
<span id="cb8-5"><a aria-hidden="true" href="#cb8-5" tabindex="-1"></a>likelihood_ratio_test <span class="ot">&lt;-</span> <span class="cf">function</span>(data, mu_0) {</span>
<span id="cb8-6"><a aria-hidden="true" href="#cb8-6" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb8-7"><a aria-hidden="true" href="#cb8-7" tabindex="-1"></a>  sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(data)</span>
<span id="cb8-8"><a aria-hidden="true" href="#cb8-8" tabindex="-1"></a>  </span>
<span id="cb8-9"><a aria-hidden="true" href="#cb8-9" tabindex="-1"></a>  <span class="co"># Calculate the log-likelihood under the null hypothesis</span></span>
<span id="cb8-10"><a aria-hidden="true" href="#cb8-10" tabindex="-1"></a>  log_likelihood_null <span class="ot">&lt;-</span> <span class="sc">-</span>n <span class="sc">/</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> pi) <span class="sc">-</span> n <span class="sc">/</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span>) <span class="sc">-</span> </span>
<span id="cb8-11"><a aria-hidden="true" href="#cb8-11" tabindex="-1"></a>    <span class="fu">sum</span>((data <span class="sc">-</span> mu_0)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb8-12"><a aria-hidden="true" href="#cb8-12" tabindex="-1"></a>  </span>
<span id="cb8-13"><a aria-hidden="true" href="#cb8-13" tabindex="-1"></a>  <span class="co"># Calculate the log-likelihood under the alternative hypothesis</span></span>
<span id="cb8-14"><a aria-hidden="true" href="#cb8-14" tabindex="-1"></a>  log_likelihood_alt <span class="ot">&lt;-</span> <span class="sc">-</span>n <span class="sc">/</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> pi) <span class="sc">-</span> n <span class="sc">/</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span>) <span class="sc">-</span> </span>
<span id="cb8-15"><a aria-hidden="true" href="#cb8-15" tabindex="-1"></a>    <span class="fu">sum</span>((data <span class="sc">-</span> sample_mean)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb8-16"><a aria-hidden="true" href="#cb8-16" tabindex="-1"></a>  </span>
<span id="cb8-17"><a aria-hidden="true" href="#cb8-17" tabindex="-1"></a>  <span class="co"># Calculate the likelihood ratio test statistic</span></span>
<span id="cb8-18"><a aria-hidden="true" href="#cb8-18" tabindex="-1"></a>  lambda <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (log_likelihood_alt <span class="sc">-</span> log_likelihood_null)</span>
<span id="cb8-19"><a aria-hidden="true" href="#cb8-19" tabindex="-1"></a>  </span>
<span id="cb8-20"><a aria-hidden="true" href="#cb8-20" tabindex="-1"></a>  <span class="fu">return</span>(lambda)</span>
<span id="cb8-21"><a aria-hidden="true" href="#cb8-21" tabindex="-1"></a>}</span>
<span id="cb8-22"><a aria-hidden="true" href="#cb8-22" tabindex="-1"></a></span>
<span id="cb8-23"><a aria-hidden="true" href="#cb8-23" tabindex="-1"></a><span class="co"># Generate sample data</span></span>
<span id="cb8-24"><a aria-hidden="true" href="#cb8-24" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb8-25"><a aria-hidden="true" href="#cb8-25" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb8-26"><a aria-hidden="true" href="#cb8-26" tabindex="-1"></a>mu_true <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb8-27"><a aria-hidden="true" href="#cb8-27" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb8-28"><a aria-hidden="true" href="#cb8-28" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu_true, <span class="at">sd =</span> sigma)</span>
<span id="cb8-29"><a aria-hidden="true" href="#cb8-29" tabindex="-1"></a></span>
<span id="cb8-30"><a aria-hidden="true" href="#cb8-30" tabindex="-1"></a><span class="co"># Hypothesized value under the null hypothesis</span></span>
<span id="cb8-31"><a aria-hidden="true" href="#cb8-31" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb8-32"><a aria-hidden="true" href="#cb8-32" tabindex="-1"></a></span>
<span id="cb8-33"><a aria-hidden="true" href="#cb8-33" tabindex="-1"></a><span class="co"># Calculate the likelihood ratio test statistic</span></span>
<span id="cb8-34"><a aria-hidden="true" href="#cb8-34" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">likelihood_ratio_test</span>(data, mu_0)</span>
<span id="cb8-35"><a aria-hidden="true" href="#cb8-35" tabindex="-1"></a></span>
<span id="cb8-36"><a aria-hidden="true" href="#cb8-36" tabindex="-1"></a><span class="co"># Calculate the p-value</span></span>
<span id="cb8-37"><a aria-hidden="true" href="#cb8-37" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(lambda, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb8-38"><a aria-hidden="true" href="#cb8-38" tabindex="-1"></a></span>
<span id="cb8-39"><a aria-hidden="true" href="#cb8-39" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb8-40"><a aria-hidden="true" href="#cb8-40" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Likelihood ratio test statistic:"</span>, lambda, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Likelihood ratio test statistic: 24.6138 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a aria-hidden="true" href="#cb10-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"P-value:"</span>, p_value, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>P-value: 7.004827e-07 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a aria-hidden="true" href="#cb12-1" tabindex="-1"></a><span class="co"># Visualization of the chi-squared distribution</span></span>
<span id="cb12-2"><a aria-hidden="true" href="#cb12-2" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb12-3"><a aria-hidden="true" href="#cb12-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">density =</span> <span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb12-4"><a aria-hidden="true" href="#cb12-4" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> density)) <span class="sc">+</span></span>
<span id="cb12-5"><a aria-hidden="true" href="#cb12-5" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb12-6"><a aria-hidden="true" href="#cb12-6" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> lambda, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a aria-hidden="true" href="#cb12-7" tabindex="-1"></a>  <span class="fu">annotate</span>(</span>
<span id="cb12-8"><a aria-hidden="true" href="#cb12-8" tabindex="-1"></a>    <span class="st">"rect"</span>,</span>
<span id="cb12-9"><a aria-hidden="true" href="#cb12-9" tabindex="-1"></a>    <span class="at">xmin =</span> lambda,</span>
<span id="cb12-10"><a aria-hidden="true" href="#cb12-10" tabindex="-1"></a>    <span class="at">xmax =</span> <span class="cn">Inf</span>,</span>
<span id="cb12-11"><a aria-hidden="true" href="#cb12-11" tabindex="-1"></a>    <span class="at">ymin =</span> <span class="dv">0</span>,</span>
<span id="cb12-12"><a aria-hidden="true" href="#cb12-12" tabindex="-1"></a>    <span class="at">ymax =</span> <span class="cn">Inf</span>,</span>
<span id="cb12-13"><a aria-hidden="true" href="#cb12-13" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.2</span>,</span>
<span id="cb12-14"><a aria-hidden="true" href="#cb12-14" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"red"</span></span>
<span id="cb12-15"><a aria-hidden="true" href="#cb12-15" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-16"><a aria-hidden="true" href="#cb12-16" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-17"><a aria-hidden="true" href="#cb12-17" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Chi-squared Distribution with Likelihood Ratio Test Statistic"</span>,</span>
<span id="cb12-18"><a aria-hidden="true" href="#cb12-18" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Chi-squared Value"</span>,</span>
<span id="cb12-19"><a aria-hidden="true" href="#cb12-19" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb12-20"><a aria-hidden="true" href="#cb12-20" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-21"><a aria-hidden="true" href="#cb12-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap12_files/figure-html/unnamed-chunk-2-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Explanation:</strong></p>
<p>This script performs a <strong>likelihood ratio test</strong> for the mean of a normal distribution with known variance and visualizes the <strong>chi-squared distribution</strong> with the test statistic.</p>
<ol type="1">
<li><strong>Setup:</strong>
<ul>
<li>Loads the <code>tidyverse</code> library for data manipulation and visualization.</li>
<li>Defines a function <code>likelihood_ratio_test</code> to calculate the likelihood ratio test statistic.</li>
</ul></li>
<li><strong>Likelihood Ratio Test Statistic Calculation:</strong>
<ul>
<li><p>The <code>likelihood_ratio_test</code> function takes the data and the null hypothesis mean (<code>mu_0</code>) as input.</p></li>
<li><p>Calculates the log-likelihood under the null hypothesis.</p></li>
<li><p>Calculates the log-likelihood under the alternative hypothesis (using the sample mean as the estimate of the true mean).</p></li>
<li><p>Calculates the likelihood ratio test statistic <span class="math inline">\(\lambda\)</span> as:</p>
<p><span class="math display">\[
\lambda = 2 \times (\text{log-likelihood under } H_1 - \text{log-likelihood under } H_0)
\]</span></p></li>
</ul></li>
<li><strong>Generate Sample Data:</strong>
<ul>
<li>Generates a sample of size <code>n</code> from a normal distribution with true mean <code>mu_true</code> and standard deviation <code>sigma</code>.</li>
</ul></li>
<li><strong>Hypothesized Value:</strong>
<ul>
<li>Sets the null hypothesis mean <code>mu_0</code>.</li>
</ul></li>
<li><strong>Calculate Test Statistic and P-value:</strong>
<ul>
<li>Calls the <code>likelihood_ratio_test</code> function to calculate the test statistic.</li>
<li>Calculates the p-value using the chi-squared distribution with 1 degree of freedom (because we are testing one parameter).</li>
</ul></li>
<li><strong>Print Results:</strong>
<ul>
<li>Prints the likelihood ratio test statistic and the p-value.</li>
</ul></li>
<li><strong>Visualization:</strong>
<ul>
<li>Creates a plot of the chi-squared distribution with 1 degree of freedom.</li>
<li>Adds a vertical line at the calculated likelihood ratio test statistic.</li>
<li>Shades the area to the right of the test statistic, representing the p-value, in red.</li>
</ul></li>
</ol>
<p><strong>Concepts from the Text:</strong></p>
<p>This script illustrates several concepts from the text:</p>
<ul>
<li><strong>Likelihood ratio test</strong> (Section 12.3): A statistical test based on the ratio of the likelihood of the data under the null hypothesis to the likelihood of the data under the alternative hypothesis.</li>
<li><strong>Likelihood ratio test statistic</strong> (Section 12.3): A statistic that measures the relative likelihood of the data under the null and alternative hypotheses.</li>
<li><strong>P-value</strong> (Section 12.5): The probability of observing a test statistic as extreme as or more extreme than the one calculated, assuming the null hypothesis is true.</li>
<li><strong>Chi-squared distribution</strong> (Theorem 12.1): Under certain regularity conditions, the likelihood ratio test statistic follows a chi-squared distribution under the null hypothesis.</li>
</ul>
</section>
<section class="level3" id="r-script-3-power-analysis-and-sample-size-determination">
<h3 class="anchored" data-anchor-id="r-script-3-power-analysis-and-sample-size-determination">R Script 3: Power Analysis and Sample Size Determination</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a aria-hidden="true" href="#cb13-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb13-2"><a aria-hidden="true" href="#cb13-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb13-3"><a aria-hidden="true" href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a aria-hidden="true" href="#cb13-4" tabindex="-1"></a><span class="co"># Function to calculate power</span></span>
<span id="cb13-5"><a aria-hidden="true" href="#cb13-5" tabindex="-1"></a>calculate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n, mu_0, mu_a, sigma, alpha) {</span>
<span id="cb13-6"><a aria-hidden="true" href="#cb13-6" tabindex="-1"></a>  z_alpha <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha)</span>
<span id="cb13-7"><a aria-hidden="true" href="#cb13-7" tabindex="-1"></a>  power <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(z_alpha <span class="sc">-</span> (mu_a <span class="sc">-</span> mu_0) <span class="sc">/</span> (sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb13-8"><a aria-hidden="true" href="#cb13-8" tabindex="-1"></a>  <span class="fu">return</span>(power)</span>
<span id="cb13-9"><a aria-hidden="true" href="#cb13-9" tabindex="-1"></a>}</span>
<span id="cb13-10"><a aria-hidden="true" href="#cb13-10" tabindex="-1"></a></span>
<span id="cb13-11"><a aria-hidden="true" href="#cb13-11" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb13-12"><a aria-hidden="true" href="#cb13-12" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">50</span>  <span class="co"># Null hypothesis mean</span></span>
<span id="cb13-13"><a aria-hidden="true" href="#cb13-13" tabindex="-1"></a>mu_a <span class="ot">&lt;-</span> <span class="dv">52</span>  <span class="co"># Alternative hypothesis mean</span></span>
<span id="cb13-14"><a aria-hidden="true" href="#cb13-14" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span>  <span class="co"># Standard deviation</span></span>
<span id="cb13-15"><a aria-hidden="true" href="#cb13-15" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb13-16"><a aria-hidden="true" href="#cb13-16" tabindex="-1"></a></span>
<span id="cb13-17"><a aria-hidden="true" href="#cb13-17" tabindex="-1"></a><span class="co"># Vector of sample sizes</span></span>
<span id="cb13-18"><a aria-hidden="true" href="#cb13-18" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">10</span>, <span class="at">to =</span> <span class="dv">200</span>, <span class="at">by =</span> <span class="dv">10</span>)</span>
<span id="cb13-19"><a aria-hidden="true" href="#cb13-19" tabindex="-1"></a></span>
<span id="cb13-20"><a aria-hidden="true" href="#cb13-20" tabindex="-1"></a><span class="co"># Calculate power for each sample size</span></span>
<span id="cb13-21"><a aria-hidden="true" href="#cb13-21" tabindex="-1"></a>power_values <span class="ot">&lt;-</span> <span class="fu">sapply</span>(sample_sizes, <span class="cf">function</span>(n) {</span>
<span id="cb13-22"><a aria-hidden="true" href="#cb13-22" tabindex="-1"></a>  <span class="fu">calculate_power</span>(n, mu_0, mu_a, sigma, alpha)</span>
<span id="cb13-23"><a aria-hidden="true" href="#cb13-23" tabindex="-1"></a>})</span>
<span id="cb13-24"><a aria-hidden="true" href="#cb13-24" tabindex="-1"></a></span>
<span id="cb13-25"><a aria-hidden="true" href="#cb13-25" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb13-26"><a aria-hidden="true" href="#cb13-26" tabindex="-1"></a>power_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_size =</span> sample_sizes, <span class="at">power =</span> power_values)</span>
<span id="cb13-27"><a aria-hidden="true" href="#cb13-27" tabindex="-1"></a></span>
<span id="cb13-28"><a aria-hidden="true" href="#cb13-28" tabindex="-1"></a><span class="co"># Plot power vs. sample size</span></span>
<span id="cb13-29"><a aria-hidden="true" href="#cb13-29" tabindex="-1"></a><span class="fu">ggplot</span>(power_df, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> power)) <span class="sc">+</span></span>
<span id="cb13-30"><a aria-hidden="true" href="#cb13-30" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb13-31"><a aria-hidden="true" href="#cb13-31" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb13-32"><a aria-hidden="true" href="#cb13-32" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-33"><a aria-hidden="true" href="#cb13-33" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Power vs. Sample Size"</span>,</span>
<span id="cb13-34"><a aria-hidden="true" href="#cb13-34" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample Size"</span>,</span>
<span id="cb13-35"><a aria-hidden="true" href="#cb13-35" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Power"</span></span>
<span id="cb13-36"><a aria-hidden="true" href="#cb13-36" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-37"><a aria-hidden="true" href="#cb13-37" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap12_files/figure-html/unnamed-chunk-3-1.png" width="672"/></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a aria-hidden="true" href="#cb14-1" tabindex="-1"></a><span class="co"># Determine sample size needed for a desired power</span></span>
<span id="cb14-2"><a aria-hidden="true" href="#cb14-2" tabindex="-1"></a>desired_power <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb14-3"><a aria-hidden="true" href="#cb14-3" tabindex="-1"></a>sample_size_needed <span class="ot">&lt;-</span> <span class="fu">ceiling</span>(</span>
<span id="cb14-4"><a aria-hidden="true" href="#cb14-4" tabindex="-1"></a>  ((<span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha) <span class="sc">+</span> <span class="fu">qnorm</span>(desired_power)) <span class="sc">*</span> sigma <span class="sc">/</span> (mu_a <span class="sc">-</span> mu_0))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb14-5"><a aria-hidden="true" href="#cb14-5" tabindex="-1"></a>)</span>
<span id="cb14-6"><a aria-hidden="true" href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a aria-hidden="true" href="#cb14-7" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb14-8"><a aria-hidden="true" href="#cb14-8" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Sample size needed for power of"</span>, desired_power, <span class="st">":"</span>, sample_size_needed, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample size needed for power of 0.8 : 155 </code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<p>This script performs <strong>power analysis</strong> to explore the relationship between sample size and the power of a hypothesis test, and it determines the sample size needed to achieve a desired level of power.</p>
<ol type="1">
<li><strong>Setup:</strong>
<ul>
<li>Loads the <code>tidyverse</code> library for data manipulation and visualization.</li>
<li>Defines a function <code>calculate_power</code> to calculate the power of a one-sided hypothesis test for a normal mean with known variance.</li>
</ul></li>
<li><strong>Power Calculation Function:</strong>
<ul>
<li><p>The <code>calculate_power</code> function takes the sample size (<code>n</code>), null hypothesis mean (<code>mu_0</code>), alternative hypothesis mean (<code>mu_a</code>), standard deviation (<code>sigma</code>), and significance level (<code>alpha</code>) as input.</p></li>
<li><p>Calculates the critical value <code>z_alpha</code> based on the significance level.</p></li>
<li><p>Calculates the power using the formula derived in Example 12.15:</p>
<p><span class="math display">\[
\pi_n(\mu) = 1 - \Phi \left( z_{\alpha} - \dfrac{\sqrt{n}(\mu - \mu_0)}{\sigma} \right)
\]</span> where <span class="math inline">\(\Phi\)</span> is the standard normal cumulative distribution function.</p></li>
</ul></li>
<li><strong>Set Parameters:</strong>
<ul>
<li>Sets the null hypothesis mean (<code>mu_0</code>), alternative hypothesis mean (<code>mu_a</code>), standard deviation (<code>sigma</code>), and significance level (<code>alpha</code>).</li>
</ul></li>
<li><strong>Calculate Power for Different Sample Sizes:</strong>
<ul>
<li>Creates a vector of sample sizes <code>sample_sizes</code>.</li>
<li>Uses <code>sapply</code> to calculate the power for each sample size using the <code>calculate_power</code> function.</li>
</ul></li>
<li><strong>Plot Power vs. Sample Size:</strong>
<ul>
<li>Creates a data frame <code>power_df</code> with the sample sizes and corresponding power values.</li>
<li>Uses <code>ggplot2</code> to create a line plot of power versus sample size.</li>
</ul></li>
<li><strong>Determine Sample Size for Desired Power:</strong>
<ul>
<li><p>Sets the desired power <code>desired_power</code>.</p></li>
<li><p>Calculates the sample size needed to achieve the desired power using the formula:</p>
<!-- $$ -->
<!-- n = \left( \dfrac{(z_{1-\alpha} + z_{\text{desired_power}}) \times \sigma}{\mu_a - \mu_0} \right)^2 -->
<!-- $$ -->
<!-- where $z_{1-\alpha}$ is the critical value corresponding to the significance level and $z_{\text{desired_power}}$ is the critical value corresponding to the desired power. --></li>
<li><p>Uses <code>ceiling</code> to round up to the nearest integer, as the sample size must be a whole number.</p></li>
</ul></li>
<li><strong>Print Result:</strong>
<ul>
<li>Prints the sample size needed to achieve the desired power.</li>
</ul></li>
</ol>
<p><strong>Concepts from the Text:</strong></p>
<p>This script illustrates several concepts from the text:</p>
<ul>
<li><strong>Power of a test</strong> (Section 12.4): The probability of rejecting the null hypothesis when it is false.</li>
<li><strong>Power analysis</strong> (Section 12.4): The process of determining the sample size needed to achieve a desired level of power or calculating the power of a test for a given sample size.</li>
<li><strong>Sample size determination</strong> (Section 12.4): The process of calculating the minimum sample size needed to achieve a desired level of power for a given significance level, effect size, and standard deviation.</li>
<li><strong>Relationship between power, sample size, effect size, and standard deviation</strong> (Section 12.4): The power of a test increases with increasing sample size, increasing effect size (the difference between the null and alternative hypothesis means), and decreasing standard deviation.</li>
</ul>
</section>
<section class="level3" id="r-script-4-simulation-of-the-central-limit-theorem-and-hypothesis-testing">
<h3 class="anchored" data-anchor-id="r-script-4-simulation-of-the-central-limit-theorem-and-hypothesis-testing">R Script 4: Simulation of the Central Limit Theorem and Hypothesis Testing</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a aria-hidden="true" href="#cb16-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb16-2"><a aria-hidden="true" href="#cb16-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb16-3"><a aria-hidden="true" href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a aria-hidden="true" href="#cb16-4" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb16-5"><a aria-hidden="true" href="#cb16-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># Sample size</span></span>
<span id="cb16-6"><a aria-hidden="true" href="#cb16-6" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">50</span>  <span class="co"># Population mean</span></span>
<span id="cb16-7"><a aria-hidden="true" href="#cb16-7" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span>  <span class="co"># Population standard deviation</span></span>
<span id="cb16-8"><a aria-hidden="true" href="#cb16-8" tabindex="-1"></a>num_sims <span class="ot">&lt;-</span> <span class="dv">10000</span>  <span class="co"># Number of simulations</span></span>
<span id="cb16-9"><a aria-hidden="true" href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a aria-hidden="true" href="#cb16-10" tabindex="-1"></a><span class="co"># Generate population data (not used in CLT but for comparison)</span></span>
<span id="cb16-11"><a aria-hidden="true" href="#cb16-11" tabindex="-1"></a>population_data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100000</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma)</span>
<span id="cb16-12"><a aria-hidden="true" href="#cb16-12" tabindex="-1"></a></span>
<span id="cb16-13"><a aria-hidden="true" href="#cb16-13" tabindex="-1"></a><span class="co"># Simulate sample means</span></span>
<span id="cb16-14"><a aria-hidden="true" href="#cb16-14" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-15"><a aria-hidden="true" href="#cb16-15" tabindex="-1"></a>sample_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_sims, {</span>
<span id="cb16-16"><a aria-hidden="true" href="#cb16-16" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">sample</span>(population_data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb16-17"><a aria-hidden="true" href="#cb16-17" tabindex="-1"></a>  <span class="fu">mean</span>(sample)</span>
<span id="cb16-18"><a aria-hidden="true" href="#cb16-18" tabindex="-1"></a>})</span>
<span id="cb16-19"><a aria-hidden="true" href="#cb16-19" tabindex="-1"></a></span>
<span id="cb16-20"><a aria-hidden="true" href="#cb16-20" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb16-21"><a aria-hidden="true" href="#cb16-21" tabindex="-1"></a>sim_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sample_mean =</span> sample_means)</span>
<span id="cb16-22"><a aria-hidden="true" href="#cb16-22" tabindex="-1"></a></span>
<span id="cb16-23"><a aria-hidden="true" href="#cb16-23" tabindex="-1"></a><span class="co"># Plot histogram of sample means</span></span>
<span id="cb16-24"><a aria-hidden="true" href="#cb16-24" tabindex="-1"></a><span class="fu">ggplot</span>(sim_df, <span class="fu">aes</span>(<span class="at">x =</span> sample_mean)) <span class="sc">+</span></span>
<span id="cb16-25"><a aria-hidden="true" href="#cb16-25" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"lightblue"</span>) <span class="sc">+</span></span>
<span id="cb16-26"><a aria-hidden="true" href="#cb16-26" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb16-27"><a aria-hidden="true" href="#cb16-27" tabindex="-1"></a>    <span class="at">fun =</span> dnorm,</span>
<span id="cb16-28"><a aria-hidden="true" href="#cb16-28" tabindex="-1"></a>    <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> mu, <span class="at">sd =</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)),</span>
<span id="cb16-29"><a aria-hidden="true" href="#cb16-29" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"red"</span>,</span>
<span id="cb16-30"><a aria-hidden="true" href="#cb16-30" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">1</span></span>
<span id="cb16-31"><a aria-hidden="true" href="#cb16-31" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb16-32"><a aria-hidden="true" href="#cb16-32" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb16-33"><a aria-hidden="true" href="#cb16-33" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Distribution of Sample Means and Central Limit Theorem"</span>,</span>
<span id="cb16-34"><a aria-hidden="true" href="#cb16-34" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample Mean"</span>,</span>
<span id="cb16-35"><a aria-hidden="true" href="#cb16-35" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb16-36"><a aria-hidden="true" href="#cb16-36" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb16-37"><a aria-hidden="true" href="#cb16-37" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(density)` instead.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap12_files/figure-html/unnamed-chunk-4-1.png" width="672"/></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a aria-hidden="true" href="#cb19-1" tabindex="-1"></a><span class="co"># Perform a hypothesis test using one simulated sample</span></span>
<span id="cb19-2"><a aria-hidden="true" href="#cb19-2" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> <span class="fu">sample</span>(population_data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb19-3"><a aria-hidden="true" href="#cb19-3" tabindex="-1"></a>t_test_result <span class="ot">&lt;-</span> <span class="fu">t.test</span>(sample_data, <span class="at">mu =</span> mu, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb19-4"><a aria-hidden="true" href="#cb19-4" tabindex="-1"></a></span>
<span id="cb19-5"><a aria-hidden="true" href="#cb19-5" tabindex="-1"></a><span class="co"># Print the t-test result</span></span>
<span id="cb19-6"><a aria-hidden="true" href="#cb19-6" tabindex="-1"></a><span class="fu">print</span>(t_test_result)</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    One Sample t-test

data:  sample_data
t = 0.25113, df = 29, p-value = 0.8035
alternative hypothesis: true mean is not equal to 50
95 percent confidence interval:
 46.97150 53.87633
sample estimates:
mean of x 
 50.42392 </code></pre>
</div>
</div>
<p><strong>Explanation:</strong></p>
<p>This script demonstrates the <strong>Central Limit Theorem (CLT)</strong> by simulating sample means from a population and comparing their distribution to the normal distribution predicted by the CLT. It also performs a <strong>t-test</strong> on a single sample.</p>
<ol type="1">
<li><strong>Setup:</strong>
<ul>
<li>Loads the <code>tidyverse</code> library for data manipulation and visualization.</li>
<li>Sets parameters for the simulation: sample size (<code>n</code>), population mean (<code>mu</code>), population standard deviation (<code>sigma</code>), and the number of simulations (<code>num_sims</code>).</li>
</ul></li>
<li><strong>Generate Population Data:</strong>
<ul>
<li>Generates a large sample from a normal distribution to represent the population. This is not strictly necessary for demonstrating the CLT but is used for comparison.</li>
</ul></li>
<li><strong>Simulate Sample Means:</strong>
<ul>
<li>Repeats the simulation <code>num_sims</code> times.</li>
<li>Takes a random sample of size <code>n</code> with replacement from the population data.</li>
<li>Calculates the mean of the sample.</li>
<li>Stores the sample mean in the <code>sample_means</code> vector.</li>
</ul></li>
<li><strong>Plot Histogram of Sample Means:</strong>
<ul>
<li>Creates a data frame <code>sim_df</code> with the simulated sample means.</li>
<li>Uses <code>ggplot2</code> to create a histogram of the sample means.</li>
<li>Overlays the probability density function of a normal distribution with mean <code>mu</code> and standard deviation <code>sigma / sqrt(n)</code>, as predicted by the CLT.</li>
</ul></li>
<li><strong>Perform t-test:</strong>
<ul>
<li>Takes a single random sample of size <code>n</code> from the population data.</li>
<li>Performs a two-sided t-test using the <code>t.test</code> function to test the null hypothesis that the population mean is equal to <code>mu</code>.</li>
</ul></li>
<li><strong>Print t-test Result:</strong>
<ul>
<li>Prints the results of the t-test, including the t-statistic, degrees of freedom, p-value, and confidence interval.</li>
</ul></li>
</ol>
<p><strong>Concepts from the Text:</strong></p>
<p>This script illustrates several concepts from the text:</p>
<ul>
<li><strong>Central Limit Theorem (CLT)</strong> (Example 12.8): The CLT states that the distribution of sample means approaches a normal distribution with mean equal to the population mean and standard deviation equal to the population standard deviation divided by the square root of the sample size, regardless of the shape of the population distribution, as long as the sample size is sufficiently large.</li>
<li><strong>Sampling distribution of the sample mean</strong> (Example 12.8): The distribution of sample means obtained from repeated sampling from a population.</li>
<li><strong>Hypothesis testing</strong> (Section 12.2): The process of using sample data to make inferences about a population parameter.</li>
<li><strong>t-test</strong> (Example 12.5): A statistical test used to compare the mean of a sample to a hypothesized value or to compare the means of two samples.</li>
</ul>
</section>
<section class="level3" id="r-script-5-simulation-of-p-values-under-the-null-and-alternative-hypotheses">
<h3 class="anchored" data-anchor-id="r-script-5-simulation-of-p-values-under-the-null-and-alternative-hypotheses">R Script 5: Simulation of p-values Under the Null and Alternative Hypotheses</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a aria-hidden="true" href="#cb21-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb21-2"><a aria-hidden="true" href="#cb21-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb21-3"><a aria-hidden="true" href="#cb21-3" tabindex="-1"></a></span>
<span id="cb21-4"><a aria-hidden="true" href="#cb21-4" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb21-5"><a aria-hidden="true" href="#cb21-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>  <span class="co"># Sample size</span></span>
<span id="cb21-6"><a aria-hidden="true" href="#cb21-6" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Null hypothesis mean</span></span>
<span id="cb21-7"><a aria-hidden="true" href="#cb21-7" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">15</span>  <span class="co"># Standard deviation</span></span>
<span id="cb21-8"><a aria-hidden="true" href="#cb21-8" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb21-9"><a aria-hidden="true" href="#cb21-9" tabindex="-1"></a>mu_a <span class="ot">&lt;-</span> <span class="dv">105</span> <span class="co"># Alternative hypothesis mean</span></span>
<span id="cb21-10"><a aria-hidden="true" href="#cb21-10" tabindex="-1"></a>num_sims <span class="ot">&lt;-</span> <span class="dv">10000</span>  <span class="co"># Number of simulations</span></span>
<span id="cb21-11"><a aria-hidden="true" href="#cb21-11" tabindex="-1"></a></span>
<span id="cb21-12"><a aria-hidden="true" href="#cb21-12" tabindex="-1"></a><span class="co"># Function to calculate p-value</span></span>
<span id="cb21-13"><a aria-hidden="true" href="#cb21-13" tabindex="-1"></a>calculate_p_value <span class="ot">&lt;-</span> <span class="cf">function</span>(sample, mu_0, sigma, <span class="at">alternative =</span> <span class="st">"two.sided"</span>) {</span>
<span id="cb21-14"><a aria-hidden="true" href="#cb21-14" tabindex="-1"></a>  sample_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample)</span>
<span id="cb21-15"><a aria-hidden="true" href="#cb21-15" tabindex="-1"></a>  z <span class="ot">&lt;-</span> (sample_mean <span class="sc">-</span> mu_0) <span class="sc">/</span> (sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">length</span>(sample)))</span>
<span id="cb21-16"><a aria-hidden="true" href="#cb21-16" tabindex="-1"></a>  </span>
<span id="cb21-17"><a aria-hidden="true" href="#cb21-17" tabindex="-1"></a>  <span class="cf">if</span> (alternative <span class="sc">==</span> <span class="st">"two.sided"</span>) {</span>
<span id="cb21-18"><a aria-hidden="true" href="#cb21-18" tabindex="-1"></a>    p_value <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fu">abs</span>(z)))</span>
<span id="cb21-19"><a aria-hidden="true" href="#cb21-19" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (alternative <span class="sc">==</span> <span class="st">"greater"</span>) {</span>
<span id="cb21-20"><a aria-hidden="true" href="#cb21-20" tabindex="-1"></a>    p_value <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(z)</span>
<span id="cb21-21"><a aria-hidden="true" href="#cb21-21" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (alternative <span class="sc">==</span> <span class="st">"less"</span>) {</span>
<span id="cb21-22"><a aria-hidden="true" href="#cb21-22" tabindex="-1"></a>    p_value <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(z)</span>
<span id="cb21-23"><a aria-hidden="true" href="#cb21-23" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb21-24"><a aria-hidden="true" href="#cb21-24" tabindex="-1"></a>    <span class="fu">stop</span>(<span class="st">"Invalid alternative hypothesis specified."</span>)</span>
<span id="cb21-25"><a aria-hidden="true" href="#cb21-25" tabindex="-1"></a>  }</span>
<span id="cb21-26"><a aria-hidden="true" href="#cb21-26" tabindex="-1"></a>  </span>
<span id="cb21-27"><a aria-hidden="true" href="#cb21-27" tabindex="-1"></a>  <span class="fu">return</span>(p_value)</span>
<span id="cb21-28"><a aria-hidden="true" href="#cb21-28" tabindex="-1"></a>}</span>
<span id="cb21-29"><a aria-hidden="true" href="#cb21-29" tabindex="-1"></a></span>
<span id="cb21-30"><a aria-hidden="true" href="#cb21-30" tabindex="-1"></a><span class="co"># Simulate p-values under the null hypothesis</span></span>
<span id="cb21-31"><a aria-hidden="true" href="#cb21-31" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb21-32"><a aria-hidden="true" href="#cb21-32" tabindex="-1"></a>p_values_null <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_sims, {</span>
<span id="cb21-33"><a aria-hidden="true" href="#cb21-33" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu_0, <span class="at">sd =</span> sigma)</span>
<span id="cb21-34"><a aria-hidden="true" href="#cb21-34" tabindex="-1"></a>  <span class="fu">calculate_p_value</span>(sample, mu_0, sigma)</span>
<span id="cb21-35"><a aria-hidden="true" href="#cb21-35" tabindex="-1"></a>})</span>
<span id="cb21-36"><a aria-hidden="true" href="#cb21-36" tabindex="-1"></a></span>
<span id="cb21-37"><a aria-hidden="true" href="#cb21-37" tabindex="-1"></a><span class="co"># Simulate p-values under the alternative hypothesis</span></span>
<span id="cb21-38"><a aria-hidden="true" href="#cb21-38" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb21-39"><a aria-hidden="true" href="#cb21-39" tabindex="-1"></a>p_values_alt <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_sims, {</span>
<span id="cb21-40"><a aria-hidden="true" href="#cb21-40" tabindex="-1"></a>  sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu_a, <span class="at">sd =</span> sigma)</span>
<span id="cb21-41"><a aria-hidden="true" href="#cb21-41" tabindex="-1"></a>  <span class="fu">calculate_p_value</span>(sample, mu_0, sigma)</span>
<span id="cb21-42"><a aria-hidden="true" href="#cb21-42" tabindex="-1"></a>})</span>
<span id="cb21-43"><a aria-hidden="true" href="#cb21-43" tabindex="-1"></a></span>
<span id="cb21-44"><a aria-hidden="true" href="#cb21-44" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb21-45"><a aria-hidden="true" href="#cb21-45" tabindex="-1"></a>p_values_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb21-46"><a aria-hidden="true" href="#cb21-46" tabindex="-1"></a>  <span class="at">p_value =</span> <span class="fu">c</span>(p_values_null, p_values_alt),</span>
<span id="cb21-47"><a aria-hidden="true" href="#cb21-47" tabindex="-1"></a>  <span class="at">hypothesis =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Null"</span>, <span class="st">"Alternative"</span>), <span class="at">each =</span> num_sims)</span>
<span id="cb21-48"><a aria-hidden="true" href="#cb21-48" tabindex="-1"></a>)</span>
<span id="cb21-49"><a aria-hidden="true" href="#cb21-49" tabindex="-1"></a></span>
<span id="cb21-50"><a aria-hidden="true" href="#cb21-50" tabindex="-1"></a><span class="co"># Plot histograms of p-values</span></span>
<span id="cb21-51"><a aria-hidden="true" href="#cb21-51" tabindex="-1"></a><span class="fu">ggplot</span>(p_values_df, <span class="fu">aes</span>(<span class="at">x =</span> p_value, <span class="at">fill =</span> hypothesis)) <span class="sc">+</span></span>
<span id="cb21-52"><a aria-hidden="true" href="#cb21-52" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">position =</span> <span class="st">"identity"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb21-53"><a aria-hidden="true" href="#cb21-53" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> alpha, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb21-54"><a aria-hidden="true" href="#cb21-54" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb21-55"><a aria-hidden="true" href="#cb21-55" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Distribution of P-values Under Null and Alternative Hypotheses"</span>,</span>
<span id="cb21-56"><a aria-hidden="true" href="#cb21-56" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"P-value"</span>,</span>
<span id="cb21-57"><a aria-hidden="true" href="#cb21-57" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Frequency"</span></span>
<span id="cb21-58"><a aria-hidden="true" href="#cb21-58" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb21-59"><a aria-hidden="true" href="#cb21-59" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"green"</span>)) <span class="sc">+</span></span>
<span id="cb21-60"><a aria-hidden="true" href="#cb21-60" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button class="code-copy-button" title="Copy to Clipboard"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img class="img-fluid figure-img" src="chap12_files/figure-html/unnamed-chunk-5-1.png" width="672"/></p>
</figure>
</div>
</div>
</div>
<p><strong>Explanation:</strong></p>
<p>This script simulates the distribution of <strong>p-values</strong> under the null and alternative hypotheses and visualizes them using histograms.</p>
<ol type="1">
<li><strong>Setup:</strong>
<ul>
<li>Loads the <code>tidyverse</code> library for data manipulation and visualization.</li>
<li>Sets parameters for the simulation: sample size (<code>n</code>), null hypothesis mean (<code>mu_0</code>), standard deviation (<code>sigma</code>), significance level (<code>alpha</code>), alternative hypothesis mean (<code>mu_a</code>), and the number of simulations (<code>num_sims</code>).</li>
</ul></li>
<li><strong>P-value Calculation Function:</strong>
<ul>
<li>Defines a function <code>calculate_p_value</code> to calculate the p-value for a two-sided, greater, or less hypothesis test given a sample, null hypothesis mean, and standard deviation.</li>
</ul></li>
<li><strong>Simulate P-values Under the Null Hypothesis:</strong>
<ul>
<li>Repeats the simulation <code>num_sims</code> times.</li>
<li>Generates a sample of size <code>n</code> from a normal distribution with mean <code>mu_0</code> and standard deviation <code>sigma</code>.</li>
<li>Calculates the p-value using the <code>calculate_p_value</code> function.</li>
<li>Stores the p-value in the <code>p_values_null</code> vector.</li>
</ul></li>
<li><strong>Simulate P-values Under the Alternative Hypothesis:</strong>
<ul>
<li>Repeats the simulation <code>num_sims</code> times.</li>
<li>Generates a sample of size <code>n</code> from a normal distribution with mean <code>mu_a</code> (the alternative hypothesis mean) and standard deviation <code>sigma</code>.</li>
<li>Calculates the p-value using the <code>calculate_p_value</code> function.</li>
<li>Stores the p-value in the <code>p_values_alt</code> vector.</li>
</ul></li>
<li><strong>Plot Histograms of P-values:</strong>
<ul>
<li>Creates a data frame <code>p_values_df</code> with the simulated p-values and a factor variable indicating whether the p-value came from the null or alternative hypothesis simulation.</li>
<li>Uses <code>ggplot2</code> to create histograms of the p-values, with separate histograms for the null and alternative hypotheses, overlaid on the same plot.</li>
<li>Adds a vertical line at the significance level <code>alpha</code>.</li>
</ul></li>
</ol>
<p><strong>Concepts from the Text:</strong></p>
<p>This script illustrates several concepts from the text:</p>
<ul>
<li><strong>P-value</strong> (Section 12.5): The probability of observing a test statistic as extreme as or more extreme than the one calculated, assuming the null hypothesis is true.</li>
<li><strong>Significance level</strong> (Sections 12.2, 12.4, 12.5): The probability of making a Type I error, denoted by <span class="math inline">\(\alpha\)</span>.</li>
<li><strong>Null hypothesis</strong> (Sections 12.1, 12.2, 12.3, 12.4, 12.5): The hypothesis being tested, typically representing the status quo or no effect.</li>
<li><strong>Alternative hypothesis</strong> (Sections 12.1, 12.2, 12.3, 12.4, 12.5): The hypothesis that is accepted if the null hypothesis is rejected.</li>
<li><strong>Distribution of p-values under the null hypothesis</strong> (Section 12.5): When the null hypothesis is true, the p-value follows a uniform distribution between 0 and 1.</li>
<li><strong>Distribution of p-values under the alternative hypothesis</strong> (Section 12.5): When the alternative hypothesis is true, the p-value tends to be smaller, with a distribution skewed towards 0.</li>
</ul>
<p>The histograms show that under the null hypothesis, the p-values are approximately uniformly distributed between 0 and 1. Under the alternative hypothesis, the p-values are skewed towards 0, indicating that smaller p-values are more likely when the alternative hypothesis is true. The vertical line at <code>alpha</code> represents the threshold for rejecting the null hypothesis. The proportion of p-values below <code>alpha</code> under the null hypothesis represents the Type I error rate, while the proportion of p-values below <code>alpha</code> under the alternative hypothesis represents the power of the test.</p>
</section>
</section>
<section class="level2" id="youtube-videos">
<h2 class="anchored" data-anchor-id="youtube-videos">YouTube Videos</h2>
<p>Here are some YouTube videos that explain the concepts mentioned in the attached text, along with explanations of how they relate to the text:</p>
<section class="level3" id="hypothesis-testing-an-introduction">
<h3 class="anchored" data-anchor-id="hypothesis-testing-an-introduction">1. Hypothesis Testing: An Introduction</h3>
<ul>
<li><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=0oc49DyA3hU">StatQuest: Hypothesis Testing - Part 1 - P Value, Null Hypothesis, and Alpha</a></li>
<li><strong>Channel:</strong> StatQuest with Josh Starmer</li>
<li><strong>Relevance to Text:</strong> This video provides a clear and intuitive introduction to the fundamental concepts of hypothesis testing, including:
<ul>
<li><strong>Null hypothesis</strong> (<span class="math inline">\(H_0\)</span>) and <strong>alternative hypothesis</strong> (<span class="math inline">\(H_1\)</span>) (Section 12.1): The video explains the concept of formulating null and alternative hypotheses, using examples like testing whether a fertilizer affects plant growth. It emphasizes that the null hypothesis typically represents the status quo or no effect, while the alternative hypothesis represents the effect we are trying to detect.</li>
<li><strong>Test statistic</strong> (Section 12.2): Although not explicitly named, the video demonstrates the idea of using sample data to calculate a value that helps us decide whether to reject the null hypothesis. For example, it uses the difference in average plant growth between groups to make a decision.</li>
<li><strong>P-value</strong> (Section 12.5): The video provides a visual and intuitive explanation of the p-value as the probability of observing data as extreme as or more extreme than the observed data, assuming the null hypothesis is true. It uses shaded areas under a curve to represent the p-value.</li>
<li><strong>Significance level</strong> (<span class="math inline">\(\alpha\)</span>) (Sections 12.2, 12.4, 12.5): The video introduces the concept of the significance level as a threshold for determining whether the p-value is small enough to reject the null hypothesis. It explains that a common choice for <span class="math inline">\(\alpha\)</span> is 0.05.</li>
<li><strong>Relationship between p-value, test statistic, and significance level</strong> (Sections 12.2, 12.5): The video demonstrates how the p-value, test statistic, and significance level are related and used together to make a decision about the null hypothesis.</li>
</ul></li>
</ul>
</section>
<section class="level3" id="type-i-and-type-ii-errors">
<h3 class="anchored" data-anchor-id="type-i-and-type-ii-errors">2. Type I and Type II Errors</h3>
<ul>
<li><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=a_l991xUAo8">Type I error vs Type II error</a></li>
<li><strong>Channel:</strong> MarinStatsLectures- R Programming &amp; Statistics</li>
<li><strong>Relevance to Text:</strong> This video explains the concepts of Type I and Type II errors in hypothesis testing:
<ul>
<li><strong>Type I error</strong> (Section 12.4): The video defines Type I error as rejecting the null hypothesis when it is true (a false positive). It uses the analogy of a smoke detector going off when there is no fire.</li>
<li><strong>Type II error</strong> (Section 12.4): The video defines Type II error as failing to reject the null hypothesis when it is false (a false negative). It uses the analogy of a smoke detector not going off when there is a fire.</li>
<li><strong>Relationship between Type I error, Type II error, and significance level</strong> (Section 12.4): The video explains that the significance level (<span class="math inline">\(\alpha\)</span>) is the probability of making a Type I error. It also discusses the trade-off between Type I and Type II errors: decreasing the probability of one type of error typically increases the probability of the other.</li>
<li><strong>Power of a test</strong> (Section 12.4): The video introduces the concept of power as the probability of correctly rejecting the null hypothesis when it is false (1 - probability of Type II error).</li>
</ul></li>
</ul>
</section>
<section class="level3" id="likelihood-ratio-test">
<h3 class="anchored" data-anchor-id="likelihood-ratio-test">3. Likelihood Ratio Test</h3>
<ul>
<li><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=LtwRaAeknP8">Likelihood Ratio Tests</a></li>
<li><strong>Channel:</strong> Ben Lambert</li>
<li><strong>Relevance to Text:</strong> This video provides a detailed explanation of the likelihood ratio test, a key concept in Section 12.3:
<ul>
<li><strong>Likelihood function</strong> (Section 12.3): The video explains the concept of a likelihood function as a function that measures how well a statistical model fits the observed data for different values of the parameters.</li>
<li><strong>Likelihood ratio test statistic</strong> (<span class="math inline">\(\lambda\)</span>) (Section 12.3): The video derives the likelihood ratio test statistic as the ratio of the maximum likelihood under the null hypothesis to the maximum likelihood under the alternative hypothesis. It provides examples using the normal and exponential distributions.</li>
<li><strong>Relationship between the likelihood ratio test statistic and the p-value</strong> (Section 12.3): The video explains how the likelihood ratio test statistic is used to calculate the p-value, which is then used to make a decision about the null hypothesis.</li>
<li><strong>Asymptotic distribution of the likelihood ratio test statistic</strong> (Theorem 12.1): The video mentions that under certain regularity conditions, the likelihood ratio test statistic follows a chi-squared distribution when the sample size is large.</li>
</ul></li>
</ul>
</section>
<section class="level3" id="power-and-sample-size">
<h3 class="anchored" data-anchor-id="power-and-sample-size">4. Power and Sample Size</h3>
<ul>
<li><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=NbeHZp23ubs">Hypothesis Testing: Power, Sample Size, and Effect Size - Part 4</a></li>
<li><strong>Channel:</strong> MarinStatsLectures- R Programming &amp; Statistics</li>
<li><strong>Relevance to Text:</strong> This video covers important concepts related to the power of a test and sample size determination, which are discussed in Section 12.4:
<ul>
<li><strong>Power of a test</strong> (Section 12.4): The video provides a visual and intuitive explanation of the power of a test as the probability of correctly rejecting the null hypothesis when it is false. It shows how power is related to the distance between the null and alternative hypothesis means, the standard deviation, and the sample size.</li>
<li><strong>Factors affecting power</strong> (Section 12.4): The video discusses how power is affected by the significance level (<span class="math inline">\(\alpha\)</span>), sample size (<span class="math inline">\(n\)</span>), effect size (the difference between the true parameter value and the null hypothesis value), and the standard deviation (<span class="math inline">\(\sigma\)</span>).</li>
<li><strong>Sample size determination</strong> (Section 12.4): The video explains how to calculate the sample size needed to achieve a desired level of power for a given significance level, effect size, and standard deviation. It provides an example using a one-sample t-test.</li>
<li><strong>Relationship between power, sample size, effect size, and standard deviation</strong> (Section 12.4): The video demonstrates that power increases with increasing sample size, increasing effect size, and decreasing standard deviation.</li>
</ul></li>
</ul>
</section>
<section class="level3" id="central-limit-theorem">
<h3 class="anchored" data-anchor-id="central-limit-theorem">5. Central Limit Theorem</h3>
<ul>
<li><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=YAlJCEDH2uY">Central Limit Theorem</a></li>
<li><strong>Channel:</strong> Khan Academy</li>
<li><strong>Relevance to Text:</strong> This video provides an intuitive explanation and demonstration of the Central Limit Theorem (CLT), which is mentioned in Example 12.8:
<ul>
<li><strong>Central Limit Theorem (CLT)</strong> (Example 12.8): The video explains the CLT as the principle that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the shape of the population distribution.</li>
<li><strong>Sampling distribution of the sample mean</strong> (Example 12.8): The video demonstrates how to create a sampling distribution of the sample mean by repeatedly taking samples from a population and calculating the mean of each sample.</li>
<li><strong>Relationship between the CLT and hypothesis testing</strong> (Example 12.8): The video explains that the CLT is the foundation for many hypothesis tests because it allows us to assume that the sample mean is approximately normally distributed when the sample size is large. This assumption is used to calculate test statistics and p-values in many common hypothesis tests, such as the t-test.</li>
</ul></li>
</ul>
<p>These videos provide a good visual and intuitive understanding of the key concepts in hypothesis testing covered in the text, including the formulation of hypotheses, Type I and Type II errors, likelihood ratio tests, power analysis, and the Central Limit Theorem. They are helpful resources for anyone learning about these concepts for the first time or looking for a refresher.</p>
</section>
</section>
<section class="level2" id="multiple-choice-exercises">
<h2 class="anchored" data-anchor-id="multiple-choice-exercises">Multiple Choice Exercises</h2>
<section class="level3" id="sec-ch12mcexercise1">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise1">MC Exercise 1</h3>
<p><a href="#sec-ch12mcsolution1">MC Solution 1</a></p>
<p>Which of the following statements is true about the <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>)?</p>
<ol type="a">
<li>It represents the status quo or no effect.</li>
<li>It is always rejected.</li>
<li>It is the hypothesis that the researcher wants to prove.</li>
<li>It is the same as the alternative hypothesis.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise2">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise2">MC Exercise 2</h3>
<p><a href="#sec-ch12mcsolution2">MC Solution 2</a></p>
<p>The <strong>alternative hypothesis</strong> (<span class="math inline">\(H_1\)</span>) is:</p>
<ol type="a">
<li>The hypothesis that is assumed to be true.</li>
<li>The hypothesis that is tested against the null hypothesis.</li>
<li>Always a two-sided hypothesis.</li>
<li>The hypothesis that specifies a single value for the parameter.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise3">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise3">MC Exercise 3</h3>
<p><a href="#sec-ch12mcsolution3">MC Solution 3</a></p>
<p>A <strong>Type I error</strong> occurs when:</p>
<ol type="a">
<li>The null hypothesis is rejected when it is true.</li>
<li>The null hypothesis is not rejected when it is false.</li>
<li>The alternative hypothesis is rejected when it is true.</li>
<li>The alternative hypothesis is not rejected when it is false.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise4">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise4">MC Exercise 4</h3>
<p><a href="#sec-ch12mcsolution4">MC Solution 4</a></p>
<p>A <strong>Type II error</strong> occurs when:</p>
<ol type="a">
<li>The null hypothesis is rejected when it is true.</li>
<li>The null hypothesis is not rejected when it is false.</li>
<li>The alternative hypothesis is rejected when it is true.</li>
<li>The alternative hypothesis is not rejected when it is false.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise5">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise5">MC Exercise 5</h3>
<p><a href="#sec-ch12mcsolution5">MC Solution 5</a></p>
<p>The <strong>significance level</strong> (<span class="math inline">\(\alpha\)</span>) of a hypothesis test is:</p>
<ol type="a">
<li>The probability of making a Type II error.</li>
<li>The probability of rejecting the null hypothesis when it is true.</li>
<li>The probability of accepting the null hypothesis when it is false.</li>
<li>The probability of accepting the null hypothesis when it is true.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise6">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise6">MC Exercise 6</h3>
<p><a href="#sec-ch12mcsolution6">MC Solution 6</a></p>
<p>The <strong>power</strong> of a hypothesis test is:</p>
<ol type="a">
<li>The probability of making a Type I error.</li>
<li>The probability of making a Type II error.</li>
<li>The probability of rejecting the null hypothesis when it is false.</li>
<li>The probability of accepting the null hypothesis when it is true.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise7">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise7">MC Exercise 7</h3>
<p><a href="#sec-ch12mcsolution7">MC Solution 7</a></p>
<p>A <strong>p-value</strong> is:</p>
<ol type="a">
<li>The probability that the null hypothesis is true.</li>
<li>The probability that the alternative hypothesis is true.</li>
<li>The probability of observing data as extreme as or more extreme than the observed data, assuming the null hypothesis is true.</li>
<li>The probability of observing data as extreme as or more extreme than the observed data, assuming the alternative hypothesis is true.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise8">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise8">MC Exercise 8</h3>
<p><a href="#sec-ch12mcsolution8">MC Solution 8</a></p>
<p>A <strong>simple hypothesis</strong> is:</p>
<ol type="a">
<li>A hypothesis that specifies a single value for the parameter.</li>
<li>A hypothesis that specifies a range of values for the parameter.</li>
<li>A hypothesis that does not involve any parameters.</li>
<li>A hypothesis that is easy to understand.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise9">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise9">MC Exercise 9</h3>
<p><a href="#sec-ch12mcsolution9">MC Solution 9</a></p>
<p>A <strong>composite hypothesis</strong> is:</p>
<ol type="a">
<li>A hypothesis that specifies a single value for the parameter.</li>
<li>A hypothesis that specifies a range of values for the parameter.</li>
<li>A hypothesis that does not involve any parameters.</li>
<li>A hypothesis that is difficult to understand.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise10">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise10">MC Exercise 10</h3>
<p><a href="#sec-ch12mcsolution10">MC Solution 10</a></p>
<p>The <strong>likelihood ratio test</strong> is based on:</p>
<ol type="a">
<li>The ratio of the sample mean to the sample variance.</li>
<li>The ratio of the maximum likelihood under the null hypothesis to the maximum likelihood under the alternative hypothesis.</li>
<li>The ratio of the maximum likelihood under the alternative hypothesis to the maximum likelihood under the null hypothesis.</li>
<li>The ratio of the p-value to the significance level.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise11">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise11">MC Exercise 11</h3>
<p><a href="#sec-ch12mcsolution11">MC Solution 11</a></p>
<p>A <strong>uniformly most powerful (UMP) test</strong> is:</p>
<ol type="a">
<li>A test that has the highest power among all possible tests of the same size for all possible values of the parameter under the alternative hypothesis.</li>
<li>A test that has the lowest power among all possible tests of the same size for all possible values of the parameter under the alternative hypothesis.</li>
<li>A test that is uniformly distributed.</li>
<li>A test that is used to test multiple hypotheses simultaneously.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise12">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise12">MC Exercise 12</h3>
<p><a href="#sec-ch12mcsolution12">MC Solution 12</a></p>
<p>A <strong>consistent test</strong> is a test for which:</p>
<ol type="a">
<li>The power approaches 0 as the sample size goes to infinity.</li>
<li>The power approaches 0.5 as the sample size goes to infinity.</li>
<li>The power approaches 1 as the sample size goes to infinity for all fixed alternatives.</li>
<li>The power approaches the significance level as the sample size goes to infinity.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise13">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise13">MC Exercise 13</h3>
<p><a href="#sec-ch12mcsolution13">MC Solution 13</a></p>
<p><strong>Pitman alternatives</strong> are:</p>
<ol type="a">
<li>Alternatives that are far from the null hypothesis.</li>
<li>Alternatives that approach the null hypothesis as the sample size goes to infinity.</li>
<li>Alternatives that are used in the Pitman test.</li>
<li>Alternatives that are always rejected.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise14">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise14">MC Exercise 14</h3>
<p><a href="#sec-ch12mcsolution14">MC Solution 14</a></p>
<p>The <strong>local power function</strong> describes:</p>
<ol type="a">
<li>The power of the test for alternatives that are close to the null hypothesis.</li>
<li>The power of the test for alternatives that are far from the null hypothesis.</li>
<li>The power of the test for small sample sizes.</li>
<li>The power of the test for large sample sizes.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise15">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise15">MC Exercise 15</h3>
<p><a href="#sec-ch12mcsolution15">MC Solution 15</a></p>
<p>A <strong>conservative test</strong> is a test where:</p>
<ol type="a">
<li>The actual probability of making a Type I error is greater than the stated significance level.</li>
<li>The actual probability of making a Type I error is less than or equal to the stated significance level.</li>
<li>The actual probability of making a Type II error is greater than the stated significance level.</li>
<li>The actual probability of making a Type II error is less than or equal to the stated significance level.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise16">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise16">MC Exercise 16</h3>
<p><a href="#sec-ch12mcsolution16">MC Solution 16</a></p>
<p>The <strong>Central Limit Theorem (CLT)</strong> states that:</p>
<ol type="a">
<li>The sample mean is always normally distributed.</li>
<li>The population mean is always normally distributed.</li>
<li>The distribution of sample means approaches a normal distribution as the sample size increases, regardless of the shape of the population distribution.</li>
<li>The distribution of sample means approaches a uniform distribution as the sample size increases, regardless of the shape of the population distribution.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise17">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise17">MC Exercise 17</h3>
<p><a href="#sec-ch12mcsolution17">MC Solution 17</a></p>
<p>The <strong>critical region</strong> of a hypothesis test is:</p>
<ol type="a">
<li>The set of values of the test statistic that lead to the acceptance of the null hypothesis.</li>
<li>The set of values of the test statistic that lead to the rejection of the null hypothesis.</li>
<li>The set of values of the parameter that are consistent with the null hypothesis.</li>
<li>The set of values of the parameter that are consistent with the alternative hypothesis.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise18">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise18">MC Exercise 18</h3>
<p><a href="#sec-ch12mcsolution18">MC Solution 18</a></p>
<p>The <strong>power</strong> of a test:</p>
<ol type="a">
<li>Increases as the sample size decreases.</li>
<li>Increases as the significance level increases.</li>
<li>Increases as the effect size decreases.</li>
<li>Increases as the standard deviation increases.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise19">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise19">MC Exercise 19</h3>
<p><a href="#sec-ch12mcsolution19">MC Solution 19</a></p>
<p>The <strong>Wald test</strong> is based on:</p>
<ol type="a">
<li>The ratio of two likelihoods.</li>
<li>The difference between the estimated parameter and the hypothesized value, standardized by the standard error of the estimate.</li>
<li>The comparison of two sample means.</li>
<li>The comparison of two sample variances.</li>
</ol>
</section>
<section class="level3" id="sec-ch12mcexercise20">
<h3 class="anchored" data-anchor-id="sec-ch12mcexercise20">MC Exercise 20</h3>
<p><a href="#sec-ch12mcsolution20">MC Solution 20</a></p>
<p>A <strong>nonparametric test</strong> is:</p>
<ol type="a">
<li>A test that assumes the data follow a specific parametric family of distributions.</li>
<li>A test that does not make specific assumptions about the functional form of the underlying population distribution.</li>
<li>A test that is always more powerful than a parametric test.</li>
<li>A test that is only used for small sample sizes.</li>
</ol>
</section>
</section>
<section class="level2" id="multiple-choice-solutions">
<h2 class="anchored" data-anchor-id="multiple-choice-solutions">Multiple Choice Solutions</h2>
<section class="level3" id="sec-ch12mcsolution1">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution1">MC Solution 1</h3>
<p><a href="#sec-ch12mcexercise1">MC Exercise 1</a></p>
<p><strong>(a) It represents the status quo or no effect.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>) is a statement about the population parameter that is assumed to be true until evidence suggests otherwise. It typically represents the status quo, no effect, or no difference between groups.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.1 introduces the concept of the null hypothesis and explains that it is a statement about the population parameter that is being tested. The examples in this section illustrate that the null hypothesis often represents no effect or no difference.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol start="2" type="a">
<li>The null hypothesis is not always rejected. It is rejected only if there is sufficient evidence against it.</li>
</ol></li>
<li><ol start="3" type="a">
<li>The alternative hypothesis is the hypothesis that the researcher usually wants to prove, not the null hypothesis.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The alternative hypothesis is the opposite of the null hypothesis, not the same.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution2">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution2">MC Solution 2</h3>
<p><a href="#sec-ch12mcexercise2">MC Exercise 2</a></p>
<p><strong>(b) The hypothesis that is tested against the null hypothesis.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>alternative hypothesis</strong> (<span class="math inline">\(H_1\)</span>) is a statement about the population parameter that contradicts the null hypothesis. It represents the effect or difference that the researcher is trying to detect. The alternative hypothesis is tested against the null hypothesis using sample data.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.1 defines the alternative hypothesis as the complement of the null hypothesis. It explains that the alternative hypothesis is what we are trying to find evidence for.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>The null hypothesis, not the alternative hypothesis, is assumed to be true until evidence suggests otherwise.</li>
</ol></li>
<li><ol start="3" type="a">
<li>The alternative hypothesis can be one-sided or two-sided, depending on the research question.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The alternative hypothesis can specify a single value (simple hypothesis) or a range of values (composite hypothesis).</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution3">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution3">MC Solution 3</h3>
<p><a href="#sec-ch12mcexercise3">MC Exercise 3</a></p>
<p><strong>(a) The null hypothesis is rejected when it is true.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>Type I error</strong> occurs when we reject the null hypothesis when it is actually true. It is a false positive, meaning we conclude that there is an effect or difference when there is none.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4 defines Type I error as rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol start="2" type="a">
<li>This describes a Type II error, not a Type I error.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not a standard error type in hypothesis testing.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not a standard error type in hypothesis testing.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution4">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution4">MC Solution 4</h3>
<p><a href="#sec-ch12mcexercise4">MC Exercise 4</a></p>
<p><strong>(b) The null hypothesis is not rejected when it is false.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>Type II error</strong> occurs when we fail to reject the null hypothesis when it is actually false. It is a false negative, meaning we conclude that there is no effect or difference when there actually is one.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4 defines Type II error as accepting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_A\)</span> is true.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes a Type I error, not a Type II error.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not a standard error type in hypothesis testing.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not a standard error type in hypothesis testing.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution5">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution5">MC Solution 5</h3>
<p><a href="#sec-ch12mcexercise5">MC Exercise 5</a></p>
<p><strong>(b) The probability of rejecting the null hypothesis when it is true.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>significance level</strong> (<span class="math inline">\(\alpha\)</span>) is the probability of making a Type I error. It is a pre-determined threshold that represents the maximum risk we are willing to take of rejecting a true null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Sections 12.2 and 12.4 define the significance level as the probability of rejecting the null hypothesis when it is true, which is equivalent to the probability of making a Type I error.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes the probability of making a Type II error, not the significance level.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not directly related to the significance level.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not directly related to the significance level.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution6">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution6">MC Solution 6</h3>
<p><a href="#sec-ch12mcexercise6">MC Exercise 6</a></p>
<p><strong>(c) The probability of rejecting the null hypothesis when it is false.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>power</strong> of a hypothesis test is the probability of correctly rejecting the null hypothesis when it is false. It represents the ability of the test to detect an effect or difference when one actually exists.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4 defines the power of a test as <span class="math inline">\(\pi = 1 - \beta\)</span>, where <span class="math inline">\(\beta\)</span> is the probability of making a Type II error.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes the significance level, not the power.</li>
</ol></li>
<li><ol start="2" type="a">
<li>This describes the probability of making a Type II error, not the power.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not directly related to the power of a test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution7">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution7">MC Solution 7</h3>
<p><a href="#sec-ch12mcexercise7">MC Exercise 7</a></p>
<p><strong>(c) The probability of observing data as extreme as or more extreme than the observed data, assuming the null hypothesis is true.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>p-value</strong> is the probability of obtaining a test statistic as extreme as or more extreme than the one observed, assuming that the null hypothesis is true. It quantifies the evidence against the null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.5 defines the p-value as <span class="math inline">\(p_{obs} = \text{Pr}(T \geq T_{obs} | H_0)\)</span>.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>The p-value is not the probability that the null hypothesis is true.</li>
</ol></li>
<li><ol start="2" type="a">
<li>The p-value is not the probability that the alternative hypothesis is true.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The p-value is calculated under the assumption that the null hypothesis is true, not the alternative hypothesis.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution8">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution8">MC Solution 8</h3>
<p><a href="#sec-ch12mcexercise8">MC Exercise 8</a></p>
<p><strong>(a) A hypothesis that specifies a single value for the parameter.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>simple hypothesis</strong> completely specifies the probability distribution of the data by specifying a single value for each parameter.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.1 defines a simple hypothesis as a hypothesis where the data distribution is completely specified under <span class="math inline">\(H_0\)</span>.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol start="2" type="a">
<li>This describes a composite hypothesis, not a simple hypothesis.</li>
</ol></li>
<li><ol start="3" type="a">
<li>A simple hypothesis does involve parameters.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The simplicity of a hypothesis refers to its statistical definition, not its ease of understanding.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution9">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution9">MC Solution 9</h3>
<p><a href="#sec-ch12mcexercise9">MC Exercise 9</a></p>
<p><strong>(b) A hypothesis that specifies a range of values for the parameter.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>composite hypothesis</strong> does not completely specify the probability distribution of the data because it allows for a range of possible values for the parameter.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.1 defines a composite hypothesis as a hypothesis where <span class="math inline">\(H_0\)</span> does not completely determine the distribution.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes a simple hypothesis, not a composite hypothesis.</li>
</ol></li>
<li><ol start="3" type="a">
<li>A composite hypothesis does involve parameters.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The complexity of a hypothesis refers to its statistical definition, not its ease of understanding.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution10">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution10">MC Solution 10</h3>
<p><a href="#sec-ch12mcexercise10">MC Exercise 10</a></p>
<p><strong>(c) The ratio of the maximum likelihood under the alternative hypothesis to the maximum likelihood under the null hypothesis.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>likelihood ratio test</strong> compares the likelihood of the data under the alternative hypothesis to the likelihood of the data under the null hypothesis. A larger likelihood ratio indicates stronger evidence in favor of the alternative hypothesis. The test statistic is constructed as the ratio of the maximum likelihood under the alternative hypothesis to the maximum likelihood under the null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.3 defines the likelihood ratio test statistic as:</p>
<p><span class="math display">\[
\lambda(X^n) = \dfrac{\max_{\theta \in \Theta} L(\theta | X^n)}{\max_{\theta \in \Theta_0} L(\theta | X^n)} = \dfrac{L(\hat{\theta}_{MLE} | X^n)}{L(\hat{\theta}_{RMLE} | X^n)}
\]</span></p>
<p>Some sources use an equivalent definition for the test statistic as the reciprocal of the expression above, where the numerator and denominator are switched.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This is not related to the likelihood ratio test.</li>
</ol></li>
<li><ol start="2" type="a">
<li>This describes the reciprocal of the likelihood ratio test statistic.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not related to the likelihood ratio test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution11">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution11">MC Solution 11</h3>
<p><a href="#sec-ch12mcexercise11">MC Exercise 11</a></p>
<p><strong>(a) A test that has the highest power among all possible tests of the same size for all possible values of the parameter under the alternative hypothesis.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>uniformly most powerful (UMP) test</strong> is the “best” possible test in terms of power. It is the test that has the highest probability of rejecting the null hypothesis when it is false, regardless of the true value of the parameter under the alternative hypothesis, among all tests with the same significance level.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4.1 defines a UMP test as a test for which <span class="math inline">\(\pi(\theta)\)</span> is uniformly maximized over <span class="math inline">\(\Theta_1\)</span>.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol start="2" type="a">
<li>This describes the opposite of a UMP test.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not related to the definition of a UMP test.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not related to the definition of a UMP test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution12">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution12">MC Solution 12</h3>
<p><a href="#sec-ch12mcexercise12">MC Exercise 12</a></p>
<p><strong>(c) The power approaches 1 as the sample size goes to infinity for all fixed alternatives.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>consistent test</strong> is a test that becomes increasingly able to detect any fixed alternative as the sample size increases. In other words, the probability of rejecting the null hypothesis when it is false (the power) approaches 1 as the sample size goes to infinity.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4.2 defines a consistent test as a test with power function <span class="math inline">\(\pi_n(\theta)\)</span> where <span class="math inline">\(\lim_{n \rightarrow \infty} \pi_n(\theta) = 1\)</span> for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes a test with decreasing power as the sample size increases.</li>
</ol></li>
<li><ol start="2" type="a">
<li>This is not related to the definition of a consistent test.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not related to the definition of a consistent test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution13">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution13">MC Solution 13</h3>
<p><a href="#sec-ch12mcexercise13">MC Exercise 13</a></p>
<p><strong>(b) Alternatives that approach the null hypothesis as the sample size goes to infinity.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p><strong>Pitman alternatives</strong> are a sequence of alternative hypotheses that get closer and closer to the null hypothesis as the sample size increases. They are used to study the local power of a test, which is the test’s ability to detect small deviations from the null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4.2 defines Pitman alternatives as alternatives of the form <span class="math inline">\(\theta_n = \theta_0 + \dfrac{c}{\sqrt{n}}\)</span>, where <span class="math inline">\(\theta_n\)</span> approaches <span class="math inline">\(\theta_0\)</span> as <span class="math inline">\(n\)</span> approaches infinity.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes fixed alternatives, not Pitman alternatives.</li>
</ol></li>
<li><ol start="3" type="a">
<li>Pitman alternatives are used to study the local power of various tests, not just a specific “Pitman test”.</li>
</ol></li>
<li><ol start="4" type="a">
<li>Pitman alternatives are not always rejected; they are used to study the behavior of tests for alternatives close to the null hypothesis.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution14">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution14">MC Solution 14</h3>
<p><a href="#sec-ch12mcexercise14">MC Exercise 14</a></p>
<p><strong>(a) The power of the test for alternatives that are close to the null hypothesis.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>local power function</strong> describes how the power of a test changes as the alternative hypothesis gets closer to the null hypothesis. It is used to study the ability of a test to detect small deviations from the null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4.2 defines the local power function as <span class="math inline">\(\pi_L(c; \alpha)\)</span>, which is the limit of the power function <span class="math inline">\(\pi_n(\theta_n)\)</span> as <span class="math inline">\(n\)</span> approaches infinity, where <span class="math inline">\(\theta_n\)</span> represents Pitman alternatives.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol start="2" type="a">
<li>The local power function focuses on alternatives close to the null hypothesis, not far from it.</li>
</ol></li>
<li><ol start="3" type="a">
<li>The local power function is not specifically about small or large sample sizes but rather about the behavior of the power function for alternatives close to the null hypothesis.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The local power function is not specifically about small or large sample sizes but rather about the behavior of the power function for alternatives close to the null hypothesis.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution15">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution15">MC Solution 15</h3>
<p><a href="#sec-ch12mcexercise15">MC Exercise 15</a></p>
<p><strong>(b) The actual probability of making a Type I error is less than or equal to the stated significance level.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>conservative test</strong> is a test that is less likely to reject the null hypothesis than it should be, given the stated significance level. This means that the actual probability of making a Type I error (rejecting a true null hypothesis) is lower than the stated significance level.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.2 defines a conservative test as a test where the probability of rejecting the null hypothesis when it is true may be less than the stated significance level <span class="math inline">\(\alpha\)</span> for some parameter values in the null hypothesis.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes a liberal test, not a conservative test.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not directly related to the definition of a conservative test.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not directly related to the definition of a conservative test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution16">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution16">MC Solution 16</h3>
<p><a href="#sec-ch12mcexercise16">MC Exercise 16</a></p>
<p><strong>(c) The distribution of sample means approaches a normal distribution as the sample size increases, regardless of the shape of the population distribution.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>Central Limit Theorem (CLT)</strong> states that the distribution of sample means will be approximately normally distributed, regardless of the shape of the original population distribution, as long as the sample size is sufficiently large. This is a fundamental theorem in statistics and is used to make inferences about population means.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>The CLT is referenced in Example 12.8 and is used to justify the use of the normal distribution in hypothesis tests involving sample means when the sample size is large.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>The sample mean itself is a single value, not a distribution. The CLT describes the distribution of sample means, not the distribution of the sample mean itself.</li>
</ol></li>
<li><ol start="2" type="a">
<li>The population mean is a fixed value, not a distribution. The CLT does not make any claims about the distribution of the population mean.</li>
</ol></li>
<li><ol start="4" type="a">
<li>The distribution of sample means approaches a normal distribution under the CLT, not a uniform distribution.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution17">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution17">MC Solution 17</h3>
<p><a href="#sec-ch12mcexercise17">MC Exercise 17</a></p>
<p><strong>(b) The set of values of the test statistic that lead to the rejection of the null hypothesis.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>critical region</strong> is the set of values of the test statistic for which we reject the null hypothesis. It is determined by the significance level (<span class="math inline">\(\alpha\)</span>) and the distribution of the test statistic under the null hypothesis.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.2 defines the critical region <span class="math inline">\(R_{\alpha}\)</span> as the set of values of the test statistic that lead to the rejection of the null hypothesis.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes the acceptance region, not the critical region.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not directly related to the definition of the critical region.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not directly related to the definition of the critical region.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution18">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution18">MC Solution 18</h3>
<p><a href="#sec-ch12mcexercise18">MC Exercise 18</a></p>
<p><strong>(b) Increases as the significance level increases.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>power</strong> of a test is the probability of rejecting the null hypothesis when it is false. Increasing the significance level (<span class="math inline">\(\alpha\)</span>) makes it easier to reject the null hypothesis, which in turn increases the power of the test. However, increasing the significance level also increases the probability of making a Type I error.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4 discusses the factors that affect the power of a test, including the significance level.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>Power generally increases as the sample size increases, not decreases.</li>
</ol></li>
<li><ol start="3" type="a">
<li>Power generally increases as the effect size increases, not decreases.</li>
</ol></li>
<li><ol start="4" type="a">
<li>Power generally decreases as the standard deviation increases, not increases.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution19">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution19">MC Solution 19</h3>
<p><a href="#sec-ch12mcexercise19">MC Exercise 19</a></p>
<p><strong>(b) The difference between the estimated parameter and the hypothesized value, standardized by the standard error of the estimate.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>The <strong>Wald test</strong> is based on the idea that if the null hypothesis is true, then the estimated parameter should be close to the hypothesized value. The Wald test statistic measures the distance between the estimated parameter and the hypothesized value, standardized by the standard error of the estimate.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.3 introduces the Wald test and provides the formula for the Wald test statistic in the case of a simple null hypothesis:</p>
<p><span class="math display">\[
W = \dfrac{n g(\hat{\theta})^2}{G(\hat{\theta})^2 I(\hat{\theta})}
\]</span></p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes the likelihood ratio test, not the Wald test.</li>
</ol></li>
<li><ol start="3" type="a">
<li>This is not directly related to the definition of the Wald test.</li>
</ol></li>
<li><ol start="4" type="a">
<li>This is not directly related to the definition of the Wald test.</li>
</ol></li>
</ul>
</section>
<section class="level3" id="sec-ch12mcsolution20">
<h3 class="anchored" data-anchor-id="sec-ch12mcsolution20">MC Solution 20</h3>
<p><a href="#sec-ch12mcexercise20">MC Exercise 20</a></p>
<p><strong>(b) A test that does not make specific assumptions about the functional form of the underlying population distribution.</strong></p>
<p><strong>Intuitive Explanation:</strong></p>
<p>A <strong>nonparametric test</strong> is a hypothesis test that does not rely on assumptions about the specific form of the population distribution, such as normality. Nonparametric tests are often based on ranks or signs of the data rather than the actual numerical values.</p>
<p><strong>Relationship to the Text:</strong></p>
<p>Section 12.4.3 introduces nonparametric testing and provides examples of situations where nonparametric tests might be used.</p>
<p><strong>Why other options are incorrect:</strong></p>
<ul>
<li><ol type="a">
<li>This describes a parametric test, not a nonparametric test.</li>
</ol></li>
<li><ol start="3" type="a">
<li>Nonparametric tests are not always more powerful than parametric tests; their power depends on the specific situation and whether the assumptions of the parametric tests are met.</li>
</ol></li>
<li><ol start="4" type="a">
<li>Nonparametric tests can be used for both small and large sample sizes.</li>
</ol></li>
</ul>
</section>
</section>
</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>

</div> <!-- /content -->
<footer class="footer">
<div class="nav-footer">
<div class="nav-footer-left">
<p>Author: Peter Fuleky</p>
</div>
<div class="nav-footer-center">
       
    </div>
<div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a></p>
</div>
</div>
</footer>
</body></html>